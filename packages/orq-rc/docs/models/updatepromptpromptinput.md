# UpdatePromptPromptInput

Prompt configuration with model and messages. Use this to update the prompt.


## Fields

| Field                                                                                                                                                                                                                                                                              | Type                                                                                                                                                                                                                                                                               | Required                                                                                                                                                                                                                                                                           | Description                                                                                                                                                                                                                                                                        | Example                                                                                                                                                                                                                                                                            |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `messages`                                                                                                                                                                                                                                                                         | List[[models.UpdatePromptPromptsMessages](../models/updatepromptpromptsmessages.md)]                                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | Array of messages that make up the conversation. Each message has a role (system, user, assistant, or tool) and content.                                                                                                                                                           | [<br/>{<br/>"role": "system",<br/>"content": "You are a helpful assistant"<br/>},<br/>{<br/>"role": "user",<br/>"content": "What is the weather today?"<br/>}<br/>]                                                                                                                |
| `model`                                                                                                                                                                                                                                                                            | *Optional[str]*                                                                                                                                                                                                                                                                    | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | Model ID used to generate the response, like `openai/gpt-4o` or `anthropic/claude-3-5-sonnet-20241022`. The full list of models can be found at https://docs.orq.ai/docs/ai-gateway-supported-models. Only chat models are supported.                                              | openai/gpt-4o                                                                                                                                                                                                                                                                      |
| `temperature`                                                                                                                                                                                                                                                                      | *OptionalNullable[float]*                                                                                                                                                                                                                                                          | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.                                                                                               |                                                                                                                                                                                                                                                                                    |
| `max_tokens`                                                                                                                                                                                                                                                                       | *OptionalNullable[int]*                                                                                                                                                                                                                                                            | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | `[Deprecated]`. The maximum number of tokens that can be generated in the chat completion. This value can be used to control costs for text generated via API. <br/><br/> This value is now `deprecated` in favor of `max_completion_tokens`, and is not compatible with o1 series models. |                                                                                                                                                                                                                                                                                    |
| `response_format`                                                                                                                                                                                                                                                                  | [Optional[models.UpdatePromptPromptsResponseFormat]](../models/updatepromptpromptsresponseformat.md)                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                 | An object specifying the format that the model must output                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                    |