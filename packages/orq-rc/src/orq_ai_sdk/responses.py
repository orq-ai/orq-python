"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from enum import Enum
from orq_ai_sdk import models, utils
from orq_ai_sdk._hooks import HookContext
from orq_ai_sdk.models import (
    createagentresponserequestop as models_createagentresponserequestop,
)
from orq_ai_sdk.types import OptionalNullable, UNSET
from orq_ai_sdk.utils import eventstreaming, get_security_from_env
from orq_ai_sdk.utils.unmarshal_json_response import unmarshal_json_response
from typing import Any, Dict, Mapping, Optional, Union


class CreateAcceptEnum(str, Enum):
    APPLICATION_JSON = "application/json"
    TEXT_EVENT_STREAM = "text/event-stream"


class Responses(BaseSDK):
    def create(
        self,
        *,
        agent_key: str,
        message: Union[
            models_createagentresponserequestop.A2AMessage,
            models_createagentresponserequestop.A2AMessageTypedDict,
        ],
        task_id: Optional[str] = None,
        variables: Optional[Dict[str, Any]] = None,
        contact: Optional[
            Union[
                models_createagentresponserequestop.Contact,
                models_createagentresponserequestop.ContactTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_createagentresponserequestop.CreateAgentResponseRequestThread,
                models_createagentresponserequestop.CreateAgentResponseRequestThreadTypedDict,
            ]
        ] = None,
        memory: Optional[
            Union[
                models_createagentresponserequestop.CreateAgentResponseRequestMemory,
                models_createagentresponserequestop.CreateAgentResponseRequestMemoryTypedDict,
            ]
        ] = None,
        metadata: Optional[Dict[str, Any]] = None,
        background: Optional[bool] = False,
        stream: Optional[bool] = False,
        conversation: Optional[
            Union[
                models_createagentresponserequestop.Conversation,
                models_createagentresponserequestop.ConversationTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        accept_header_override: Optional[CreateAcceptEnum] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.CreateAgentResponseRequestResponse:
        r"""Create response

        Initiates an agent conversation and returns a complete response. This endpoint manages the full lifecycle of an agent interaction, from receiving the initial message through all processing steps until completion. Supports synchronous execution (waits for completion) and asynchronous execution (returns immediately with task ID). The response includes all messages exchanged, tool calls made, and token usage statistics. Ideal for request-response patterns where you need the complete interaction result.

        :param agent_key: The unique key of identifier of the agent to invoke
        :param message: The A2A message to send to the agent (user input or tool results)
        :param task_id: Optional task ID to continue an existing agent execution. When provided, the agent will continue the conversation from the existing task state. The task must be in an inactive state to continue.
        :param variables: Optional variables for template replacement in system prompt, instructions, and messages
        :param contact: Information about the contact making the request. If the contact does not exist, it will be created automatically.
        :param thread: Thread information to group related requests
        :param memory: Memory configuration for the agent execution. Used to associate memory stores with specific entities like users or sessions.
        :param metadata: Optional metadata for the agent invocation as key-value pairs that will be included in traces
        :param background: If true, returns immediately without waiting for completion. If false (default), waits until the agent becomes inactive or errors.
        :param stream: If true, returns Server-Sent Events (SSE) streaming response with real-time events. If false (default), returns standard JSON response.
        :param conversation:
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param accept_header_override: Override the default accept header for this method
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.CreateAgentResponseRequestRequest(
            agent_key=agent_key,
            request_body=models.CreateAgentResponseRequestRequestBody(
                task_id=task_id,
                message=utils.get_pydantic_model(message, models.A2AMessage),
                variables=variables,
                contact=utils.get_pydantic_model(contact, Optional[models.Contact]),
                thread=utils.get_pydantic_model(
                    thread, Optional[models.CreateAgentResponseRequestThread]
                ),
                memory=utils.get_pydantic_model(
                    memory, Optional[models.CreateAgentResponseRequestMemory]
                ),
                metadata=metadata,
                background=background,
                stream=stream,
                conversation=utils.get_pydantic_model(
                    conversation, Optional[models.Conversation]
                ),
            ),
        )

        req = self._build_request(
            method="POST",
            path="/v2/agents/{agent_key}/responses",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=True,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value=accept_header_override.value
            if accept_header_override is not None
            else "application/json;q=1, text/event-stream;q=0",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request.request_body,
                False,
                False,
                "json",
                models.CreateAgentResponseRequestRequestBody,
            ),
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="CreateAgentResponseRequest",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "5XX"],
            stream=True,
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            http_res_text = utils.stream_to_text(http_res)
            return unmarshal_json_response(
                models.CreateAgentResponse, http_res, http_res_text
            )
        if utils.match_response(http_res, "200", "text/event-stream"):
            return eventstreaming.EventStream(
                http_res,
                lambda raw: utils.unmarshal_json(
                    raw, models.CreateAgentResponseRequestResponseBody
                ),
                sentinel="[DONE]",
                client_ref=self,
            )
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        http_res_text = utils.stream_to_text(http_res)
        raise models.APIError("Unexpected response received", http_res, http_res_text)

    async def create_async(
        self,
        *,
        agent_key: str,
        message: Union[
            models_createagentresponserequestop.A2AMessage,
            models_createagentresponserequestop.A2AMessageTypedDict,
        ],
        task_id: Optional[str] = None,
        variables: Optional[Dict[str, Any]] = None,
        contact: Optional[
            Union[
                models_createagentresponserequestop.Contact,
                models_createagentresponserequestop.ContactTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_createagentresponserequestop.CreateAgentResponseRequestThread,
                models_createagentresponserequestop.CreateAgentResponseRequestThreadTypedDict,
            ]
        ] = None,
        memory: Optional[
            Union[
                models_createagentresponserequestop.CreateAgentResponseRequestMemory,
                models_createagentresponserequestop.CreateAgentResponseRequestMemoryTypedDict,
            ]
        ] = None,
        metadata: Optional[Dict[str, Any]] = None,
        background: Optional[bool] = False,
        stream: Optional[bool] = False,
        conversation: Optional[
            Union[
                models_createagentresponserequestop.Conversation,
                models_createagentresponserequestop.ConversationTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        accept_header_override: Optional[CreateAcceptEnum] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.CreateAgentResponseRequestResponse:
        r"""Create response

        Initiates an agent conversation and returns a complete response. This endpoint manages the full lifecycle of an agent interaction, from receiving the initial message through all processing steps until completion. Supports synchronous execution (waits for completion) and asynchronous execution (returns immediately with task ID). The response includes all messages exchanged, tool calls made, and token usage statistics. Ideal for request-response patterns where you need the complete interaction result.

        :param agent_key: The unique key of identifier of the agent to invoke
        :param message: The A2A message to send to the agent (user input or tool results)
        :param task_id: Optional task ID to continue an existing agent execution. When provided, the agent will continue the conversation from the existing task state. The task must be in an inactive state to continue.
        :param variables: Optional variables for template replacement in system prompt, instructions, and messages
        :param contact: Information about the contact making the request. If the contact does not exist, it will be created automatically.
        :param thread: Thread information to group related requests
        :param memory: Memory configuration for the agent execution. Used to associate memory stores with specific entities like users or sessions.
        :param metadata: Optional metadata for the agent invocation as key-value pairs that will be included in traces
        :param background: If true, returns immediately without waiting for completion. If false (default), waits until the agent becomes inactive or errors.
        :param stream: If true, returns Server-Sent Events (SSE) streaming response with real-time events. If false (default), returns standard JSON response.
        :param conversation:
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param accept_header_override: Override the default accept header for this method
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.CreateAgentResponseRequestRequest(
            agent_key=agent_key,
            request_body=models.CreateAgentResponseRequestRequestBody(
                task_id=task_id,
                message=utils.get_pydantic_model(message, models.A2AMessage),
                variables=variables,
                contact=utils.get_pydantic_model(contact, Optional[models.Contact]),
                thread=utils.get_pydantic_model(
                    thread, Optional[models.CreateAgentResponseRequestThread]
                ),
                memory=utils.get_pydantic_model(
                    memory, Optional[models.CreateAgentResponseRequestMemory]
                ),
                metadata=metadata,
                background=background,
                stream=stream,
                conversation=utils.get_pydantic_model(
                    conversation, Optional[models.Conversation]
                ),
            ),
        )

        req = self._build_request_async(
            method="POST",
            path="/v2/agents/{agent_key}/responses",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=True,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value=accept_header_override.value
            if accept_header_override is not None
            else "application/json;q=1, text/event-stream;q=0",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request.request_body,
                False,
                False,
                "json",
                models.CreateAgentResponseRequestRequestBody,
            ),
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="CreateAgentResponseRequest",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "5XX"],
            stream=True,
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            http_res_text = await utils.stream_to_text_async(http_res)
            return unmarshal_json_response(
                models.CreateAgentResponse, http_res, http_res_text
            )
        if utils.match_response(http_res, "200", "text/event-stream"):
            return eventstreaming.EventStreamAsync(
                http_res,
                lambda raw: utils.unmarshal_json(
                    raw, models.CreateAgentResponseRequestResponseBody
                ),
                sentinel="[DONE]",
                client_ref=self,
            )
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        http_res_text = await utils.stream_to_text_async(http_res)
        raise models.APIError("Unexpected response received", http_res, http_res_text)
