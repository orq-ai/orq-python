"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from orq_ai_sdk import models, utils
from orq_ai_sdk._hooks import HookContext
from orq_ai_sdk.models import createtranscriptionop as models_createtranscriptionop
from orq_ai_sdk.types import OptionalNullable, UNSET
from orq_ai_sdk.utils import get_security_from_env
from orq_ai_sdk.utils.unmarshal_json_response import unmarshal_json_response
from typing import Any, List, Mapping, Optional, Union


class Transcriptions(BaseSDK):
    def create(
        self,
        *,
        model: str,
        prompt: Optional[str] = None,
        enable_logging: Optional[bool] = True,
        diarize: Optional[bool] = False,
        response_format: Optional[
            models_createtranscriptionop.CreateTranscriptionResponseFormat
        ] = None,
        tag_audio_events: Optional[bool] = True,
        num_speakers: Optional[float] = None,
        timestamps_granularity: Optional[
            models_createtranscriptionop.TimestampsGranularity
        ] = "word",
        temperature: Optional[float] = None,
        language: Optional[str] = None,
        timestamp_granularities: Optional[
            List[models_createtranscriptionop.TimestampGranularities]
        ] = None,
        name: Optional[str] = None,
        fallbacks: Optional[
            Union[
                List[models_createtranscriptionop.CreateTranscriptionFallbacks],
                List[
                    models_createtranscriptionop.CreateTranscriptionFallbacksTypedDict
                ],
            ]
        ] = None,
        retry: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionRetry,
                models_createtranscriptionop.CreateTranscriptionRetryTypedDict,
            ]
        ] = None,
        load_balancer: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionLoadBalancer,
                models_createtranscriptionop.CreateTranscriptionLoadBalancerTypedDict,
            ]
        ] = None,
        timeout: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionTimeout,
                models_createtranscriptionop.CreateTranscriptionTimeoutTypedDict,
            ]
        ] = None,
        orq: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionOrq,
                models_createtranscriptionop.CreateTranscriptionOrqTypedDict,
            ]
        ] = None,
        file: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionFile,
                models_createtranscriptionop.CreateTranscriptionFileTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.CreateTranscriptionResponseBody:
        r"""Create transcription

        :param model: ID of the model to use
        :param prompt: An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.
        :param enable_logging: When enable_logging is set to false, zero retention mode is used. This disables history features like request stitching and is only available to enterprise customers.
        :param diarize: Whether to annotate which speaker is currently talking in the uploaded file.
        :param response_format: The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
        :param tag_audio_events: Whether to tag audio events like (laughter), (footsteps), etc. in the transcription.
        :param num_speakers: The maximum amount of speakers talking in the uploaded file. Helps with predicting who speaks when, the maximum is 32.
        :param timestamps_granularity: The granularity of the timestamps in the transcription. Word provides word-level timestamps and character provides character-level timestamps per word.
        :param temperature: The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        :param language: The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency.
        :param timestamp_granularities: The timestamp granularities to populate for this transcription. response_format must be set to verbose_json to use timestamp granularities. Either or both of these options are supported: \"word\" or \"segment\". Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
        :param name: The name to display on the trace. If not specified, the default system name will be used.
        :param fallbacks: Array of fallback models to use if primary model fails
        :param retry: Retry configuration for the request
        :param load_balancer: Load balancer configuration for the request.
        :param timeout: Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured.
        :param orq:
        :param file: The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.CreateTranscriptionRequestBody(
            model=model,
            prompt=prompt,
            enable_logging=enable_logging,
            diarize=diarize,
            response_format=response_format,
            tag_audio_events=tag_audio_events,
            num_speakers=num_speakers,
            timestamps_granularity=timestamps_granularity,
            temperature=temperature,
            language=language,
            timestamp_granularities=timestamp_granularities,
            name=name,
            fallbacks=utils.get_pydantic_model(
                fallbacks, Optional[List[models.CreateTranscriptionFallbacks]]
            ),
            retry=utils.get_pydantic_model(
                retry, Optional[models.CreateTranscriptionRetry]
            ),
            load_balancer=utils.get_pydantic_model(
                load_balancer, Optional[models.CreateTranscriptionLoadBalancer]
            ),
            timeout=utils.get_pydantic_model(
                timeout, Optional[models.CreateTranscriptionTimeout]
            ),
            orq=utils.get_pydantic_model(orq, Optional[models.CreateTranscriptionOrq]),
            file=utils.get_pydantic_model(
                file, Optional[models.CreateTranscriptionFile]
            ),
        )

        req = self._build_request(
            method="POST",
            path="/v2/router/audio/transcriptions",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request,
                False,
                False,
                "multipart",
                models.CreateTranscriptionRequestBody,
            ),
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="createTranscription",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["422", "4XX", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                models.CreateTranscriptionResponseBody, http_res
            )
        if utils.match_response(http_res, "422", "application/json"):
            response_data = unmarshal_json_response(
                models.CreateTranscriptionRouterAudioTranscriptionsResponseBodyData,
                http_res,
            )
            raise models.CreateTranscriptionRouterAudioTranscriptionsResponseBody(
                response_data, http_res
            )
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)

    async def create_async(
        self,
        *,
        model: str,
        prompt: Optional[str] = None,
        enable_logging: Optional[bool] = True,
        diarize: Optional[bool] = False,
        response_format: Optional[
            models_createtranscriptionop.CreateTranscriptionResponseFormat
        ] = None,
        tag_audio_events: Optional[bool] = True,
        num_speakers: Optional[float] = None,
        timestamps_granularity: Optional[
            models_createtranscriptionop.TimestampsGranularity
        ] = "word",
        temperature: Optional[float] = None,
        language: Optional[str] = None,
        timestamp_granularities: Optional[
            List[models_createtranscriptionop.TimestampGranularities]
        ] = None,
        name: Optional[str] = None,
        fallbacks: Optional[
            Union[
                List[models_createtranscriptionop.CreateTranscriptionFallbacks],
                List[
                    models_createtranscriptionop.CreateTranscriptionFallbacksTypedDict
                ],
            ]
        ] = None,
        retry: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionRetry,
                models_createtranscriptionop.CreateTranscriptionRetryTypedDict,
            ]
        ] = None,
        load_balancer: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionLoadBalancer,
                models_createtranscriptionop.CreateTranscriptionLoadBalancerTypedDict,
            ]
        ] = None,
        timeout: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionTimeout,
                models_createtranscriptionop.CreateTranscriptionTimeoutTypedDict,
            ]
        ] = None,
        orq: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionOrq,
                models_createtranscriptionop.CreateTranscriptionOrqTypedDict,
            ]
        ] = None,
        file: Optional[
            Union[
                models_createtranscriptionop.CreateTranscriptionFile,
                models_createtranscriptionop.CreateTranscriptionFileTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.CreateTranscriptionResponseBody:
        r"""Create transcription

        :param model: ID of the model to use
        :param prompt: An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.
        :param enable_logging: When enable_logging is set to false, zero retention mode is used. This disables history features like request stitching and is only available to enterprise customers.
        :param diarize: Whether to annotate which speaker is currently talking in the uploaded file.
        :param response_format: The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
        :param tag_audio_events: Whether to tag audio events like (laughter), (footsteps), etc. in the transcription.
        :param num_speakers: The maximum amount of speakers talking in the uploaded file. Helps with predicting who speaks when, the maximum is 32.
        :param timestamps_granularity: The granularity of the timestamps in the transcription. Word provides word-level timestamps and character provides character-level timestamps per word.
        :param temperature: The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        :param language: The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency.
        :param timestamp_granularities: The timestamp granularities to populate for this transcription. response_format must be set to verbose_json to use timestamp granularities. Either or both of these options are supported: \"word\" or \"segment\". Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
        :param name: The name to display on the trace. If not specified, the default system name will be used.
        :param fallbacks: Array of fallback models to use if primary model fails
        :param retry: Retry configuration for the request
        :param load_balancer: Load balancer configuration for the request.
        :param timeout: Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured.
        :param orq:
        :param file: The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.CreateTranscriptionRequestBody(
            model=model,
            prompt=prompt,
            enable_logging=enable_logging,
            diarize=diarize,
            response_format=response_format,
            tag_audio_events=tag_audio_events,
            num_speakers=num_speakers,
            timestamps_granularity=timestamps_granularity,
            temperature=temperature,
            language=language,
            timestamp_granularities=timestamp_granularities,
            name=name,
            fallbacks=utils.get_pydantic_model(
                fallbacks, Optional[List[models.CreateTranscriptionFallbacks]]
            ),
            retry=utils.get_pydantic_model(
                retry, Optional[models.CreateTranscriptionRetry]
            ),
            load_balancer=utils.get_pydantic_model(
                load_balancer, Optional[models.CreateTranscriptionLoadBalancer]
            ),
            timeout=utils.get_pydantic_model(
                timeout, Optional[models.CreateTranscriptionTimeout]
            ),
            orq=utils.get_pydantic_model(orq, Optional[models.CreateTranscriptionOrq]),
            file=utils.get_pydantic_model(
                file, Optional[models.CreateTranscriptionFile]
            ),
        )

        req = self._build_request_async(
            method="POST",
            path="/v2/router/audio/transcriptions",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request,
                False,
                False,
                "multipart",
                models.CreateTranscriptionRequestBody,
            ),
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="createTranscription",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["422", "4XX", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                models.CreateTranscriptionResponseBody, http_res
            )
        if utils.match_response(http_res, "422", "application/json"):
            response_data = unmarshal_json_response(
                models.CreateTranscriptionRouterAudioTranscriptionsResponseBodyData,
                http_res,
            )
            raise models.CreateTranscriptionRouterAudioTranscriptionsResponseBody(
                response_data, http_res
            )
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)
