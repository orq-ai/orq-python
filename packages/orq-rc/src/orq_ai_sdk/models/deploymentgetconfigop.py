"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .audiocontentpartschema import (
    AudioContentPartSchema,
    AudioContentPartSchemaTypedDict,
)
from .filecontentpartschema import FileContentPartSchema, FileContentPartSchemaTypedDict
from .imagecontentpartschema import (
    ImageContentPartSchema,
    ImageContentPartSchemaTypedDict,
)
from .reasoningpartschema import ReasoningPartSchema, ReasoningPartSchemaTypedDict
from .redactedreasoningpartschema import (
    RedactedReasoningPartSchema,
    RedactedReasoningPartSchemaTypedDict,
)
from .refusalpartschema import RefusalPartSchema, RefusalPartSchemaTypedDict
from .textcontentpartschema import TextContentPartSchema, TextContentPartSchemaTypedDict
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from orq_ai_sdk.utils import get_discriminator
import pydantic
from pydantic import Discriminator, Tag, model_serializer
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5Role = Literal["tool",]
r"""The role of the messages author, in this case tool."""


DeploymentGetConfigContentDeploymentsRequest2TypedDict = TextContentPartSchemaTypedDict


DeploymentGetConfigContentDeploymentsRequest2 = TextContentPartSchema


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5ContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5ContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequest2TypedDict]],
)
r"""The contents of the tool message."""


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5Content = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5Content",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequest2]],
)
r"""The contents of the tool message."""


DeploymentGetConfigPrefixMessagesDeploymentsType = Literal["ephemeral",]
r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""


DeploymentGetConfigPrefixMessagesTTL = Literal[
    "5m",
    "1h",
]
r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

- `5m`: 5 minutes
- `1h`: 1 hour

Defaults to `5m`. Only supported by `Anthropic` Claude models.
"""


class DeploymentGetConfigPrefixMessagesCacheControlTypedDict(TypedDict):
    type: DeploymentGetConfigPrefixMessagesDeploymentsType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""
    ttl: NotRequired[DeploymentGetConfigPrefixMessagesTTL]
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """


class DeploymentGetConfigPrefixMessagesCacheControl(BaseModel):
    type: DeploymentGetConfigPrefixMessagesDeploymentsType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""

    ttl: Optional[DeploymentGetConfigPrefixMessagesTTL] = "5m"
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["ttl"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class PrefixMessagesToolMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""
    content: (
        DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5ContentTypedDict
    )
    r"""The contents of the tool message."""
    tool_call_id: Nullable[str]
    r"""Tool call that this message is responding to."""
    cache_control: NotRequired[DeploymentGetConfigPrefixMessagesCacheControlTypedDict]


class PrefixMessagesToolMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""

    content: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody5Content
    r"""The contents of the tool message."""

    tool_call_id: Nullable[str]
    r"""Tool call that this message is responding to."""

    cache_control: Optional[DeploymentGetConfigPrefixMessagesCacheControl] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["cache_control"])
        nullable_fields = set(["tool_call_id"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


DeploymentGetConfigContentDeployments2TypedDict = TypeAliasType(
    "DeploymentGetConfigContentDeployments2TypedDict",
    Union[
        RefusalPartSchemaTypedDict,
        RedactedReasoningPartSchemaTypedDict,
        TextContentPartSchemaTypedDict,
        ReasoningPartSchemaTypedDict,
    ],
)


DeploymentGetConfigContentDeployments2 = Annotated[
    Union[
        Annotated[TextContentPartSchema, Tag("text")],
        Annotated[RefusalPartSchema, Tag("refusal")],
        Annotated[ReasoningPartSchema, Tag("reasoning")],
        Annotated[RedactedReasoningPartSchema, Tag("redacted_reasoning")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeployments2TypedDict]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyContent = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyContent",
    Union[str, List[DeploymentGetConfigContentDeployments2]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyRole = Literal[
    "assistant",
]
r"""The role of the messages author, in this case `assistant`."""


class PrefixMessagesAudioTypedDict(TypedDict):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


class PrefixMessagesAudio(BaseModel):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


DeploymentGetConfigPrefixMessagesType = Literal["function",]
r"""The type of the tool. Currently, only `function` is supported."""


class DeploymentGetConfigPrefixMessagesFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name of the function to call."""
    arguments: NotRequired[str]
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentGetConfigPrefixMessagesFunction(BaseModel):
    name: Optional[str] = None
    r"""The name of the function to call."""

    arguments: Optional[str] = None
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name", "arguments"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class PrefixMessagesToolCallsTypedDict(TypedDict):
    id: str
    r"""The ID of the tool call."""
    type: DeploymentGetConfigPrefixMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: DeploymentGetConfigPrefixMessagesFunctionTypedDict
    thought_signature: NotRequired[str]
    r"""Encrypted representation of the model internal reasoning state during function calling. Required by Gemini 3 models when continuing a conversation after a tool call."""


class PrefixMessagesToolCalls(BaseModel):
    id: str
    r"""The ID of the tool call."""

    type: DeploymentGetConfigPrefixMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: DeploymentGetConfigPrefixMessagesFunction

    thought_signature: Optional[str] = None
    r"""Encrypted representation of the model internal reasoning state during function calling. Required by Gemini 3 models when continuing a conversation after a tool call."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["thought_signature"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class PrefixMessagesAssistantMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""
    content: NotRequired[
        Nullable[
            DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyContentTypedDict
        ]
    ]
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""
    refusal: NotRequired[Nullable[str]]
    r"""The refusal message by the assistant."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""
    audio: NotRequired[Nullable[PrefixMessagesAudioTypedDict]]
    r"""Data about a previous audio response from the model."""
    tool_calls: NotRequired[List[PrefixMessagesToolCallsTypedDict]]
    r"""The tool calls generated by the model, such as function calls."""


class PrefixMessagesAssistantMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""

    content: OptionalNullable[
        DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyContent
    ] = UNSET
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""

    refusal: OptionalNullable[str] = UNSET
    r"""The refusal message by the assistant."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    audio: OptionalNullable[PrefixMessagesAudio] = UNSET
    r"""Data about a previous audio response from the model."""

    tool_calls: Optional[List[PrefixMessagesToolCalls]] = None
    r"""The tool calls generated by the model, such as function calls."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["content", "refusal", "name", "audio", "tool_calls"])
        nullable_fields = set(["content", "refusal", "audio"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


DeploymentGetConfigPrefixMessagesDeploymentsRequestRole = Literal["user",]
r"""The role of the messages author, in this case `user`."""


DeploymentGetConfig2Type = Literal["file",]
r"""The type of the content part. Always `file`."""


DeploymentGetConfig2DeploymentsType = Literal["ephemeral",]
r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""


DeploymentGetConfig2TTL = Literal[
    "5m",
    "1h",
]
r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

- `5m`: 5 minutes
- `1h`: 1 hour

Defaults to `5m`. Only supported by `Anthropic` Claude models.
"""


class DeploymentGetConfig2CacheControlTypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""
    ttl: NotRequired[DeploymentGetConfig2TTL]
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """


class DeploymentGetConfig2CacheControl(BaseModel):
    type: DeploymentGetConfig2DeploymentsType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""

    ttl: Optional[DeploymentGetConfig2TTL] = "5m"
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["ttl"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfig24TypedDict(TypedDict):
    type: DeploymentGetConfig2Type
    r"""The type of the content part. Always `file`."""
    file: FileContentPartSchemaTypedDict
    r"""File data for the content part. Must contain either file_data or uri, but not both."""
    cache_control: NotRequired[DeploymentGetConfig2CacheControlTypedDict]


class DeploymentGetConfig24(BaseModel):
    type: DeploymentGetConfig2Type
    r"""The type of the content part. Always `file`."""

    file: FileContentPartSchema
    r"""File data for the content part. Must contain either file_data or uri, but not both."""

    cache_control: Optional[DeploymentGetConfig2CacheControl] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["cache_control"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigContent2TypedDict = TypeAliasType(
    "DeploymentGetConfigContent2TypedDict",
    Union[
        AudioContentPartSchemaTypedDict,
        TextContentPartSchemaTypedDict,
        ImageContentPartSchemaTypedDict,
        DeploymentGetConfig24TypedDict,
    ],
)


DeploymentGetConfigContent2 = Annotated[
    Union[
        Annotated[TextContentPartSchema, Tag("text")],
        Annotated[ImageContentPartSchema, Tag("image_url")],
        Annotated[AudioContentPartSchema, Tag("input_audio")],
        Annotated[DeploymentGetConfig24, Tag("file")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]


DeploymentGetConfigPrefixMessagesDeploymentsRequestContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestContentTypedDict",
    Union[str, List[DeploymentGetConfigContent2TypedDict]],
)
r"""The contents of the user message."""


DeploymentGetConfigPrefixMessagesDeploymentsRequestContent = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestContent",
    Union[str, List[DeploymentGetConfigContent2]],
)
r"""The contents of the user message."""


class PrefixMessagesUserMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""
    content: DeploymentGetConfigPrefixMessagesDeploymentsRequestContentTypedDict
    r"""The contents of the user message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class PrefixMessagesUserMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""

    content: DeploymentGetConfigPrefixMessagesDeploymentsRequestContent
    r"""The contents of the user message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigPrefixMessagesDeploymentsRole = Literal["developer",]
r"""The role of the messages author, in this case  `developer`."""


DeploymentGetConfigPrefixMessagesDeploymentsContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsContentTypedDict",
    Union[str, List[TextContentPartSchemaTypedDict]],
)
r"""The contents of the developer message."""


DeploymentGetConfigPrefixMessagesDeploymentsContent = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsContent",
    Union[str, List[TextContentPartSchema]],
)
r"""The contents of the developer message."""


class PrefixMessagesDeveloperMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRole
    r"""The role of the messages author, in this case  `developer`."""
    content: DeploymentGetConfigPrefixMessagesDeploymentsContentTypedDict
    r"""The contents of the developer message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class PrefixMessagesDeveloperMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRole
    r"""The role of the messages author, in this case  `developer`."""

    content: DeploymentGetConfigPrefixMessagesDeploymentsContent
    r"""The contents of the developer message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigPrefixMessagesRole = Literal["system",]
r"""The role of the messages author, in this case `system`."""


DeploymentGetConfigPrefixMessagesContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesContentTypedDict",
    Union[str, List[TextContentPartSchemaTypedDict]],
)
r"""The contents of the system message."""


DeploymentGetConfigPrefixMessagesContent = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesContent", Union[str, List[TextContentPartSchema]]
)
r"""The contents of the system message."""


class PrefixMessagesSystemMessageTypedDict(TypedDict):
    r"""Developer-provided instructions that the model should follow, regardless of messages sent by the user."""

    role: DeploymentGetConfigPrefixMessagesRole
    r"""The role of the messages author, in this case `system`."""
    content: DeploymentGetConfigPrefixMessagesContentTypedDict
    r"""The contents of the system message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class PrefixMessagesSystemMessage(BaseModel):
    r"""Developer-provided instructions that the model should follow, regardless of messages sent by the user."""

    role: DeploymentGetConfigPrefixMessagesRole
    r"""The role of the messages author, in this case `system`."""

    content: DeploymentGetConfigPrefixMessagesContent
    r"""The contents of the system message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigPrefixMessagesTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesTypedDict",
    Union[
        PrefixMessagesSystemMessageTypedDict,
        PrefixMessagesDeveloperMessageTypedDict,
        PrefixMessagesUserMessageTypedDict,
        PrefixMessagesToolMessageTypedDict,
        PrefixMessagesAssistantMessageTypedDict,
    ],
)


DeploymentGetConfigPrefixMessages = Annotated[
    Union[
        Annotated[PrefixMessagesSystemMessage, Tag("system")],
        Annotated[PrefixMessagesDeveloperMessage, Tag("developer")],
        Annotated[PrefixMessagesUserMessage, Tag("user")],
        Annotated[PrefixMessagesAssistantMessage, Tag("assistant")],
        Annotated[PrefixMessagesToolMessage, Tag("tool")],
    ],
    Discriminator(lambda m: get_discriminator(m, "role", "role")),
]


DeploymentGetConfigMessagesDeploymentsRequestRequestBody5Role = Literal["tool",]
r"""The role of the messages author, in this case tool."""


DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages52TypedDict = (
    TextContentPartSchemaTypedDict
)


DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages52 = (
    TextContentPartSchema
)


DeploymentGetConfigMessagesDeploymentsRequestRequestBody5ContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestRequestBody5ContentTypedDict",
    Union[
        str,
        List[
            DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages52TypedDict
        ],
    ],
)
r"""The contents of the tool message."""


DeploymentGetConfigMessagesDeploymentsRequestRequestBody5Content = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestRequestBody5Content",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages52]],
)
r"""The contents of the tool message."""


DeploymentGetConfigMessagesDeploymentsType = Literal["ephemeral",]
r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""


DeploymentGetConfigMessagesTTL = Literal[
    "5m",
    "1h",
]
r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

- `5m`: 5 minutes
- `1h`: 1 hour

Defaults to `5m`. Only supported by `Anthropic` Claude models.
"""


class DeploymentGetConfigMessagesCacheControlTypedDict(TypedDict):
    type: DeploymentGetConfigMessagesDeploymentsType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""
    ttl: NotRequired[DeploymentGetConfigMessagesTTL]
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """


class DeploymentGetConfigMessagesCacheControl(BaseModel):
    type: DeploymentGetConfigMessagesDeploymentsType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""

    ttl: Optional[DeploymentGetConfigMessagesTTL] = "5m"
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["ttl"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigMessagesToolMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""
    content: DeploymentGetConfigMessagesDeploymentsRequestRequestBody5ContentTypedDict
    r"""The contents of the tool message."""
    tool_call_id: Nullable[str]
    r"""Tool call that this message is responding to."""
    cache_control: NotRequired[DeploymentGetConfigMessagesCacheControlTypedDict]


class DeploymentGetConfigMessagesToolMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""

    content: DeploymentGetConfigMessagesDeploymentsRequestRequestBody5Content
    r"""The contents of the tool message."""

    tool_call_id: Nullable[str]
    r"""Tool call that this message is responding to."""

    cache_control: Optional[DeploymentGetConfigMessagesCacheControl] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["cache_control"])
        nullable_fields = set(["tool_call_id"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages2TypedDict = (
    TypeAliasType(
        "DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages2TypedDict",
        Union[
            RefusalPartSchemaTypedDict,
            RedactedReasoningPartSchemaTypedDict,
            TextContentPartSchemaTypedDict,
            ReasoningPartSchemaTypedDict,
        ],
    )
)


DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages2 = Annotated[
    Union[
        Annotated[TextContentPartSchema, Tag("text")],
        Annotated[RefusalPartSchema, Tag("refusal")],
        Annotated[ReasoningPartSchema, Tag("reasoning")],
        Annotated[RedactedReasoningPartSchema, Tag("redacted_reasoning")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]


DeploymentGetConfigMessagesDeploymentsRequestRequestBodyContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestRequestBodyContentTypedDict",
    Union[
        str,
        List[DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages2TypedDict],
    ],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigMessagesDeploymentsRequestRequestBodyContent = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestRequestBodyContent",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequestRequestBodyMessages2]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigMessagesDeploymentsRequestRequestBodyRole = Literal["assistant",]
r"""The role of the messages author, in this case `assistant`."""


class DeploymentGetConfigMessagesAudioTypedDict(TypedDict):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


class DeploymentGetConfigMessagesAudio(BaseModel):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


DeploymentGetConfigMessagesType = Literal["function",]
r"""The type of the tool. Currently, only `function` is supported."""


class DeploymentGetConfigMessagesFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name of the function to call."""
    arguments: NotRequired[str]
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentGetConfigMessagesFunction(BaseModel):
    name: Optional[str] = None
    r"""The name of the function to call."""

    arguments: Optional[str] = None
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name", "arguments"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigMessagesToolCallsTypedDict(TypedDict):
    id: str
    r"""The ID of the tool call."""
    type: DeploymentGetConfigMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: DeploymentGetConfigMessagesFunctionTypedDict
    thought_signature: NotRequired[str]
    r"""Encrypted representation of the model internal reasoning state during function calling. Required by Gemini 3 models when continuing a conversation after a tool call."""


class DeploymentGetConfigMessagesToolCalls(BaseModel):
    id: str
    r"""The ID of the tool call."""

    type: DeploymentGetConfigMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: DeploymentGetConfigMessagesFunction

    thought_signature: Optional[str] = None
    r"""Encrypted representation of the model internal reasoning state during function calling. Required by Gemini 3 models when continuing a conversation after a tool call."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["thought_signature"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigMessagesAssistantMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""
    content: NotRequired[
        Nullable[
            DeploymentGetConfigMessagesDeploymentsRequestRequestBodyContentTypedDict
        ]
    ]
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""
    refusal: NotRequired[Nullable[str]]
    r"""The refusal message by the assistant."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""
    audio: NotRequired[Nullable[DeploymentGetConfigMessagesAudioTypedDict]]
    r"""Data about a previous audio response from the model."""
    tool_calls: NotRequired[List[DeploymentGetConfigMessagesToolCallsTypedDict]]
    r"""The tool calls generated by the model, such as function calls."""


class DeploymentGetConfigMessagesAssistantMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""

    content: OptionalNullable[
        DeploymentGetConfigMessagesDeploymentsRequestRequestBodyContent
    ] = UNSET
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""

    refusal: OptionalNullable[str] = UNSET
    r"""The refusal message by the assistant."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    audio: OptionalNullable[DeploymentGetConfigMessagesAudio] = UNSET
    r"""Data about a previous audio response from the model."""

    tool_calls: Optional[List[DeploymentGetConfigMessagesToolCalls]] = None
    r"""The tool calls generated by the model, such as function calls."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["content", "refusal", "name", "audio", "tool_calls"])
        nullable_fields = set(["content", "refusal", "audio"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


DeploymentGetConfigMessagesDeploymentsRequestRole = Literal["user",]
r"""The role of the messages author, in this case `user`."""


DeploymentGetConfig2DeploymentsRequestType = Literal["file",]
r"""The type of the content part. Always `file`."""


DeploymentGetConfig2DeploymentsRequestRequestBodyType = Literal["ephemeral",]
r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""


DeploymentGetConfig2DeploymentsTTL = Literal[
    "5m",
    "1h",
]
r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

- `5m`: 5 minutes
- `1h`: 1 hour

Defaults to `5m`. Only supported by `Anthropic` Claude models.
"""


class DeploymentGetConfig2DeploymentsCacheControlTypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""
    ttl: NotRequired[DeploymentGetConfig2DeploymentsTTL]
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """


class DeploymentGetConfig2DeploymentsCacheControl(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyType
    r"""Create a cache control breakpoint at this content block. Accepts only the value \"ephemeral\"."""

    ttl: Optional[DeploymentGetConfig2DeploymentsTTL] = "5m"
    r"""The time-to-live for the cache control breakpoint. This may be one of the following values:

    - `5m`: 5 minutes
    - `1h`: 1 hour

    Defaults to `5m`. Only supported by `Anthropic` Claude models.
    """

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["ttl"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfig2Deployments4TypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestType
    r"""The type of the content part. Always `file`."""
    file: FileContentPartSchemaTypedDict
    r"""File data for the content part. Must contain either file_data or uri, but not both."""
    cache_control: NotRequired[DeploymentGetConfig2DeploymentsCacheControlTypedDict]


class DeploymentGetConfig2Deployments4(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestType
    r"""The type of the content part. Always `file`."""

    file: FileContentPartSchema
    r"""File data for the content part. Must contain either file_data or uri, but not both."""

    cache_control: Optional[DeploymentGetConfig2DeploymentsCacheControl] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["cache_control"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigContentDeploymentsRequestRequestBody2TypedDict = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsRequestRequestBody2TypedDict",
    Union[
        AudioContentPartSchemaTypedDict,
        TextContentPartSchemaTypedDict,
        ImageContentPartSchemaTypedDict,
        DeploymentGetConfig2Deployments4TypedDict,
    ],
)


DeploymentGetConfigContentDeploymentsRequestRequestBody2 = Annotated[
    Union[
        Annotated[TextContentPartSchema, Tag("text")],
        Annotated[ImageContentPartSchema, Tag("image_url")],
        Annotated[AudioContentPartSchema, Tag("input_audio")],
        Annotated[DeploymentGetConfig2Deployments4, Tag("file")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]


DeploymentGetConfigMessagesDeploymentsRequestContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequestRequestBody2TypedDict]],
)
r"""The contents of the user message."""


DeploymentGetConfigMessagesDeploymentsRequestContent = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestContent",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequestRequestBody2]],
)
r"""The contents of the user message."""


class DeploymentGetConfigMessagesUserMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""
    content: DeploymentGetConfigMessagesDeploymentsRequestContentTypedDict
    r"""The contents of the user message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentGetConfigMessagesUserMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""

    content: DeploymentGetConfigMessagesDeploymentsRequestContent
    r"""The contents of the user message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigMessagesDeploymentsRole = Literal["developer",]
r"""The role of the messages author, in this case  `developer`."""


DeploymentGetConfigMessagesDeploymentsContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsContentTypedDict",
    Union[str, List[TextContentPartSchemaTypedDict]],
)
r"""The contents of the developer message."""


DeploymentGetConfigMessagesDeploymentsContent = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsContent",
    Union[str, List[TextContentPartSchema]],
)
r"""The contents of the developer message."""


class DeploymentGetConfigMessagesDeveloperMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRole
    r"""The role of the messages author, in this case  `developer`."""
    content: DeploymentGetConfigMessagesDeploymentsContentTypedDict
    r"""The contents of the developer message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentGetConfigMessagesDeveloperMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRole
    r"""The role of the messages author, in this case  `developer`."""

    content: DeploymentGetConfigMessagesDeploymentsContent
    r"""The contents of the developer message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigMessagesRole = Literal["system",]
r"""The role of the messages author, in this case `system`."""


DeploymentGetConfigMessagesContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesContentTypedDict",
    Union[str, List[TextContentPartSchemaTypedDict]],
)
r"""The contents of the system message."""


DeploymentGetConfigMessagesContent = TypeAliasType(
    "DeploymentGetConfigMessagesContent", Union[str, List[TextContentPartSchema]]
)
r"""The contents of the system message."""


class DeploymentGetConfigMessagesSystemMessageTypedDict(TypedDict):
    r"""Developer-provided instructions that the model should follow, regardless of messages sent by the user."""

    role: DeploymentGetConfigMessagesRole
    r"""The role of the messages author, in this case `system`."""
    content: DeploymentGetConfigMessagesContentTypedDict
    r"""The contents of the system message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentGetConfigMessagesSystemMessage(BaseModel):
    r"""Developer-provided instructions that the model should follow, regardless of messages sent by the user."""

    role: DeploymentGetConfigMessagesRole
    r"""The role of the messages author, in this case `system`."""

    content: DeploymentGetConfigMessagesContent
    r"""The contents of the system message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigMessagesTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesTypedDict",
    Union[
        DeploymentGetConfigMessagesSystemMessageTypedDict,
        DeploymentGetConfigMessagesDeveloperMessageTypedDict,
        DeploymentGetConfigMessagesUserMessageTypedDict,
        DeploymentGetConfigMessagesToolMessageTypedDict,
        DeploymentGetConfigMessagesAssistantMessageTypedDict,
    ],
)


DeploymentGetConfigMessages = Annotated[
    Union[
        Annotated[DeploymentGetConfigMessagesSystemMessage, Tag("system")],
        Annotated[DeploymentGetConfigMessagesDeveloperMessage, Tag("developer")],
        Annotated[DeploymentGetConfigMessagesUserMessage, Tag("user")],
        Annotated[DeploymentGetConfigMessagesAssistantMessage, Tag("assistant")],
        Annotated[DeploymentGetConfigMessagesToolMessage, Tag("tool")],
    ],
    Discriminator(lambda m: get_discriminator(m, "role", "role")),
]


class DeploymentGetConfigMetadataTypedDict(TypedDict):
    r"""Metadata about the document"""

    file_name: NotRequired[str]
    r"""Name of the file the text is from."""
    file_type: NotRequired[str]
    r"""Content type of the file the text is from."""
    page_number: NotRequired[float]
    r"""The page number the text is from."""


class DeploymentGetConfigMetadata(BaseModel):
    r"""Metadata about the document"""

    file_name: Optional[str] = None
    r"""Name of the file the text is from."""

    file_type: Optional[str] = None
    r"""Content type of the file the text is from."""

    page_number: Optional[float] = None
    r"""The page number the text is from."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["file_name", "file_type", "page_number"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigDocumentsTypedDict(TypedDict):
    text: str
    r"""The text content of the document"""
    metadata: NotRequired[DeploymentGetConfigMetadataTypedDict]
    r"""Metadata about the document"""


class DeploymentGetConfigDocuments(BaseModel):
    text: str
    r"""The text content of the document"""

    metadata: Optional[DeploymentGetConfigMetadata] = None
    r"""Metadata about the document"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["metadata"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigInvokeOptionsTypedDict(TypedDict):
    include_retrievals: NotRequired[bool]
    r"""Whether to include the retrieved knowledge chunks in the response."""
    include_usage: NotRequired[bool]
    r"""Whether to include the usage metrics in the response."""
    mock_response: NotRequired[str]
    r"""A mock response to use instead of calling the LLM API. This is useful for testing purposes. When provided, the system will return a response object with this content as the completion, without making an actual API call to the LLM provider. This works for both streaming and non-streaming requests. Mock responses will not generate logs, traces or be counted for your plan usage."""


class DeploymentGetConfigInvokeOptions(BaseModel):
    include_retrievals: Optional[bool] = False
    r"""Whether to include the retrieved knowledge chunks in the response."""

    include_usage: Optional[bool] = False
    r"""Whether to include the usage metrics in the response."""

    mock_response: Optional[str] = None
    r"""A mock response to use instead of calling the LLM API. This is useful for testing purposes. When provided, the system will return a response object with this content as the completion, without making an actual API call to the LLM provider. This works for both streaming and non-streaming requests. Mock responses will not generate logs, traces or be counted for your plan usage."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["include_retrievals", "include_usage", "mock_response"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigThreadTypedDict(TypedDict):
    id: str
    r"""Unique thread identifier to group related invocations."""
    tags: NotRequired[List[str]]
    r"""Optional tags to differentiate or categorize threads"""


class DeploymentGetConfigThread(BaseModel):
    id: str
    r"""Unique thread identifier to group related invocations."""

    tags: Optional[List[str]] = None
    r"""Optional tags to differentiate or categorize threads"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["tags"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigOrExistsTypedDict(TypedDict):
    r"""Exists"""

    exists: bool


class DeploymentGetConfigOrExists(BaseModel):
    r"""Exists"""

    exists: bool


DeploymentGetConfigOrDeploymentsNinTypedDict = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsNinTypedDict", Union[str, float, bool]
)


DeploymentGetConfigOrDeploymentsNin = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsNin", Union[str, float, bool]
)


class DeploymentGetConfigOrNinTypedDict(TypedDict):
    r"""Not in"""

    nin: List[DeploymentGetConfigOrDeploymentsNinTypedDict]


class DeploymentGetConfigOrNin(BaseModel):
    r"""Not in"""

    nin: List[DeploymentGetConfigOrDeploymentsNin]


DeploymentGetConfigOrDeploymentsInTypedDict = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsInTypedDict", Union[str, float, bool]
)


DeploymentGetConfigOrDeploymentsIn = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsIn", Union[str, float, bool]
)


class DeploymentGetConfigOrInTypedDict(TypedDict):
    r"""In"""

    in_: List[DeploymentGetConfigOrDeploymentsInTypedDict]


class DeploymentGetConfigOrIn(BaseModel):
    r"""In"""

    in_: Annotated[List[DeploymentGetConfigOrDeploymentsIn], pydantic.Field(alias="in")]


class DeploymentGetConfigOrLteTypedDict(TypedDict):
    r"""Less than or equal to"""

    lte: float


class DeploymentGetConfigOrLte(BaseModel):
    r"""Less than or equal to"""

    lte: float


class DeploymentGetConfigOrLtTypedDict(TypedDict):
    r"""Less than"""

    lt: float


class DeploymentGetConfigOrLt(BaseModel):
    r"""Less than"""

    lt: float


class DeploymentGetConfigOrGteTypedDict(TypedDict):
    r"""Greater than or equal to"""

    gte: float


class DeploymentGetConfigOrGte(BaseModel):
    r"""Greater than or equal to"""

    gte: float


class DeploymentGetConfigOrGtTypedDict(TypedDict):
    r"""Greater than"""

    gt: float


class DeploymentGetConfigOrGt(BaseModel):
    r"""Greater than"""

    gt: float


DeploymentGetConfigOrDeploymentsNeTypedDict = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsNeTypedDict", Union[str, float, bool]
)


DeploymentGetConfigOrDeploymentsNe = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsNe", Union[str, float, bool]
)


class DeploymentGetConfigOrNeTypedDict(TypedDict):
    r"""Not equal to"""

    ne: DeploymentGetConfigOrDeploymentsNeTypedDict


class DeploymentGetConfigOrNe(BaseModel):
    r"""Not equal to"""

    ne: DeploymentGetConfigOrDeploymentsNe


DeploymentGetConfigOrDeploymentsEqTypedDict = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsEqTypedDict", Union[str, float, bool]
)


DeploymentGetConfigOrDeploymentsEq = TypeAliasType(
    "DeploymentGetConfigOrDeploymentsEq", Union[str, float, bool]
)


class DeploymentGetConfigOrEqTypedDict(TypedDict):
    r"""Equal to"""

    eq: DeploymentGetConfigOrDeploymentsEqTypedDict


class DeploymentGetConfigOrEq(BaseModel):
    r"""Equal to"""

    eq: DeploymentGetConfigOrDeploymentsEq


class DeploymentGetConfigKnowledgeFilterOrTypedDict(TypedDict):
    r"""Or"""

    or_: List[Dict[str, DeploymentGetConfigKnowledgeFilterDeploymentsOrTypedDict]]


class DeploymentGetConfigKnowledgeFilterOr(BaseModel):
    r"""Or"""

    or_: Annotated[
        List[Dict[str, DeploymentGetConfigKnowledgeFilterDeploymentsOr]],
        pydantic.Field(alias="or"),
    ]


class DeploymentGetConfigAndExistsTypedDict(TypedDict):
    r"""Exists"""

    exists: bool


class DeploymentGetConfigAndExists(BaseModel):
    r"""Exists"""

    exists: bool


DeploymentGetConfigAndDeploymentsNinTypedDict = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsNinTypedDict", Union[str, float, bool]
)


DeploymentGetConfigAndDeploymentsNin = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsNin", Union[str, float, bool]
)


class DeploymentGetConfigAndNinTypedDict(TypedDict):
    r"""Not in"""

    nin: List[DeploymentGetConfigAndDeploymentsNinTypedDict]


class DeploymentGetConfigAndNin(BaseModel):
    r"""Not in"""

    nin: List[DeploymentGetConfigAndDeploymentsNin]


DeploymentGetConfigAndDeploymentsInTypedDict = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsInTypedDict", Union[str, float, bool]
)


DeploymentGetConfigAndDeploymentsIn = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsIn", Union[str, float, bool]
)


class DeploymentGetConfigAndInTypedDict(TypedDict):
    r"""In"""

    in_: List[DeploymentGetConfigAndDeploymentsInTypedDict]


class DeploymentGetConfigAndIn(BaseModel):
    r"""In"""

    in_: Annotated[
        List[DeploymentGetConfigAndDeploymentsIn], pydantic.Field(alias="in")
    ]


class DeploymentGetConfigAndLteTypedDict(TypedDict):
    r"""Less than or equal to"""

    lte: float


class DeploymentGetConfigAndLte(BaseModel):
    r"""Less than or equal to"""

    lte: float


class DeploymentGetConfigAndLtTypedDict(TypedDict):
    r"""Less than"""

    lt: float


class DeploymentGetConfigAndLt(BaseModel):
    r"""Less than"""

    lt: float


class DeploymentGetConfigAndGteTypedDict(TypedDict):
    r"""Greater than or equal to"""

    gte: float


class DeploymentGetConfigAndGte(BaseModel):
    r"""Greater than or equal to"""

    gte: float


class DeploymentGetConfigAndGtTypedDict(TypedDict):
    r"""Greater than"""

    gt: float


class DeploymentGetConfigAndGt(BaseModel):
    r"""Greater than"""

    gt: float


DeploymentGetConfigAndDeploymentsNeTypedDict = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsNeTypedDict", Union[str, float, bool]
)


DeploymentGetConfigAndDeploymentsNe = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsNe", Union[str, float, bool]
)


class DeploymentGetConfigAndNeTypedDict(TypedDict):
    r"""Not equal to"""

    ne: DeploymentGetConfigAndDeploymentsNeTypedDict


class DeploymentGetConfigAndNe(BaseModel):
    r"""Not equal to"""

    ne: DeploymentGetConfigAndDeploymentsNe


DeploymentGetConfigAndDeploymentsEqTypedDict = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsEqTypedDict", Union[str, float, bool]
)


DeploymentGetConfigAndDeploymentsEq = TypeAliasType(
    "DeploymentGetConfigAndDeploymentsEq", Union[str, float, bool]
)


class DeploymentGetConfigAndEqTypedDict(TypedDict):
    r"""Equal to"""

    eq: DeploymentGetConfigAndDeploymentsEqTypedDict


class DeploymentGetConfigAndEq(BaseModel):
    r"""Equal to"""

    eq: DeploymentGetConfigAndDeploymentsEq


DeploymentGetConfigKnowledgeFilterDeploymentsAndTypedDict = TypeAliasType(
    "DeploymentGetConfigKnowledgeFilterDeploymentsAndTypedDict",
    Union[
        DeploymentGetConfigAndEqTypedDict,
        DeploymentGetConfigAndNeTypedDict,
        DeploymentGetConfigAndGtTypedDict,
        DeploymentGetConfigAndGteTypedDict,
        DeploymentGetConfigAndLtTypedDict,
        DeploymentGetConfigAndLteTypedDict,
        DeploymentGetConfigAndInTypedDict,
        DeploymentGetConfigAndNinTypedDict,
        DeploymentGetConfigAndExistsTypedDict,
    ],
)


DeploymentGetConfigKnowledgeFilterDeploymentsAnd = TypeAliasType(
    "DeploymentGetConfigKnowledgeFilterDeploymentsAnd",
    Union[
        DeploymentGetConfigAndEq,
        DeploymentGetConfigAndNe,
        DeploymentGetConfigAndGt,
        DeploymentGetConfigAndGte,
        DeploymentGetConfigAndLt,
        DeploymentGetConfigAndLte,
        DeploymentGetConfigAndIn,
        DeploymentGetConfigAndNin,
        DeploymentGetConfigAndExists,
    ],
)


class DeploymentGetConfigKnowledgeFilterAndTypedDict(TypedDict):
    r"""And"""

    and_: List[Dict[str, DeploymentGetConfigKnowledgeFilterDeploymentsAndTypedDict]]


class DeploymentGetConfigKnowledgeFilterAnd(BaseModel):
    r"""And"""

    and_: Annotated[
        List[Dict[str, DeploymentGetConfigKnowledgeFilterDeploymentsAnd]],
        pydantic.Field(alias="and"),
    ]


class OneExistsTypedDict(TypedDict):
    r"""Exists"""

    exists: bool


class OneExists(BaseModel):
    r"""Exists"""

    exists: bool


DeploymentGetConfig1DeploymentsNinTypedDict = TypeAliasType(
    "DeploymentGetConfig1DeploymentsNinTypedDict", Union[str, float, bool]
)


DeploymentGetConfig1DeploymentsNin = TypeAliasType(
    "DeploymentGetConfig1DeploymentsNin", Union[str, float, bool]
)


class DeploymentGetConfig1NinTypedDict(TypedDict):
    r"""Not in"""

    nin: List[DeploymentGetConfig1DeploymentsNinTypedDict]


class DeploymentGetConfig1Nin(BaseModel):
    r"""Not in"""

    nin: List[DeploymentGetConfig1DeploymentsNin]


DeploymentGetConfig1DeploymentsInTypedDict = TypeAliasType(
    "DeploymentGetConfig1DeploymentsInTypedDict", Union[str, float, bool]
)


DeploymentGetConfig1DeploymentsIn = TypeAliasType(
    "DeploymentGetConfig1DeploymentsIn", Union[str, float, bool]
)


class DeploymentGetConfig1InTypedDict(TypedDict):
    r"""In"""

    in_: List[DeploymentGetConfig1DeploymentsInTypedDict]


class DeploymentGetConfig1In(BaseModel):
    r"""In"""

    in_: Annotated[List[DeploymentGetConfig1DeploymentsIn], pydantic.Field(alias="in")]


class OneLteTypedDict(TypedDict):
    r"""Less than or equal to"""

    lte: float


class OneLte(BaseModel):
    r"""Less than or equal to"""

    lte: float


class OneLtTypedDict(TypedDict):
    r"""Less than"""

    lt: float


class OneLt(BaseModel):
    r"""Less than"""

    lt: float


class OneGteTypedDict(TypedDict):
    r"""Greater than or equal to"""

    gte: float


class OneGte(BaseModel):
    r"""Greater than or equal to"""

    gte: float


class OneGtTypedDict(TypedDict):
    r"""Greater than"""

    gt: float


class OneGt(BaseModel):
    r"""Greater than"""

    gt: float


DeploymentGetConfig1DeploymentsNeTypedDict = TypeAliasType(
    "DeploymentGetConfig1DeploymentsNeTypedDict", Union[str, float, bool]
)


DeploymentGetConfig1DeploymentsNe = TypeAliasType(
    "DeploymentGetConfig1DeploymentsNe", Union[str, float, bool]
)


class DeploymentGetConfig1NeTypedDict(TypedDict):
    r"""Not equal to"""

    ne: DeploymentGetConfig1DeploymentsNeTypedDict


class DeploymentGetConfig1Ne(BaseModel):
    r"""Not equal to"""

    ne: DeploymentGetConfig1DeploymentsNe


DeploymentGetConfig1DeploymentsEqTypedDict = TypeAliasType(
    "DeploymentGetConfig1DeploymentsEqTypedDict", Union[str, float, bool]
)


DeploymentGetConfig1DeploymentsEq = TypeAliasType(
    "DeploymentGetConfig1DeploymentsEq", Union[str, float, bool]
)


class DeploymentGetConfig1EqTypedDict(TypedDict):
    r"""Equal to"""

    eq: DeploymentGetConfig1DeploymentsEqTypedDict


class DeploymentGetConfig1Eq(BaseModel):
    r"""Equal to"""

    eq: DeploymentGetConfig1DeploymentsEq


DeploymentGetConfigKnowledgeFilterDeploymentsOrTypedDict = TypeAliasType(
    "DeploymentGetConfigKnowledgeFilterDeploymentsOrTypedDict",
    Union[
        DeploymentGetConfigOrEqTypedDict,
        DeploymentGetConfigOrNeTypedDict,
        DeploymentGetConfigOrGtTypedDict,
        DeploymentGetConfigOrGteTypedDict,
        DeploymentGetConfigOrLtTypedDict,
        DeploymentGetConfigOrLteTypedDict,
        DeploymentGetConfigOrInTypedDict,
        DeploymentGetConfigOrNinTypedDict,
        DeploymentGetConfigOrExistsTypedDict,
    ],
)


DeploymentGetConfigKnowledgeFilterDeploymentsOr = TypeAliasType(
    "DeploymentGetConfigKnowledgeFilterDeploymentsOr",
    Union[
        DeploymentGetConfigOrEq,
        DeploymentGetConfigOrNe,
        DeploymentGetConfigOrGt,
        DeploymentGetConfigOrGte,
        DeploymentGetConfigOrLt,
        DeploymentGetConfigOrLte,
        DeploymentGetConfigOrIn,
        DeploymentGetConfigOrNin,
        DeploymentGetConfigOrExists,
    ],
)


KnowledgeFilter1TypedDict = TypeAliasType(
    "KnowledgeFilter1TypedDict",
    Union[
        DeploymentGetConfig1EqTypedDict,
        DeploymentGetConfig1NeTypedDict,
        OneGtTypedDict,
        OneGteTypedDict,
        OneLtTypedDict,
        OneLteTypedDict,
        DeploymentGetConfig1InTypedDict,
        DeploymentGetConfig1NinTypedDict,
        OneExistsTypedDict,
    ],
)


KnowledgeFilter1 = TypeAliasType(
    "KnowledgeFilter1",
    Union[
        DeploymentGetConfig1Eq,
        DeploymentGetConfig1Ne,
        OneGt,
        OneGte,
        OneLt,
        OneLte,
        DeploymentGetConfig1In,
        DeploymentGetConfig1Nin,
        OneExists,
    ],
)


DeploymentGetConfigKnowledgeFilterTypedDict = TypeAliasType(
    "DeploymentGetConfigKnowledgeFilterTypedDict",
    Union[
        DeploymentGetConfigKnowledgeFilterAndTypedDict,
        DeploymentGetConfigKnowledgeFilterOrTypedDict,
        Dict[str, KnowledgeFilter1TypedDict],
    ],
)
r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""


DeploymentGetConfigKnowledgeFilter = TypeAliasType(
    "DeploymentGetConfigKnowledgeFilter",
    Union[
        DeploymentGetConfigKnowledgeFilterAnd,
        DeploymentGetConfigKnowledgeFilterOr,
        Dict[str, KnowledgeFilter1],
    ],
)
r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""


class DeploymentGetConfigRequestBodyTypedDict(TypedDict):
    key: str
    r"""The deployment key to invoke"""
    inputs: NotRequired[Dict[str, Any]]
    r"""Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used."""
    context: NotRequired[Dict[str, Any]]
    r"""Key-value pairs that match your data model and fields declared in your deployment routing configuration"""
    prefix_messages: NotRequired[List[DeploymentGetConfigPrefixMessagesTypedDict]]
    r"""A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment."""
    messages: NotRequired[List[DeploymentGetConfigMessagesTypedDict]]
    r"""A list of messages to send to the deployment."""
    file_ids: NotRequired[List[str]]
    r"""A list of file IDs that are associated with the deployment request."""
    metadata: NotRequired[Dict[str, Any]]
    r"""Key-value pairs that you want to attach to the log generated by this request."""
    extra_params: NotRequired[Dict[str, Any]]
    r"""Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration."""
    documents: NotRequired[List[DeploymentGetConfigDocumentsTypedDict]]
    r"""A list of documents from your external knowledge base (e.g., chunks retrieved from your own vector database or RAG pipeline) that provide context for the model response. These documents can be used by evaluators and guardrails to assess the relevance and accuracy of the model output against the provided context."""
    invoke_options: NotRequired[DeploymentGetConfigInvokeOptionsTypedDict]
    thread: NotRequired[DeploymentGetConfigThreadTypedDict]
    knowledge_filter: NotRequired[DeploymentGetConfigKnowledgeFilterTypedDict]
    r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""


class DeploymentGetConfigRequestBody(BaseModel):
    key: str
    r"""The deployment key to invoke"""

    inputs: Optional[Dict[str, Any]] = None
    r"""Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used."""

    context: Optional[Dict[str, Any]] = None
    r"""Key-value pairs that match your data model and fields declared in your deployment routing configuration"""

    prefix_messages: Optional[List[DeploymentGetConfigPrefixMessages]] = None
    r"""A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment."""

    messages: Optional[List[DeploymentGetConfigMessages]] = None
    r"""A list of messages to send to the deployment."""

    file_ids: Optional[List[str]] = None
    r"""A list of file IDs that are associated with the deployment request."""

    metadata: Optional[Dict[str, Any]] = None
    r"""Key-value pairs that you want to attach to the log generated by this request."""

    extra_params: Optional[Dict[str, Any]] = None
    r"""Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration."""

    documents: Optional[List[DeploymentGetConfigDocuments]] = None
    r"""A list of documents from your external knowledge base (e.g., chunks retrieved from your own vector database or RAG pipeline) that provide context for the model response. These documents can be used by evaluators and guardrails to assess the relevance and accuracy of the model output against the provided context."""

    invoke_options: Optional[DeploymentGetConfigInvokeOptions] = None

    thread: Optional[DeploymentGetConfigThread] = None

    knowledge_filter: Optional[DeploymentGetConfigKnowledgeFilter] = None
    r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "inputs",
                "context",
                "prefix_messages",
                "messages",
                "file_ids",
                "metadata",
                "extra_params",
                "documents",
                "invoke_options",
                "thread",
                "knowledge_filter",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigType = Literal[
    "chat",
    "completion",
    "embedding",
    "image",
    "tts",
    "stt",
    "rerank",
    "moderation",
    "vision",
]
r"""The type of the model. Current `chat`,`completion` and `image` are supported"""


DeploymentGetConfigRole = Literal[
    "system",
    "assistant",
    "user",
    "exception",
    "tool",
    "prompt",
    "correction",
    "expected_output",
]
r"""The role of the prompt message"""


DeploymentGetConfig2DeploymentsResponse200ApplicationJSONType = Literal["file",]
r"""The type of the content part. Always `file`."""


class DeploymentGetConfig2FileTypedDict(TypedDict):
    file_data: NotRequired[str]
    r"""The file data as a data URI string in the format 'data:<mime-type>;base64,<base64-encoded-data>'. Example: 'data:image/png;base64,iVBORw0KGgoAAAANS...'"""
    uri: NotRequired[str]
    r"""URL to the file. Only supported by Anthropic Claude models for PDF files."""
    mime_type: NotRequired[str]
    r"""MIME type of the file (e.g., application/pdf, image/png)"""
    filename: NotRequired[str]
    r"""The name of the file, used when passing the file to the model as a string."""


class DeploymentGetConfig2File(BaseModel):
    file_data: Optional[str] = None
    r"""The file data as a data URI string in the format 'data:<mime-type>;base64,<base64-encoded-data>'. Example: 'data:image/png;base64,iVBORw0KGgoAAAANS...'"""

    uri: Optional[str] = None
    r"""URL to the file. Only supported by Anthropic Claude models for PDF files."""

    mime_type: Annotated[Optional[str], pydantic.Field(alias="mimeType")] = None
    r"""MIME type of the file (e.g., application/pdf, image/png)"""

    filename: Optional[str] = None
    r"""The name of the file, used when passing the file to the model as a string."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["file_data", "uri", "mimeType", "filename"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfig23TypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsResponse200ApplicationJSONType
    r"""The type of the content part. Always `file`."""
    file: DeploymentGetConfig2FileTypedDict


class DeploymentGetConfig23(BaseModel):
    type: DeploymentGetConfig2DeploymentsResponse200ApplicationJSONType
    r"""The type of the content part. Always `file`."""

    file: DeploymentGetConfig2File


DeploymentGetConfig2DeploymentsResponse200Type = Literal["image_url",]


class DeploymentGetConfig2ImageURLTypedDict(TypedDict):
    url: str
    r"""Either a URL of the image or the base64 encoded data URI."""
    id: NotRequired[str]
    r"""The orq.ai id of the image"""
    detail: NotRequired[str]
    r"""Specifies the detail level of the image. Currently only supported with OpenAI models"""


class DeploymentGetConfig2ImageURL(BaseModel):
    url: str
    r"""Either a URL of the image or the base64 encoded data URI."""

    id: Optional[str] = None
    r"""The orq.ai id of the image"""

    detail: Optional[str] = None
    r"""Specifies the detail level of the image. Currently only supported with OpenAI models"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["id", "detail"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfig22TypedDict(TypedDict):
    r"""The image part of the prompt message. Only supported with vision models."""

    type: DeploymentGetConfig2DeploymentsResponse200Type
    image_url: DeploymentGetConfig2ImageURLTypedDict


class DeploymentGetConfig22(BaseModel):
    r"""The image part of the prompt message. Only supported with vision models."""

    type: DeploymentGetConfig2DeploymentsResponse200Type

    image_url: DeploymentGetConfig2ImageURL


DeploymentGetConfig2DeploymentsResponseType = Literal["text",]


class DeploymentGetConfig21TypedDict(TypedDict):
    r"""Text content part of a prompt message"""

    type: DeploymentGetConfig2DeploymentsResponseType
    text: str


class DeploymentGetConfig21(BaseModel):
    r"""Text content part of a prompt message"""

    type: DeploymentGetConfig2DeploymentsResponseType

    text: str


DeploymentGetConfigContentDeploymentsResponse2TypedDict = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsResponse2TypedDict",
    Union[
        DeploymentGetConfig21TypedDict,
        DeploymentGetConfig22TypedDict,
        DeploymentGetConfig23TypedDict,
    ],
)


DeploymentGetConfigContentDeploymentsResponse2 = Annotated[
    Union[
        Annotated[DeploymentGetConfig21, Tag("text")],
        Annotated[DeploymentGetConfig22, Tag("image_url")],
        Annotated[DeploymentGetConfig23, Tag("file")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]


DeploymentGetConfigContentTypedDict = TypeAliasType(
    "DeploymentGetConfigContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeploymentsResponse2TypedDict]],
)
r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Can be null for tool messages in certain scenarios."""


DeploymentGetConfigContent = TypeAliasType(
    "DeploymentGetConfigContent",
    Union[str, List[DeploymentGetConfigContentDeploymentsResponse2]],
)
r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Can be null for tool messages in certain scenarios."""


DeploymentGetConfigDeploymentsResponseType = Literal["function",]


class DeploymentGetConfigDeploymentsFunctionTypedDict(TypedDict):
    name: str
    arguments: str
    r"""JSON string arguments for the functions"""


class DeploymentGetConfigDeploymentsFunction(BaseModel):
    name: str

    arguments: str
    r"""JSON string arguments for the functions"""


class DeploymentGetConfigToolCallsTypedDict(TypedDict):
    type: DeploymentGetConfigDeploymentsResponseType
    function: DeploymentGetConfigDeploymentsFunctionTypedDict
    id: NotRequired[str]
    index: NotRequired[float]


class DeploymentGetConfigToolCalls(BaseModel):
    type: DeploymentGetConfigDeploymentsResponseType

    function: DeploymentGetConfigDeploymentsFunction

    id: Optional[str] = None

    index: Optional[float] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["id", "index"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigDeploymentsMessagesTypedDict(TypedDict):
    role: DeploymentGetConfigRole
    r"""The role of the prompt message"""
    content: Nullable[DeploymentGetConfigContentTypedDict]
    r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Can be null for tool messages in certain scenarios."""
    tool_calls: NotRequired[List[DeploymentGetConfigToolCallsTypedDict]]
    tool_call_id: NotRequired[Nullable[str]]


class DeploymentGetConfigDeploymentsMessages(BaseModel):
    role: DeploymentGetConfigRole
    r"""The role of the prompt message"""

    content: Nullable[DeploymentGetConfigContent]
    r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Can be null for tool messages in certain scenarios."""

    tool_calls: Optional[List[DeploymentGetConfigToolCalls]] = None

    tool_call_id: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["tool_calls", "tool_call_id"])
        nullable_fields = set(["content", "tool_call_id"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


DeploymentGetConfigFormat = Literal[
    "url",
    "b64_json",
    "text",
    "json_object",
]
r"""Only supported on `image` models."""


ResponseFormat6 = Literal[
    "json",
    "text",
    "srt",
    "verbose_json",
    "vtt",
]


ResponseFormat5 = Literal[
    "url",
    "base64_json",
]


ResponseFormat4 = Literal[
    "mp3",
    "opus",
    "aac",
    "flac",
    "wav",
    "pcm",
]


DeploymentGetConfigResponseFormatDeploymentsType = Literal["text",]


class ResponseFormat3TypedDict(TypedDict):
    type: DeploymentGetConfigResponseFormatDeploymentsType


class ResponseFormat3(BaseModel):
    type: DeploymentGetConfigResponseFormatDeploymentsType


DeploymentGetConfigResponseFormatType = Literal["json_object",]


class ResponseFormat2TypedDict(TypedDict):
    type: DeploymentGetConfigResponseFormatType


class ResponseFormat2(BaseModel):
    type: DeploymentGetConfigResponseFormatType


DeploymentGetConfigResponseFormatDeploymentsResponseType = Literal["json_schema",]


class DeploymentGetConfigResponseFormatJSONSchemaTypedDict(TypedDict):
    name: str
    schema_: Dict[str, Any]
    description: NotRequired[str]
    strict: NotRequired[bool]


class DeploymentGetConfigResponseFormatJSONSchema(BaseModel):
    name: str

    schema_: Annotated[Dict[str, Any], pydantic.Field(alias="schema")]

    description: Optional[str] = None

    strict: Optional[bool] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["description", "strict"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class ResponseFormat1TypedDict(TypedDict):
    type: DeploymentGetConfigResponseFormatDeploymentsResponseType
    json_schema: DeploymentGetConfigResponseFormatJSONSchemaTypedDict
    display_name: NotRequired[str]


class ResponseFormat1(BaseModel):
    type: DeploymentGetConfigResponseFormatDeploymentsResponseType

    json_schema: DeploymentGetConfigResponseFormatJSONSchema

    display_name: Optional[str] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["display_name"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


DeploymentGetConfigResponseFormatTypedDict = TypeAliasType(
    "DeploymentGetConfigResponseFormatTypedDict",
    Union[
        ResponseFormat2TypedDict,
        ResponseFormat3TypedDict,
        ResponseFormat1TypedDict,
        ResponseFormat4,
        ResponseFormat5,
        ResponseFormat6,
    ],
)
r"""An object specifying the format that the model must output.

Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
"""


DeploymentGetConfigResponseFormat = TypeAliasType(
    "DeploymentGetConfigResponseFormat",
    Union[
        ResponseFormat2,
        ResponseFormat3,
        ResponseFormat1,
        ResponseFormat4,
        ResponseFormat5,
        ResponseFormat6,
    ],
)
r"""An object specifying the format that the model must output.

Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
"""


PhotoRealVersion = Literal[
    "v1",
    "v2",
]
r"""The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider"""


DeploymentGetConfigEncodingFormat = Literal[
    "float",
    "base64",
]
r"""The format to return the embeddings"""


DeploymentGetConfigReasoningEffort = Literal[
    "none",
    "disable",
    "minimal",
    "low",
    "medium",
    "high",
]
r"""Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."""


Verbosity = Literal[
    "low",
    "medium",
    "high",
]
r"""Controls the verbosity of the model output."""


DeploymentGetConfigThinkingLevel = Literal[
    "low",
    "high",
]
r"""The level of thinking to use for the model. Only supported by `Google AI`"""


class DeploymentGetConfigParametersTypedDict(TypedDict):
    r"""Model Parameters: Not all parameters apply to every model"""

    temperature: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    max_tokens: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    top_k: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    top_p: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    frequency_penalty: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    presence_penalty: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    num_images: NotRequired[float]
    r"""Only supported on `image` models."""
    seed: NotRequired[float]
    r"""Best effort deterministic seed for the model. Currently only OpenAI models support these"""
    format_: NotRequired[DeploymentGetConfigFormat]
    r"""Only supported on `image` models."""
    dimensions: NotRequired[str]
    r"""Only supported on `image` models."""
    quality: NotRequired[str]
    r"""Only supported on `image` models."""
    style: NotRequired[str]
    r"""Only supported on `image` models."""
    response_format: NotRequired[Nullable[DeploymentGetConfigResponseFormatTypedDict]]
    r"""An object specifying the format that the model must output.

    Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

    Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

    Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
    """
    photo_real_version: NotRequired[PhotoRealVersion]
    r"""The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider"""
    encoding_format: NotRequired[DeploymentGetConfigEncodingFormat]
    r"""The format to return the embeddings"""
    reasoning_effort: NotRequired[DeploymentGetConfigReasoningEffort]
    r"""Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."""
    budget_tokens: NotRequired[float]
    r"""Gives the model enhanced reasoning capabilities for complex tasks. A value of 0 disables thinking. The minimum budget tokens for thinking are 1024. The Budget Tokens should never exceed the Max Tokens parameter. Only supported by `Anthropic`"""
    verbosity: NotRequired[Verbosity]
    r"""Controls the verbosity of the model output."""
    thinking_level: NotRequired[DeploymentGetConfigThinkingLevel]
    r"""The level of thinking to use for the model. Only supported by `Google AI`"""


class DeploymentGetConfigParameters(BaseModel):
    r"""Model Parameters: Not all parameters apply to every model"""

    temperature: Optional[float] = None
    r"""Only supported on `chat` and `completion` models."""

    max_tokens: Annotated[Optional[float], pydantic.Field(alias="maxTokens")] = None
    r"""Only supported on `chat` and `completion` models."""

    top_k: Annotated[Optional[float], pydantic.Field(alias="topK")] = None
    r"""Only supported on `chat` and `completion` models."""

    top_p: Annotated[Optional[float], pydantic.Field(alias="topP")] = None
    r"""Only supported on `chat` and `completion` models."""

    frequency_penalty: Annotated[
        Optional[float], pydantic.Field(alias="frequencyPenalty")
    ] = None
    r"""Only supported on `chat` and `completion` models."""

    presence_penalty: Annotated[
        Optional[float], pydantic.Field(alias="presencePenalty")
    ] = None
    r"""Only supported on `chat` and `completion` models."""

    num_images: Annotated[Optional[float], pydantic.Field(alias="numImages")] = None
    r"""Only supported on `image` models."""

    seed: Optional[float] = None
    r"""Best effort deterministic seed for the model. Currently only OpenAI models support these"""

    format_: Annotated[
        Optional[DeploymentGetConfigFormat], pydantic.Field(alias="format")
    ] = None
    r"""Only supported on `image` models."""

    dimensions: Optional[str] = None
    r"""Only supported on `image` models."""

    quality: Optional[str] = None
    r"""Only supported on `image` models."""

    style: Optional[str] = None
    r"""Only supported on `image` models."""

    response_format: Annotated[
        OptionalNullable[DeploymentGetConfigResponseFormat],
        pydantic.Field(alias="responseFormat"),
    ] = UNSET
    r"""An object specifying the format that the model must output.

    Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

    Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

    Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
    """

    photo_real_version: Annotated[
        Optional[PhotoRealVersion], pydantic.Field(alias="photoRealVersion")
    ] = None
    r"""The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider"""

    encoding_format: Optional[DeploymentGetConfigEncodingFormat] = None
    r"""The format to return the embeddings"""

    reasoning_effort: Annotated[
        Optional[DeploymentGetConfigReasoningEffort],
        pydantic.Field(alias="reasoningEffort"),
    ] = None
    r"""Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."""

    budget_tokens: Annotated[Optional[float], pydantic.Field(alias="budgetTokens")] = (
        None
    )
    r"""Gives the model enhanced reasoning capabilities for complex tasks. A value of 0 disables thinking. The minimum budget tokens for thinking are 1024. The Budget Tokens should never exceed the Max Tokens parameter. Only supported by `Anthropic`"""

    verbosity: Optional[Verbosity] = None
    r"""Controls the verbosity of the model output."""

    thinking_level: Annotated[
        Optional[DeploymentGetConfigThinkingLevel],
        pydantic.Field(alias="thinkingLevel"),
    ] = None
    r"""The level of thinking to use for the model. Only supported by `Google AI`"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "temperature",
                "maxTokens",
                "topK",
                "topP",
                "frequencyPenalty",
                "presencePenalty",
                "numImages",
                "seed",
                "format",
                "dimensions",
                "quality",
                "style",
                "responseFormat",
                "photoRealVersion",
                "encoding_format",
                "reasoningEffort",
                "budgetTokens",
                "verbosity",
                "thinkingLevel",
            ]
        )
        nullable_fields = set(["responseFormat"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


DeploymentGetConfigDeploymentsType = Literal["function",]
r"""The type of the tool. Currently, only `function` is supported."""


class DeploymentGetConfigFunctionTypedDict(TypedDict):
    name: str
    r"""The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."""
    description: NotRequired[str]
    r"""A description of what the function does, used by the model to choose when and how to call the function."""
    parameters: NotRequired[Dict[str, Any]]
    r"""The parameters the functions accepts, described as a JSON Schema object.

    Omitting `parameters` defines a function with an empty parameter list.
    """


class DeploymentGetConfigFunction(BaseModel):
    name: str
    r"""The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."""

    description: Optional[str] = None
    r"""A description of what the function does, used by the model to choose when and how to call the function."""

    parameters: Optional[Dict[str, Any]] = None
    r"""The parameters the functions accepts, described as a JSON Schema object.

    Omitting `parameters` defines a function with an empty parameter list.
    """

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["description", "parameters"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DeploymentGetConfigToolsTypedDict(TypedDict):
    type: DeploymentGetConfigDeploymentsType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: DeploymentGetConfigFunctionTypedDict


class DeploymentGetConfigTools(BaseModel):
    type: DeploymentGetConfigDeploymentsType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: DeploymentGetConfigFunction


class DeploymentGetConfigResponseBodyTypedDict(TypedDict):
    r"""The deployment configuration"""

    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""
    provider: str
    r"""The provider of the model"""
    model: str
    r"""The model of the configuration"""
    version: str
    r"""The current version of the deployment"""
    messages: List[DeploymentGetConfigDeploymentsMessagesTypedDict]
    parameters: DeploymentGetConfigParametersTypedDict
    r"""Model Parameters: Not all parameters apply to every model"""
    type: NotRequired[DeploymentGetConfigType]
    r"""The type of the model. Current `chat`,`completion` and `image` are supported"""
    tools: NotRequired[List[DeploymentGetConfigToolsTypedDict]]
    r"""A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for."""


class DeploymentGetConfigResponseBody(BaseModel):
    r"""The deployment configuration"""

    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""

    provider: str
    r"""The provider of the model"""

    model: str
    r"""The model of the configuration"""

    version: str
    r"""The current version of the deployment"""

    messages: List[DeploymentGetConfigDeploymentsMessages]

    parameters: DeploymentGetConfigParameters
    r"""Model Parameters: Not all parameters apply to every model"""

    type: Optional[DeploymentGetConfigType] = None
    r"""The type of the model. Current `chat`,`completion` and `image` are supported"""

    tools: Optional[List[DeploymentGetConfigTools]] = None
    r"""A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["type", "tools"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
