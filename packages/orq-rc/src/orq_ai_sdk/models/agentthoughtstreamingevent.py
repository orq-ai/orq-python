"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .datapart import DataPart, DataPartTypedDict
from .filepart import FilePart, FilePartTypedDict
from .textpart import TextPart, TextPartTypedDict
from .toolcallpart import ToolCallPart, ToolCallPartTypedDict
from .toolresultpart import ToolResultPart, ToolResultPartTypedDict
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from orq_ai_sdk.utils import get_discriminator
import pydantic
from pydantic import Discriminator, Tag, model_serializer
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


AgentThoughtStreamingEventType = Literal["event.agents.thought",]


AgentThoughtStreamingEventRole = Literal[
    "user",
    "agent",
    "tool",
    "system",
]


AgentThoughtStreamingEventPartsTypedDict = TypeAliasType(
    "AgentThoughtStreamingEventPartsTypedDict",
    Union[
        TextPartTypedDict,
        DataPartTypedDict,
        FilePartTypedDict,
        ToolResultPartTypedDict,
        ToolCallPartTypedDict,
    ],
)


AgentThoughtStreamingEventParts = Annotated[
    Union[
        Annotated[TextPart, Tag("text")],
        Annotated[DataPart, Tag("data")],
        Annotated[FilePart, Tag("file")],
        Annotated[ToolCallPart, Tag("tool_call")],
        Annotated[ToolResultPart, Tag("tool_result")],
    ],
    Discriminator(lambda m: get_discriminator(m, "kind", "kind")),
]


class MessageDifferenceTypedDict(TypedDict):
    message_id: str
    role: AgentThoughtStreamingEventRole
    parts: List[AgentThoughtStreamingEventPartsTypedDict]
    agent_id: str
    agent_execution_id: str
    workspace_id: str
    metadata: NotRequired[Dict[str, Any]]


class MessageDifference(BaseModel):
    message_id: Annotated[str, pydantic.Field(alias="messageId")]

    role: AgentThoughtStreamingEventRole

    parts: List[AgentThoughtStreamingEventParts]

    agent_id: str

    agent_execution_id: str

    workspace_id: str

    metadata: Optional[Dict[str, Any]] = None


AgentThoughtStreamingEventFinishReason = Literal[
    "stop",
    "length",
    "tool_calls",
    "content_filter",
    "function_call",
]
r"""The reason the model stopped generating tokens."""


AgentThoughtStreamingEventDataType = Literal["function",]


class AgentThoughtStreamingEventFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."""
    arguments: NotRequired[str]
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class AgentThoughtStreamingEventFunction(BaseModel):
    name: Optional[str] = None
    r"""The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."""

    arguments: Optional[str] = None
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class AgentThoughtStreamingEventToolCallsTypedDict(TypedDict):
    id: NotRequired[str]
    type: NotRequired[AgentThoughtStreamingEventDataType]
    function: NotRequired[AgentThoughtStreamingEventFunctionTypedDict]


class AgentThoughtStreamingEventToolCalls(BaseModel):
    id: Optional[str] = None

    type: Optional[AgentThoughtStreamingEventDataType] = None

    function: Optional[AgentThoughtStreamingEventFunction] = None


AgentThoughtStreamingEventDataRole = Literal["assistant",]


class AgentThoughtStreamingEventAudioTypedDict(TypedDict):
    r"""If the audio output modality is requested, this object contains data about the audio response from the model."""

    id: str
    expires_at: int
    data: str
    transcript: str


class AgentThoughtStreamingEventAudio(BaseModel):
    r"""If the audio output modality is requested, this object contains data about the audio response from the model."""

    id: str

    expires_at: int

    data: str

    transcript: str


class AgentThoughtStreamingEventMessageTypedDict(TypedDict):
    r"""A chat completion message generated by the model."""

    content: NotRequired[Nullable[str]]
    refusal: NotRequired[Nullable[str]]
    tool_calls: NotRequired[List[AgentThoughtStreamingEventToolCallsTypedDict]]
    role: NotRequired[AgentThoughtStreamingEventDataRole]
    reasoning: NotRequired[Nullable[str]]
    r"""Internal thought process of the model"""
    reasoning_signature: NotRequired[Nullable[str]]
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""
    redacted_reasoning: NotRequired[str]
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""
    audio: NotRequired[Nullable[AgentThoughtStreamingEventAudioTypedDict]]
    r"""If the audio output modality is requested, this object contains data about the audio response from the model."""


class AgentThoughtStreamingEventMessage(BaseModel):
    r"""A chat completion message generated by the model."""

    content: OptionalNullable[str] = UNSET

    refusal: OptionalNullable[str] = UNSET

    tool_calls: Optional[List[AgentThoughtStreamingEventToolCalls]] = None

    role: Optional[AgentThoughtStreamingEventDataRole] = None

    reasoning: OptionalNullable[str] = UNSET
    r"""Internal thought process of the model"""

    reasoning_signature: OptionalNullable[str] = UNSET
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""

    redacted_reasoning: Optional[str] = None
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""

    audio: OptionalNullable[AgentThoughtStreamingEventAudio] = UNSET
    r"""If the audio output modality is requested, this object contains data about the audio response from the model."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "content",
            "refusal",
            "tool_calls",
            "role",
            "reasoning",
            "reasoning_signature",
            "redacted_reasoning",
            "audio",
        ]
        nullable_fields = [
            "content",
            "refusal",
            "reasoning",
            "reasoning_signature",
            "audio",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class TopLogprobsTypedDict(TypedDict):
    token: str
    r"""The token."""
    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""
    bytes_: Nullable[List[float]]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""


class TopLogprobs(BaseModel):
    token: str
    r"""The token."""

    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""

    bytes_: Annotated[Nullable[List[float]], pydantic.Field(alias="bytes")]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = []
        nullable_fields = ["bytes"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class AgentThoughtStreamingEventContentTypedDict(TypedDict):
    token: str
    r"""The token."""
    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""
    bytes_: Nullable[List[float]]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""
    top_logprobs: List[TopLogprobsTypedDict]
    r"""List of the most likely tokens and their log probability, at this token position."""


class AgentThoughtStreamingEventContent(BaseModel):
    token: str
    r"""The token."""

    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""

    bytes_: Annotated[Nullable[List[float]], pydantic.Field(alias="bytes")]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""

    top_logprobs: List[TopLogprobs]
    r"""List of the most likely tokens and their log probability, at this token position."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = []
        nullable_fields = ["bytes"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class AgentThoughtStreamingEventTopLogprobsTypedDict(TypedDict):
    token: str
    r"""The token."""
    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""
    bytes_: Nullable[List[float]]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""


class AgentThoughtStreamingEventTopLogprobs(BaseModel):
    token: str
    r"""The token."""

    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""

    bytes_: Annotated[Nullable[List[float]], pydantic.Field(alias="bytes")]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = []
        nullable_fields = ["bytes"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class RefusalTypedDict(TypedDict):
    token: str
    r"""The token."""
    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""
    bytes_: Nullable[List[float]]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""
    top_logprobs: List[AgentThoughtStreamingEventTopLogprobsTypedDict]
    r"""List of the most likely tokens and their log probability, at this token position."""


class Refusal(BaseModel):
    token: str
    r"""The token."""

    logprob: float
    r"""The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify that the token is very unlikely."""

    bytes_: Annotated[Nullable[List[float]], pydantic.Field(alias="bytes")]
    r"""A list of integers representing the UTF-8 bytes representation of the token."""

    top_logprobs: List[AgentThoughtStreamingEventTopLogprobs]
    r"""List of the most likely tokens and their log probability, at this token position."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = []
        nullable_fields = ["bytes"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class LogprobsTypedDict(TypedDict):
    r"""Log probability information for the choice."""

    content: Nullable[List[AgentThoughtStreamingEventContentTypedDict]]
    r"""A list of message content tokens with log probability information."""
    refusal: Nullable[List[RefusalTypedDict]]
    r"""A list of message refusal tokens with log probability information."""


class Logprobs(BaseModel):
    r"""Log probability information for the choice."""

    content: Nullable[List[AgentThoughtStreamingEventContent]]
    r"""A list of message content tokens with log probability information."""

    refusal: Nullable[List[Refusal]]
    r"""A list of message refusal tokens with log probability information."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = []
        nullable_fields = ["content", "refusal"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class ChoiceTypedDict(TypedDict):
    finish_reason: Nullable[AgentThoughtStreamingEventFinishReason]
    r"""The reason the model stopped generating tokens."""
    message: AgentThoughtStreamingEventMessageTypedDict
    r"""A chat completion message generated by the model."""
    index: NotRequired[float]
    r"""The index of the choice in the list of choices."""
    logprobs: NotRequired[Nullable[LogprobsTypedDict]]
    r"""Log probability information for the choice."""


class Choice(BaseModel):
    finish_reason: Nullable[AgentThoughtStreamingEventFinishReason]
    r"""The reason the model stopped generating tokens."""

    message: AgentThoughtStreamingEventMessage
    r"""A chat completion message generated by the model."""

    index: Optional[float] = 0
    r"""The index of the choice in the list of choices."""

    logprobs: OptionalNullable[Logprobs] = UNSET
    r"""Log probability information for the choice."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["index", "logprobs"]
        nullable_fields = ["finish_reason", "logprobs"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PromptTokensDetailsTypedDict(TypedDict):
    cached_tokens: NotRequired[Nullable[int]]
    cache_creation_tokens: NotRequired[Nullable[int]]
    audio_tokens: NotRequired[Nullable[int]]
    r"""The number of audio input tokens consumed by the request."""


class PromptTokensDetails(BaseModel):
    cached_tokens: OptionalNullable[int] = UNSET

    cache_creation_tokens: OptionalNullable[int] = UNSET

    audio_tokens: OptionalNullable[int] = UNSET
    r"""The number of audio input tokens consumed by the request."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["cached_tokens", "cache_creation_tokens", "audio_tokens"]
        nullable_fields = ["cached_tokens", "cache_creation_tokens", "audio_tokens"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class CompletionTokensDetailsTypedDict(TypedDict):
    reasoning_tokens: NotRequired[Nullable[float]]
    accepted_prediction_tokens: NotRequired[Nullable[float]]
    rejected_prediction_tokens: NotRequired[Nullable[float]]
    audio_tokens: NotRequired[Nullable[int]]
    r"""The number of audio output tokens produced by the response."""


class CompletionTokensDetails(BaseModel):
    reasoning_tokens: OptionalNullable[float] = UNSET

    accepted_prediction_tokens: OptionalNullable[float] = UNSET

    rejected_prediction_tokens: OptionalNullable[float] = UNSET

    audio_tokens: OptionalNullable[int] = UNSET
    r"""The number of audio output tokens produced by the response."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "reasoning_tokens",
            "accepted_prediction_tokens",
            "rejected_prediction_tokens",
            "audio_tokens",
        ]
        nullable_fields = [
            "reasoning_tokens",
            "accepted_prediction_tokens",
            "rejected_prediction_tokens",
            "audio_tokens",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class UsageTypedDict(TypedDict):
    r"""Usage statistics for the completion request."""

    completion_tokens: NotRequired[float]
    r"""Number of tokens in the generated completion."""
    prompt_tokens: NotRequired[float]
    r"""Number of tokens in the prompt."""
    total_tokens: NotRequired[float]
    r"""Total number of tokens used in the request (prompt + completion)."""
    prompt_tokens_details: NotRequired[Nullable[PromptTokensDetailsTypedDict]]
    completion_tokens_details: NotRequired[Nullable[CompletionTokensDetailsTypedDict]]


class Usage(BaseModel):
    r"""Usage statistics for the completion request."""

    completion_tokens: Optional[float] = None
    r"""Number of tokens in the generated completion."""

    prompt_tokens: Optional[float] = None
    r"""Number of tokens in the prompt."""

    total_tokens: Optional[float] = None
    r"""Total number of tokens used in the request (prompt + completion)."""

    prompt_tokens_details: OptionalNullable[PromptTokensDetails] = UNSET

    completion_tokens_details: OptionalNullable[CompletionTokensDetails] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "completion_tokens",
            "prompt_tokens",
            "total_tokens",
            "prompt_tokens_details",
            "completion_tokens_details",
        ]
        nullable_fields = ["prompt_tokens_details", "completion_tokens_details"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class AgentThoughtStreamingEventDataTypedDict(TypedDict):
    agent_id: str
    message_difference: Dict[str, MessageDifferenceTypedDict]
    iteration: float
    accumulated_execution_time: float
    choice: NotRequired[ChoiceTypedDict]
    choice_index: NotRequired[float]
    response_id: NotRequired[str]
    usage: NotRequired[UsageTypedDict]
    r"""Usage statistics for the completion request."""


class AgentThoughtStreamingEventData(BaseModel):
    agent_id: str

    message_difference: Dict[str, MessageDifference]

    iteration: float

    accumulated_execution_time: float

    choice: Optional[Choice] = None

    choice_index: Annotated[Optional[float], pydantic.Field(alias="choiceIndex")] = None

    response_id: Annotated[Optional[str], pydantic.Field(alias="responseId")] = None

    usage: Optional[Usage] = None
    r"""Usage statistics for the completion request."""


class AgentThoughtStreamingEventTypedDict(TypedDict):
    r"""Emitted during agent reasoning. Contains the incremental message changes, model choices, iteration count, and token usage for this processing step."""

    type: AgentThoughtStreamingEventType
    timestamp: str
    r"""ISO timestamp of the event"""
    data: AgentThoughtStreamingEventDataTypedDict


class AgentThoughtStreamingEvent(BaseModel):
    r"""Emitted during agent reasoning. Contains the incremental message changes, model choices, iteration count, and token usage for this processing step."""

    type: AgentThoughtStreamingEventType

    timestamp: str
    r"""ISO timestamp of the event"""

    data: AgentThoughtStreamingEventData
