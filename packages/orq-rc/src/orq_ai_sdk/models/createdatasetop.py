"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from datetime import datetime
from orq_ai_sdk.types import BaseModel, UNSET_SENTINEL
from orq_ai_sdk.utils import parse_datetime
import pydantic
from pydantic import model_serializer
from typing import Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class CreateDatasetRequestBodyTypedDict(TypedDict):
    display_name: str
    r"""The display name of the dataset"""
    path: str
    r"""Entity storage path in the format: `project/folder/subfolder/...`

    The first element identifies the project, followed by nested folders (auto-created as needed).

    With project-based API keys, the first element is treated as a folder name, as the project is predetermined by the API key.
    """


class CreateDatasetRequestBody(BaseModel):
    display_name: str
    r"""The display name of the dataset"""

    path: str
    r"""Entity storage path in the format: `project/folder/subfolder/...`

    The first element identifies the project, followed by nested folders (auto-created as needed).

    With project-based API keys, the first element is treated as a folder name, as the project is predetermined by the API key.
    """


class CreateDatasetMetadataTypedDict(TypedDict):
    total_versions: float
    datapoints_count: float


class CreateDatasetMetadata(BaseModel):
    total_versions: float

    datapoints_count: float


class CreateDatasetResponseBodyTypedDict(TypedDict):
    r"""Dataset created successfully. Returns the newly created dataset object."""

    id: str
    r"""The unique identifier of the dataset"""
    display_name: str
    r"""The display name of the dataset"""
    project_id: str
    r"""The unique identifier of the project it belongs to"""
    workspace_id: str
    r"""The unique identifier of the workspace it belongs to"""
    metadata: CreateDatasetMetadataTypedDict
    created_by_id: NotRequired[str]
    r"""The unique identifier of the user who created the dataset"""
    updated_by_id: NotRequired[str]
    r"""The unique identifier of the user who last updated the dataset"""
    created: NotRequired[datetime]
    r"""The date and time the resource was created"""
    updated: NotRequired[datetime]
    r"""The date and time the resource was last updated"""


class CreateDatasetResponseBody(BaseModel):
    r"""Dataset created successfully. Returns the newly created dataset object."""

    id: Annotated[str, pydantic.Field(alias="_id")]
    r"""The unique identifier of the dataset"""

    display_name: str
    r"""The display name of the dataset"""

    project_id: str
    r"""The unique identifier of the project it belongs to"""

    workspace_id: str
    r"""The unique identifier of the workspace it belongs to"""

    metadata: CreateDatasetMetadata

    created_by_id: Optional[str] = None
    r"""The unique identifier of the user who created the dataset"""

    updated_by_id: Optional[str] = None
    r"""The unique identifier of the user who last updated the dataset"""

    created: Optional[datetime] = None
    r"""The date and time the resource was created"""

    updated: Optional[datetime] = parse_datetime("2026-02-12T11:56:38.463Z")
    r"""The date and time the resource was last updated"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["created_by_id", "updated_by_id", "created", "updated"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
