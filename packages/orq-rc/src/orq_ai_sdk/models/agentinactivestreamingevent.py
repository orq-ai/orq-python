"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .datapart import DataPart, DataPartTypedDict
from .errorpart import ErrorPart, ErrorPartTypedDict
from .filepart import FilePart, FilePartTypedDict
from .textpart import TextPart, TextPartTypedDict
from .toolcallpart import ToolCallPart, ToolCallPartTypedDict
from .toolresultpart import ToolResultPart, ToolResultPartTypedDict
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from orq_ai_sdk.utils import get_discriminator
import pydantic
from pydantic import Discriminator, Tag, model_serializer
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


AgentInactiveStreamingEventType = Literal["event.agents.inactive",]


AgentInactiveStreamingEventRole = Literal[
    "user",
    "agent",
    "tool",
    "system",
]
r"""Extended A2A message role"""


AgentInactiveStreamingEventPartsTypedDict = TypeAliasType(
    "AgentInactiveStreamingEventPartsTypedDict",
    Union[
        TextPartTypedDict,
        ErrorPartTypedDict,
        DataPartTypedDict,
        FilePartTypedDict,
        ToolResultPartTypedDict,
        ToolCallPartTypedDict,
    ],
)


AgentInactiveStreamingEventParts = Annotated[
    Union[
        Annotated[TextPart, Tag("text")],
        Annotated[ErrorPart, Tag("error")],
        Annotated[DataPart, Tag("data")],
        Annotated[FilePart, Tag("file")],
        Annotated[ToolCallPart, Tag("tool_call")],
        Annotated[ToolResultPart, Tag("tool_result")],
    ],
    Discriminator(lambda m: get_discriminator(m, "kind", "kind")),
]


class LastMessageFullTypedDict(TypedDict):
    r"""Full last message in A2A format (for backwards compatibility)"""

    role: AgentInactiveStreamingEventRole
    r"""Extended A2A message role"""
    parts: List[AgentInactiveStreamingEventPartsTypedDict]
    message_id: NotRequired[str]
    metadata: NotRequired[Dict[str, Any]]


class LastMessageFull(BaseModel):
    r"""Full last message in A2A format (for backwards compatibility)"""

    role: AgentInactiveStreamingEventRole
    r"""Extended A2A message role"""

    parts: List[AgentInactiveStreamingEventParts]

    message_id: Annotated[Optional[str], pydantic.Field(alias="messageId")] = None

    metadata: Optional[Dict[str, Any]] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["messageId", "metadata"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


AgentInactiveStreamingEventFinishReason = Literal[
    "stop",
    "length",
    "tool_calls",
    "content_filter",
    "function_call",
    "max_iterations",
    "max_time",
]
r"""The reason why the agent execution became inactive"""


AgentInactiveStreamingEventDataType = Literal["function",]


class AgentInactiveStreamingEventFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    arguments: NotRequired[str]


class AgentInactiveStreamingEventFunction(BaseModel):
    name: Optional[str] = None

    arguments: Optional[str] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["name", "arguments"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class AgentInactiveStreamingEventPendingToolCallsTypedDict(TypedDict):
    id: str
    type: AgentInactiveStreamingEventDataType
    function: AgentInactiveStreamingEventFunctionTypedDict


class AgentInactiveStreamingEventPendingToolCalls(BaseModel):
    id: str

    type: AgentInactiveStreamingEventDataType

    function: AgentInactiveStreamingEventFunction


class AgentInactiveStreamingEventPromptTokensDetailsTypedDict(TypedDict):
    cached_tokens: NotRequired[Nullable[int]]
    cache_creation_tokens: NotRequired[Nullable[int]]
    audio_tokens: NotRequired[Nullable[int]]
    r"""The number of audio input tokens consumed by the request."""


class AgentInactiveStreamingEventPromptTokensDetails(BaseModel):
    cached_tokens: OptionalNullable[int] = UNSET

    cache_creation_tokens: OptionalNullable[int] = UNSET

    audio_tokens: OptionalNullable[int] = UNSET
    r"""The number of audio input tokens consumed by the request."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            ["cached_tokens", "cache_creation_tokens", "audio_tokens"]
        )
        nullable_fields = set(
            ["cached_tokens", "cache_creation_tokens", "audio_tokens"]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


class AgentInactiveStreamingEventCompletionTokensDetailsTypedDict(TypedDict):
    reasoning_tokens: NotRequired[Nullable[float]]
    accepted_prediction_tokens: NotRequired[Nullable[float]]
    rejected_prediction_tokens: NotRequired[Nullable[float]]
    audio_tokens: NotRequired[Nullable[int]]
    r"""The number of audio output tokens produced by the response."""


class AgentInactiveStreamingEventCompletionTokensDetails(BaseModel):
    reasoning_tokens: OptionalNullable[float] = UNSET

    accepted_prediction_tokens: OptionalNullable[float] = UNSET

    rejected_prediction_tokens: OptionalNullable[float] = UNSET

    audio_tokens: OptionalNullable[int] = UNSET
    r"""The number of audio output tokens produced by the response."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "reasoning_tokens",
                "accepted_prediction_tokens",
                "rejected_prediction_tokens",
                "audio_tokens",
            ]
        )
        nullable_fields = set(
            [
                "reasoning_tokens",
                "accepted_prediction_tokens",
                "rejected_prediction_tokens",
                "audio_tokens",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


class AgentInactiveStreamingEventUsageTypedDict(TypedDict):
    r"""Token usage from the last agent message"""

    completion_tokens: NotRequired[float]
    r"""Number of tokens in the generated completion."""
    prompt_tokens: NotRequired[float]
    r"""Number of tokens in the prompt."""
    total_tokens: NotRequired[float]
    r"""Total number of tokens used in the request (prompt + completion)."""
    prompt_tokens_details: NotRequired[
        Nullable[AgentInactiveStreamingEventPromptTokensDetailsTypedDict]
    ]
    completion_tokens_details: NotRequired[
        Nullable[AgentInactiveStreamingEventCompletionTokensDetailsTypedDict]
    ]
    time_to_first_token: NotRequired[float]


class AgentInactiveStreamingEventUsage(BaseModel):
    r"""Token usage from the last agent message"""

    completion_tokens: Optional[float] = None
    r"""Number of tokens in the generated completion."""

    prompt_tokens: Optional[float] = None
    r"""Number of tokens in the prompt."""

    total_tokens: Optional[float] = None
    r"""Total number of tokens used in the request (prompt + completion)."""

    prompt_tokens_details: OptionalNullable[
        AgentInactiveStreamingEventPromptTokensDetails
    ] = UNSET

    completion_tokens_details: OptionalNullable[
        AgentInactiveStreamingEventCompletionTokensDetails
    ] = UNSET

    time_to_first_token: Optional[float] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "completion_tokens",
                "prompt_tokens",
                "total_tokens",
                "prompt_tokens_details",
                "completion_tokens_details",
                "time_to_first_token",
            ]
        )
        nullable_fields = set(["prompt_tokens_details", "completion_tokens_details"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


class AgentInactiveStreamingEventDataTypedDict(TypedDict):
    last_message: str
    finish_reason: AgentInactiveStreamingEventFinishReason
    r"""The reason why the agent execution became inactive"""
    workflow_run_id: str
    last_message_full: NotRequired[LastMessageFullTypedDict]
    r"""Full last message in A2A format (for backwards compatibility)"""
    pending_tool_calls: NotRequired[
        List[AgentInactiveStreamingEventPendingToolCallsTypedDict]
    ]
    r"""Tool calls that are pending user response (for function_call finish reason)"""
    usage: NotRequired[AgentInactiveStreamingEventUsageTypedDict]
    r"""Token usage from the last agent message"""
    response_id: NotRequired[str]
    r"""ID of the response tracking this execution"""


class AgentInactiveStreamingEventData(BaseModel):
    last_message: str

    finish_reason: AgentInactiveStreamingEventFinishReason
    r"""The reason why the agent execution became inactive"""

    workflow_run_id: Annotated[str, pydantic.Field(alias="workflowRunId")]

    last_message_full: Optional[LastMessageFull] = None
    r"""Full last message in A2A format (for backwards compatibility)"""

    pending_tool_calls: Optional[List[AgentInactiveStreamingEventPendingToolCalls]] = (
        None
    )
    r"""Tool calls that are pending user response (for function_call finish reason)"""

    usage: Optional[AgentInactiveStreamingEventUsage] = None
    r"""Token usage from the last agent message"""

    response_id: Annotated[Optional[str], pydantic.Field(alias="responseId")] = None
    r"""ID of the response tracking this execution"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            ["last_message_full", "pending_tool_calls", "usage", "responseId"]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class AgentInactiveStreamingEventTypedDict(TypedDict):
    r"""Emitted when the agent completes processing or pauses for input. Contains the final message, finish reason (stop, tool_calls, max_iterations, etc.), and any pending tool calls awaiting user response."""

    type: AgentInactiveStreamingEventType
    timestamp: str
    r"""ISO timestamp of the event"""
    data: AgentInactiveStreamingEventDataTypedDict


class AgentInactiveStreamingEvent(BaseModel):
    r"""Emitted when the agent completes processing or pauses for input. Contains the final message, finish reason (stop, tool_calls, max_iterations, etc.), and any pending tool calls awaiting user response."""

    type: AgentInactiveStreamingEventType

    timestamp: str
    r"""ISO timestamp of the event"""

    data: AgentInactiveStreamingEventData
