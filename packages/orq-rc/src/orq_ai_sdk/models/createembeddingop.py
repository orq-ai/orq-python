"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .publiccontact import PublicContact, PublicContactTypedDict
from .publicidentity import PublicIdentity, PublicIdentityTypedDict
from orq_ai_sdk.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


CreateEmbeddingInputTypedDict = TypeAliasType(
    "CreateEmbeddingInputTypedDict", Union[str, List[str]]
)
r"""Input text to embed, encoded as a string or array of tokens."""


CreateEmbeddingInput = TypeAliasType("CreateEmbeddingInput", Union[str, List[str]])
r"""Input text to embed, encoded as a string or array of tokens."""


EncodingFormat = Literal[
    "base64",
    "float",
]
r"""Type of the document element"""


class CreateEmbeddingFallbacksTypedDict(TypedDict):
    model: str
    r"""Fallback model identifier"""


class CreateEmbeddingFallbacks(BaseModel):
    model: str
    r"""Fallback model identifier"""


class CreateEmbeddingRetryTypedDict(TypedDict):
    r"""Retry configuration for the request"""

    count: NotRequired[float]
    r"""Number of retry attempts (1-5)"""
    on_codes: NotRequired[List[float]]
    r"""HTTP status codes that trigger retry logic"""


class CreateEmbeddingRetry(BaseModel):
    r"""Retry configuration for the request"""

    count: Optional[float] = 3
    r"""Number of retry attempts (1-5)"""

    on_codes: Optional[List[float]] = None
    r"""HTTP status codes that trigger retry logic"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["count", "on_codes"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateEmbeddingType = Literal["exact_match",]


class CreateEmbeddingCacheTypedDict(TypedDict):
    r"""Cache configuration for the request."""

    type: CreateEmbeddingType
    ttl: NotRequired[float]
    r"""Time to live for cached responses in seconds. Maximum 259200 seconds (3 days)."""


class CreateEmbeddingCache(BaseModel):
    r"""Cache configuration for the request."""

    type: CreateEmbeddingType

    ttl: Optional[float] = 1800
    r"""Time to live for cached responses in seconds. Maximum 259200 seconds (3 days)."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["ttl"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateEmbeddingLoadBalancerType = Literal["weight_based",]


class CreateEmbeddingLoadBalancerModelsTypedDict(TypedDict):
    model: str
    r"""Model identifier for load balancing"""
    weight: NotRequired[float]
    r"""Weight assigned to this model for load balancing"""


class CreateEmbeddingLoadBalancerModels(BaseModel):
    model: str
    r"""Model identifier for load balancing"""

    weight: Optional[float] = 0.5
    r"""Weight assigned to this model for load balancing"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["weight"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateEmbeddingLoadBalancer1TypedDict(TypedDict):
    type: CreateEmbeddingLoadBalancerType
    models: List[CreateEmbeddingLoadBalancerModelsTypedDict]


class CreateEmbeddingLoadBalancer1(BaseModel):
    type: CreateEmbeddingLoadBalancerType

    models: List[CreateEmbeddingLoadBalancerModels]


CreateEmbeddingLoadBalancerTypedDict = CreateEmbeddingLoadBalancer1TypedDict
r"""Load balancer configuration for the request."""


CreateEmbeddingLoadBalancer = CreateEmbeddingLoadBalancer1
r"""Load balancer configuration for the request."""


class CreateEmbeddingTimeoutTypedDict(TypedDict):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateEmbeddingTimeout(BaseModel):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateEmbeddingRouterEmbeddingsFallbacksTypedDict(TypedDict):
    model: str
    r"""Fallback model identifier"""


class CreateEmbeddingRouterEmbeddingsFallbacks(BaseModel):
    model: str
    r"""Fallback model identifier"""


CreateEmbeddingRouterEmbeddingsType = Literal["exact_match",]


class CreateEmbeddingRouterEmbeddingsCacheTypedDict(TypedDict):
    r"""Cache configuration for the request."""

    type: CreateEmbeddingRouterEmbeddingsType
    ttl: NotRequired[float]
    r"""Time to live for cached responses in seconds. Maximum 259200 seconds (3 days)."""


class CreateEmbeddingRouterEmbeddingsCache(BaseModel):
    r"""Cache configuration for the request."""

    type: CreateEmbeddingRouterEmbeddingsType

    ttl: Optional[float] = 1800
    r"""Time to live for cached responses in seconds. Maximum 259200 seconds (3 days)."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["ttl"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateEmbeddingRouterEmbeddingsRetryTypedDict(TypedDict):
    r"""Retry configuration for the request"""

    count: NotRequired[float]
    r"""Number of retry attempts (1-5)"""
    on_codes: NotRequired[List[float]]
    r"""HTTP status codes that trigger retry logic"""


class CreateEmbeddingRouterEmbeddingsRetry(BaseModel):
    r"""Retry configuration for the request"""

    count: Optional[float] = 3
    r"""Number of retry attempts (1-5)"""

    on_codes: Optional[List[float]] = None
    r"""HTTP status codes that trigger retry logic"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["count", "on_codes"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateEmbeddingLoadBalancerRouterEmbeddingsType = Literal["weight_based",]


class CreateEmbeddingLoadBalancerRouterEmbeddingsModelsTypedDict(TypedDict):
    model: str
    r"""Model identifier for load balancing"""
    weight: NotRequired[float]
    r"""Weight assigned to this model for load balancing"""


class CreateEmbeddingLoadBalancerRouterEmbeddingsModels(BaseModel):
    model: str
    r"""Model identifier for load balancing"""

    weight: Optional[float] = 0.5
    r"""Weight assigned to this model for load balancing"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["weight"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateEmbeddingLoadBalancerRouterEmbeddings1TypedDict(TypedDict):
    type: CreateEmbeddingLoadBalancerRouterEmbeddingsType
    models: List[CreateEmbeddingLoadBalancerRouterEmbeddingsModelsTypedDict]


class CreateEmbeddingLoadBalancerRouterEmbeddings1(BaseModel):
    type: CreateEmbeddingLoadBalancerRouterEmbeddingsType

    models: List[CreateEmbeddingLoadBalancerRouterEmbeddingsModels]


CreateEmbeddingRouterEmbeddingsLoadBalancerTypedDict = (
    CreateEmbeddingLoadBalancerRouterEmbeddings1TypedDict
)
r"""Array of models with weights for load balancing requests"""


CreateEmbeddingRouterEmbeddingsLoadBalancer = (
    CreateEmbeddingLoadBalancerRouterEmbeddings1
)
r"""Array of models with weights for load balancing requests"""


class CreateEmbeddingRouterEmbeddingsTimeoutTypedDict(TypedDict):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateEmbeddingRouterEmbeddingsTimeout(BaseModel):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateEmbeddingOrqTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name to display on the trace. If not specified, the default system name will be used."""
    fallbacks: NotRequired[List[CreateEmbeddingRouterEmbeddingsFallbacksTypedDict]]
    r"""Array of fallback models to use if primary model fails"""
    cache: NotRequired[CreateEmbeddingRouterEmbeddingsCacheTypedDict]
    r"""Cache configuration for the request."""
    retry: NotRequired[CreateEmbeddingRouterEmbeddingsRetryTypedDict]
    r"""Retry configuration for the request"""
    identity: NotRequired[PublicIdentityTypedDict]
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""
    contact: NotRequired[PublicContactTypedDict]
    r"""@deprecated Use identity instead. Information about the contact making the request."""
    load_balancer: NotRequired[CreateEmbeddingRouterEmbeddingsLoadBalancerTypedDict]
    r"""Array of models with weights for load balancing requests"""
    timeout: NotRequired[CreateEmbeddingRouterEmbeddingsTimeoutTypedDict]
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""


class CreateEmbeddingOrq(BaseModel):
    name: Optional[str] = None
    r"""The name to display on the trace. If not specified, the default system name will be used."""

    fallbacks: Optional[List[CreateEmbeddingRouterEmbeddingsFallbacks]] = None
    r"""Array of fallback models to use if primary model fails"""

    cache: Optional[CreateEmbeddingRouterEmbeddingsCache] = None
    r"""Cache configuration for the request."""

    retry: Optional[CreateEmbeddingRouterEmbeddingsRetry] = None
    r"""Retry configuration for the request"""

    identity: Optional[PublicIdentity] = None
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""

    contact: Annotated[
        Optional[PublicContact],
        pydantic.Field(
            deprecated="warning: ** DEPRECATED ** - This will be removed in a future release, please migrate away from it as soon as possible."
        ),
    ] = None
    r"""@deprecated Use identity instead. Information about the contact making the request."""

    load_balancer: Optional[CreateEmbeddingRouterEmbeddingsLoadBalancer] = None
    r"""Array of models with weights for load balancing requests"""

    timeout: Optional[CreateEmbeddingRouterEmbeddingsTimeout] = None
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "name",
                "fallbacks",
                "cache",
                "retry",
                "identity",
                "contact",
                "load_balancer",
                "timeout",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateEmbeddingRequestBodyTypedDict(TypedDict):
    r"""input"""

    input: CreateEmbeddingInputTypedDict
    r"""Input text to embed, encoded as a string or array of tokens."""
    model: str
    r"""ID of the model to use"""
    encoding_format: NotRequired[EncodingFormat]
    r"""Type of the document element"""
    dimensions: NotRequired[float]
    r"""The number of dimensions the resulting output embeddings should have."""
    user: NotRequired[str]
    r"""A unique identifier representing your end-user"""
    name: NotRequired[str]
    r"""The name to display on the trace. If not specified, the default system name will be used."""
    fallbacks: NotRequired[List[CreateEmbeddingFallbacksTypedDict]]
    r"""Array of fallback models to use if primary model fails"""
    retry: NotRequired[CreateEmbeddingRetryTypedDict]
    r"""Retry configuration for the request"""
    cache: NotRequired[CreateEmbeddingCacheTypedDict]
    r"""Cache configuration for the request."""
    load_balancer: NotRequired[CreateEmbeddingLoadBalancerTypedDict]
    r"""Load balancer configuration for the request."""
    timeout: NotRequired[CreateEmbeddingTimeoutTypedDict]
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""
    orq: NotRequired[CreateEmbeddingOrqTypedDict]


class CreateEmbeddingRequestBody(BaseModel):
    r"""input"""

    input: CreateEmbeddingInput
    r"""Input text to embed, encoded as a string or array of tokens."""

    model: str
    r"""ID of the model to use"""

    encoding_format: Optional[EncodingFormat] = "float"
    r"""Type of the document element"""

    dimensions: Optional[float] = None
    r"""The number of dimensions the resulting output embeddings should have."""

    user: Optional[str] = None
    r"""A unique identifier representing your end-user"""

    name: Optional[str] = None
    r"""The name to display on the trace. If not specified, the default system name will be used."""

    fallbacks: Optional[List[CreateEmbeddingFallbacks]] = None
    r"""Array of fallback models to use if primary model fails"""

    retry: Optional[CreateEmbeddingRetry] = None
    r"""Retry configuration for the request"""

    cache: Optional[CreateEmbeddingCache] = None
    r"""Cache configuration for the request."""

    load_balancer: Optional[CreateEmbeddingLoadBalancer] = None
    r"""Load balancer configuration for the request."""

    timeout: Optional[CreateEmbeddingTimeout] = None
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    orq: Optional[CreateEmbeddingOrq] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "encoding_format",
                "dimensions",
                "user",
                "name",
                "fallbacks",
                "retry",
                "cache",
                "load_balancer",
                "timeout",
                "orq",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateEmbeddingObject = Literal["list",]


CreateEmbeddingRouterEmbeddingsObject = Literal["embedding",]
r"""The object type, which is always `embedding`."""


EmbeddingTypedDict = TypeAliasType("EmbeddingTypedDict", Union[List[float], str])
r"""The embedding vector, which is a list of floats. The length of vector depends on the model."""


Embedding = TypeAliasType("Embedding", Union[List[float], str])
r"""The embedding vector, which is a list of floats. The length of vector depends on the model."""


class CreateEmbeddingDataTypedDict(TypedDict):
    object: CreateEmbeddingRouterEmbeddingsObject
    r"""The object type, which is always `embedding`."""
    embedding: EmbeddingTypedDict
    r"""The embedding vector, which is a list of floats. The length of vector depends on the model."""
    index: float
    r"""The index of the embedding in the list of embeddings."""


class CreateEmbeddingData(BaseModel):
    object: CreateEmbeddingRouterEmbeddingsObject
    r"""The object type, which is always `embedding`."""

    embedding: Embedding
    r"""The embedding vector, which is a list of floats. The length of vector depends on the model."""

    index: float
    r"""The index of the embedding in the list of embeddings."""


class CreateEmbeddingUsageTypedDict(TypedDict):
    r"""The usage information for the request."""

    prompt_tokens: float
    r"""The number of tokens used by the prompt."""
    total_tokens: float
    r"""The total number of tokens used by the request."""


class CreateEmbeddingUsage(BaseModel):
    r"""The usage information for the request."""

    prompt_tokens: float
    r"""The number of tokens used by the prompt."""

    total_tokens: float
    r"""The total number of tokens used by the request."""


class CreateEmbeddingResponseBodyTypedDict(TypedDict):
    r"""Returns the embedding vector."""

    object: CreateEmbeddingObject
    data: List[CreateEmbeddingDataTypedDict]
    model: str
    r"""ID of the model to used."""
    usage: CreateEmbeddingUsageTypedDict
    r"""The usage information for the request."""


class CreateEmbeddingResponseBody(BaseModel):
    r"""Returns the embedding vector."""

    object: CreateEmbeddingObject

    data: List[CreateEmbeddingData]

    model: str
    r"""ID of the model to used."""

    usage: CreateEmbeddingUsage
    r"""The usage information for the request."""
