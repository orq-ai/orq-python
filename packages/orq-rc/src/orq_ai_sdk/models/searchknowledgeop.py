"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from orq_ai_sdk.utils import FieldMetadata, PathParamMetadata, RequestMetadata
from pydantic import model_serializer
from typing import List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


SearchKnowledgeRetrievalConfigKnowledgeType = Literal["hybrid_search"]

SearchKnowledgeRetrievalConfigKnowledgeProvider = Literal[
    "cohere",
    "openai",
    "anthropic",
    "huggingface",
    "replicate",
    "google",
    "google-ai",
    "azure",
    "aws",
    "anyscale",
    "perplexity",
    "groq",
    "fal",
    "leonardoai",
    "nvidia",
    "jina",
    "togetherai",
    "elevenlabs",
]

SearchKnowledgeRetrievalConfigKnowledgeModelType = Literal["rerank"]


class SearchKnowledgeRetrievalConfigKnowledgeModelParametersTypedDict(TypedDict):
    threshold: NotRequired[float]
    r"""The threshold value used to filter the rerank results, only documents with a relevance score greater than the threshold will be returned"""


class SearchKnowledgeRetrievalConfigKnowledgeModelParameters(BaseModel):
    threshold: Optional[float] = None
    r"""The threshold value used to filter the rerank results, only documents with a relevance score greater than the threshold will be returned"""


class SearchKnowledgeRetrievalConfigRerankConfigInputTypedDict(TypedDict):
    enabled: NotRequired[bool]
    provider: NotRequired[SearchKnowledgeRetrievalConfigKnowledgeProvider]
    model: NotRequired[str]
    r"""The name of the model to use"""
    model_db_id: NotRequired[str]
    r"""The ID of the model in the database"""
    model_type: NotRequired[SearchKnowledgeRetrievalConfigKnowledgeModelType]
    model_parameters: NotRequired[
        SearchKnowledgeRetrievalConfigKnowledgeModelParametersTypedDict
    ]


class SearchKnowledgeRetrievalConfigRerankConfigInput(BaseModel):
    enabled: Optional[bool] = None

    provider: Optional[SearchKnowledgeRetrievalConfigKnowledgeProvider] = None

    model: Optional[str] = None
    r"""The name of the model to use"""

    model_db_id: Optional[str] = None
    r"""The ID of the model in the database"""

    model_type: Optional[SearchKnowledgeRetrievalConfigKnowledgeModelType] = None

    model_parameters: Optional[
        SearchKnowledgeRetrievalConfigKnowledgeModelParameters
    ] = None


class RetrievalConfig3TypedDict(TypedDict):
    type: SearchKnowledgeRetrievalConfigKnowledgeType
    top_k: NotRequired[int]
    r"""Used to filter chunks that are most similar to the query"""
    threshold: NotRequired[float]
    r"""Used to filter chunks that are most similar to the query. A value of `0` will be consider disabled."""
    rerank_config: NotRequired[
        Nullable[SearchKnowledgeRetrievalConfigRerankConfigInputTypedDict]
    ]


class RetrievalConfig3(BaseModel):
    type: SearchKnowledgeRetrievalConfigKnowledgeType

    top_k: Optional[int] = 5
    r"""Used to filter chunks that are most similar to the query"""

    threshold: Optional[float] = 0
    r"""Used to filter chunks that are most similar to the query. A value of `0` will be consider disabled."""

    rerank_config: OptionalNullable[SearchKnowledgeRetrievalConfigRerankConfigInput] = (
        UNSET
    )

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["top_k", "threshold", "rerank_config"]
        nullable_fields = ["rerank_config"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


SearchKnowledgeRetrievalConfigType = Literal["keyword_search"]

SearchKnowledgeRetrievalConfigProvider = Literal[
    "cohere",
    "openai",
    "anthropic",
    "huggingface",
    "replicate",
    "google",
    "google-ai",
    "azure",
    "aws",
    "anyscale",
    "perplexity",
    "groq",
    "fal",
    "leonardoai",
    "nvidia",
    "jina",
    "togetherai",
    "elevenlabs",
]

SearchKnowledgeRetrievalConfigModelType = Literal["rerank"]


class SearchKnowledgeRetrievalConfigModelParametersTypedDict(TypedDict):
    threshold: NotRequired[float]
    r"""The threshold value used to filter the rerank results, only documents with a relevance score greater than the threshold will be returned"""


class SearchKnowledgeRetrievalConfigModelParameters(BaseModel):
    threshold: Optional[float] = None
    r"""The threshold value used to filter the rerank results, only documents with a relevance score greater than the threshold will be returned"""


class SearchKnowledgeRetrievalConfigRerankConfigTypedDict(TypedDict):
    enabled: NotRequired[bool]
    provider: NotRequired[SearchKnowledgeRetrievalConfigProvider]
    model: NotRequired[str]
    r"""The name of the model to use"""
    model_db_id: NotRequired[str]
    r"""The ID of the model in the database"""
    model_type: NotRequired[SearchKnowledgeRetrievalConfigModelType]
    model_parameters: NotRequired[
        SearchKnowledgeRetrievalConfigModelParametersTypedDict
    ]


class SearchKnowledgeRetrievalConfigRerankConfig(BaseModel):
    enabled: Optional[bool] = None

    provider: Optional[SearchKnowledgeRetrievalConfigProvider] = None

    model: Optional[str] = None
    r"""The name of the model to use"""

    model_db_id: Optional[str] = None
    r"""The ID of the model in the database"""

    model_type: Optional[SearchKnowledgeRetrievalConfigModelType] = None

    model_parameters: Optional[SearchKnowledgeRetrievalConfigModelParameters] = None


class RetrievalConfig2TypedDict(TypedDict):
    type: SearchKnowledgeRetrievalConfigType
    top_k: NotRequired[int]
    r"""Used to filter chunks that are most similar to the query"""
    threshold: NotRequired[float]
    r"""Used to filter chunks that are most similar to the query. A value of `0` will be consider disabled."""
    rerank_config: NotRequired[
        Nullable[SearchKnowledgeRetrievalConfigRerankConfigTypedDict]
    ]


class RetrievalConfig2(BaseModel):
    type: SearchKnowledgeRetrievalConfigType

    top_k: Optional[int] = 5
    r"""Used to filter chunks that are most similar to the query"""

    threshold: Optional[float] = 0
    r"""Used to filter chunks that are most similar to the query. A value of `0` will be consider disabled."""

    rerank_config: OptionalNullable[SearchKnowledgeRetrievalConfigRerankConfig] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["top_k", "threshold", "rerank_config"]
        nullable_fields = ["rerank_config"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


RetrievalConfigType = Literal["vector_search"]

RetrievalConfigProvider = Literal[
    "cohere",
    "openai",
    "anthropic",
    "huggingface",
    "replicate",
    "google",
    "google-ai",
    "azure",
    "aws",
    "anyscale",
    "perplexity",
    "groq",
    "fal",
    "leonardoai",
    "nvidia",
    "jina",
    "togetherai",
    "elevenlabs",
]

RetrievalConfigModelType = Literal["rerank"]


class RetrievalConfigModelParametersTypedDict(TypedDict):
    threshold: NotRequired[float]
    r"""The threshold value used to filter the rerank results, only documents with a relevance score greater than the threshold will be returned"""


class RetrievalConfigModelParameters(BaseModel):
    threshold: Optional[float] = None
    r"""The threshold value used to filter the rerank results, only documents with a relevance score greater than the threshold will be returned"""


class RetrievalConfigRerankConfigTypedDict(TypedDict):
    enabled: NotRequired[bool]
    provider: NotRequired[RetrievalConfigProvider]
    model: NotRequired[str]
    r"""The name of the model to use"""
    model_db_id: NotRequired[str]
    r"""The ID of the model in the database"""
    model_type: NotRequired[RetrievalConfigModelType]
    model_parameters: NotRequired[RetrievalConfigModelParametersTypedDict]


class RetrievalConfigRerankConfig(BaseModel):
    enabled: Optional[bool] = None

    provider: Optional[RetrievalConfigProvider] = None

    model: Optional[str] = None
    r"""The name of the model to use"""

    model_db_id: Optional[str] = None
    r"""The ID of the model in the database"""

    model_type: Optional[RetrievalConfigModelType] = None

    model_parameters: Optional[RetrievalConfigModelParameters] = None


class RetrievalConfig1TypedDict(TypedDict):
    type: RetrievalConfigType
    top_k: NotRequired[int]
    r"""Used to filter chunks that are most similar to the query"""
    threshold: NotRequired[float]
    r"""Used to filter chunks that are most similar to the query. A value of `0` will be consider disabled."""
    rerank_config: NotRequired[Nullable[RetrievalConfigRerankConfigTypedDict]]


class RetrievalConfig1(BaseModel):
    type: RetrievalConfigType

    top_k: Optional[int] = 5
    r"""Used to filter chunks that are most similar to the query"""

    threshold: Optional[float] = 0
    r"""Used to filter chunks that are most similar to the query. A value of `0` will be consider disabled."""

    rerank_config: OptionalNullable[RetrievalConfigRerankConfig] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["top_k", "threshold", "rerank_config"]
        nullable_fields = ["rerank_config"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


RetrievalConfigTypedDict = TypeAliasType(
    "RetrievalConfigTypedDict",
    Union[
        RetrievalConfig1TypedDict, RetrievalConfig2TypedDict, RetrievalConfig3TypedDict
    ],
)
r"""Allow to modify the retrieval config for the search. If not provided, the knowledge base configuration set in the database will be used."""


RetrievalConfig = TypeAliasType(
    "RetrievalConfig", Union[RetrievalConfig1, RetrievalConfig2, RetrievalConfig3]
)
r"""Allow to modify the retrieval config for the search. If not provided, the knowledge base configuration set in the database will be used."""


class SearchKnowledgeRequestBodyTypedDict(TypedDict):
    query: str
    retrieval_config: NotRequired[RetrievalConfigTypedDict]
    r"""Allow to modify the retrieval config for the search. If not provided, the knowledge base configuration set in the database will be used."""


class SearchKnowledgeRequestBody(BaseModel):
    query: str

    retrieval_config: Optional[RetrievalConfig] = None
    r"""Allow to modify the retrieval config for the search. If not provided, the knowledge base configuration set in the database will be used."""


class SearchKnowledgeRequestTypedDict(TypedDict):
    knowledge_id: str
    request_body: SearchKnowledgeRequestBodyTypedDict


class SearchKnowledgeRequest(BaseModel):
    knowledge_id: Annotated[
        str, FieldMetadata(path=PathParamMetadata(style="simple", explode=False))
    ]

    request_body: Annotated[
        SearchKnowledgeRequestBody,
        FieldMetadata(request=RequestMetadata(media_type="application/json")),
    ]


class SearchKnowledgeMetadataTypedDict(TypedDict):
    datasource_id: str
    r"""Unique identifier for the data source"""
    chunk_id: str
    r"""Unique identifier for the chunk"""
    file_name: str
    r"""Name of the uploaded file during the datasource creation."""
    file_type: str
    r"""Type of the uploaded file when the datasource was created."""
    page_number: NotRequired[Nullable[float]]
    r"""Reference to the page number the chunk was extracted from. The property will only be available for `application/pdf` type of files. For other file types, the property will be `null`."""


class SearchKnowledgeMetadata(BaseModel):
    datasource_id: str
    r"""Unique identifier for the data source"""

    chunk_id: str
    r"""Unique identifier for the chunk"""

    file_name: str
    r"""Name of the uploaded file during the datasource creation."""

    file_type: str
    r"""Type of the uploaded file when the datasource was created."""

    page_number: OptionalNullable[float] = UNSET
    r"""Reference to the page number the chunk was extracted from. The property will only be available for `application/pdf` type of files. For other file types, the property will be `null`."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["page_number"]
        nullable_fields = ["page_number"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class SearchKnowledgeDocumentsTypedDict(TypedDict):
    id: str
    r"""Unique identifier for the retrieval"""
    text: str
    r"""Text content of the document"""
    metadata: SearchKnowledgeMetadataTypedDict
    score: float
    r"""The score of the document"""
    rerank_score: NotRequired[float]
    r"""The rerank score of the document"""


class SearchKnowledgeDocuments(BaseModel):
    id: str
    r"""Unique identifier for the retrieval"""

    text: str
    r"""Text content of the document"""

    metadata: SearchKnowledgeMetadata

    score: float
    r"""The score of the document"""

    rerank_score: Optional[float] = None
    r"""The rerank score of the document"""


class SearchKnowledgeResponseBodyTypedDict(TypedDict):
    r"""Knowledge successfully retrieved"""

    knowledge_id: str
    r"""Unique id of the knowledge base"""
    documents: List[SearchKnowledgeDocumentsTypedDict]
    r"""The documents returned"""
    knowledge_key: str
    r"""The key of the knowledge base"""
    query: str
    r"""The query used to search the knowledge base"""


class SearchKnowledgeResponseBody(BaseModel):
    r"""Knowledge successfully retrieved"""

    knowledge_id: str
    r"""Unique id of the knowledge base"""

    documents: List[SearchKnowledgeDocuments]
    r"""The documents returned"""

    knowledge_key: str
    r"""The key of the knowledge base"""

    query: str
    r"""The query used to search the knowledge base"""
