"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .publiccontact import PublicContact, PublicContactTypedDict
from orq_ai_sdk.types import BaseModel, UNSET_SENTINEL
from pydantic import model_serializer
from typing import Any, Dict, List, Literal, Optional
from typing_extensions import NotRequired, TypedDict, deprecated


CreateSpeechResponseFormat = Literal[
    "mp3",
    "opus",
    "aac",
    "flac",
    "wav",
    "pcm",
]
r"""The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`. If a format is provided but not supported by the provider, the response will be in the default format. When the provided format is not supported by the provider, the response will be in the default format."""


class CreateSpeechRetryTypedDict(TypedDict):
    r"""Retry configuration for the request"""

    count: NotRequired[float]
    r"""Number of retry attempts (1-5)"""
    on_codes: NotRequired[List[float]]
    r"""HTTP status codes that trigger retry logic"""


class CreateSpeechRetry(BaseModel):
    r"""Retry configuration for the request"""

    count: Optional[float] = 3
    r"""Number of retry attempts (1-5)"""

    on_codes: Optional[List[float]] = None
    r"""HTTP status codes that trigger retry logic"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["count", "on_codes"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateSpeechFallbacksTypedDict(TypedDict):
    model: str
    r"""Fallback model identifier"""


class CreateSpeechFallbacks(BaseModel):
    model: str
    r"""Fallback model identifier"""


@deprecated(
    "warning: ** DEPRECATED ** - This will be removed in a future release, please migrate away from it as soon as possible."
)
class CreateSpeechContactTypedDict(TypedDict):
    r"""@deprecated Use identity instead. Information about the contact making the request."""

    id: str
    r"""Unique identifier for the contact"""
    display_name: NotRequired[str]
    r"""Display name of the contact"""
    email: NotRequired[str]
    r"""Email address of the contact"""
    metadata: NotRequired[List[Dict[str, Any]]]
    r"""A hash of key/value pairs containing any other data about the contact"""
    logo_url: NotRequired[str]
    r"""URL to the contact's avatar or logo"""
    tags: NotRequired[List[str]]
    r"""A list of tags associated with the contact"""


@deprecated(
    "warning: ** DEPRECATED ** - This will be removed in a future release, please migrate away from it as soon as possible."
)
class CreateSpeechContact(BaseModel):
    r"""@deprecated Use identity instead. Information about the contact making the request."""

    id: str
    r"""Unique identifier for the contact"""

    display_name: Optional[str] = None
    r"""Display name of the contact"""

    email: Optional[str] = None
    r"""Email address of the contact"""

    metadata: Optional[List[Dict[str, Any]]] = None
    r"""A hash of key/value pairs containing any other data about the contact"""

    logo_url: Optional[str] = None
    r"""URL to the contact's avatar or logo"""

    tags: Optional[List[str]] = None
    r"""A list of tags associated with the contact"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["display_name", "email", "metadata", "logo_url", "tags"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateSpeechThreadTypedDict(TypedDict):
    r"""Thread information to group related requests"""

    id: str
    r"""Unique thread identifier to group related invocations."""
    tags: NotRequired[List[str]]
    r"""Optional tags to differentiate or categorize threads"""


class CreateSpeechThread(BaseModel):
    r"""Thread information to group related requests"""

    id: str
    r"""Unique thread identifier to group related invocations."""

    tags: Optional[List[str]] = None
    r"""Optional tags to differentiate or categorize threads"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["tags"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateSpeechLoadBalancerType = Literal["weight_based",]


class CreateSpeechLoadBalancer1TypedDict(TypedDict):
    type: CreateSpeechLoadBalancerType
    model: str
    r"""Model identifier for load balancing"""
    weight: NotRequired[float]
    r"""Weight assigned to this model for load balancing"""


class CreateSpeechLoadBalancer1(BaseModel):
    type: CreateSpeechLoadBalancerType

    model: str
    r"""Model identifier for load balancing"""

    weight: Optional[float] = 0.5
    r"""Weight assigned to this model for load balancing"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["weight"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateSpeechLoadBalancerTypedDict = CreateSpeechLoadBalancer1TypedDict


CreateSpeechLoadBalancer = CreateSpeechLoadBalancer1


class CreateSpeechTimeoutTypedDict(TypedDict):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateSpeechTimeout(BaseModel):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateSpeechOrqTypedDict(TypedDict):
    retry: NotRequired[CreateSpeechRetryTypedDict]
    r"""Retry configuration for the request"""
    fallbacks: NotRequired[List[CreateSpeechFallbacksTypedDict]]
    r"""Array of fallback models to use if primary model fails"""
    name: NotRequired[str]
    r"""The name to display on the trace. If not specified, the default system name will be used."""
    identity: NotRequired[PublicContactTypedDict]
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""
    contact: NotRequired[CreateSpeechContactTypedDict]
    thread: NotRequired[CreateSpeechThreadTypedDict]
    r"""Thread information to group related requests"""
    load_balancer: NotRequired[List[CreateSpeechLoadBalancerTypedDict]]
    r"""Array of models with weights for load balancing requests"""
    timeout: NotRequired[CreateSpeechTimeoutTypedDict]
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""


class CreateSpeechOrq(BaseModel):
    retry: Optional[CreateSpeechRetry] = None
    r"""Retry configuration for the request"""

    fallbacks: Optional[List[CreateSpeechFallbacks]] = None
    r"""Array of fallback models to use if primary model fails"""

    name: Optional[str] = None
    r"""The name to display on the trace. If not specified, the default system name will be used."""

    identity: Optional[PublicContact] = None
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""

    contact: Optional[CreateSpeechContact] = None

    thread: Optional[CreateSpeechThread] = None
    r"""Thread information to group related requests"""

    load_balancer: Optional[List[CreateSpeechLoadBalancer]] = None
    r"""Array of models with weights for load balancing requests"""

    timeout: Optional[CreateSpeechTimeout] = None
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "retry",
                "fallbacks",
                "name",
                "identity",
                "contact",
                "thread",
                "load_balancer",
                "timeout",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateSpeechRequestBodyTypedDict(TypedDict):
    r"""input"""

    input: str
    r"""The text to generate audio for. The maximum length is 4096 characters"""
    model: str
    r"""ID of the model to use"""
    voice: str
    r"""The voice to use.

    Available voices for OpenAI

    `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`

    Available voices for ElevenLabs

    `aria`, `roger`, `sarah`, `laura`, `charlie`, `george`, `callum`, `river`, `liam`, `charlotte`, `alice`, `matilda`, `will`, `jessica`, `eric`, `chris`, `brian`, `daniel`, `lily`, `bill`
    """
    response_format: NotRequired[CreateSpeechResponseFormat]
    r"""The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`. If a format is provided but not supported by the provider, the response will be in the default format. When the provided format is not supported by the provider, the response will be in the default format."""
    speed: NotRequired[float]
    r"""The speed of the generated audio."""
    orq: NotRequired[CreateSpeechOrqTypedDict]


class CreateSpeechRequestBody(BaseModel):
    r"""input"""

    input: str
    r"""The text to generate audio for. The maximum length is 4096 characters"""

    model: str
    r"""ID of the model to use"""

    voice: str
    r"""The voice to use.

    Available voices for OpenAI

    `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`

    Available voices for ElevenLabs

    `aria`, `roger`, `sarah`, `laura`, `charlie`, `george`, `callum`, `river`, `liam`, `charlotte`, `alice`, `matilda`, `will`, `jessica`, `eric`, `chris`, `brian`, `daniel`, `lily`, `bill`
    """

    response_format: Optional[CreateSpeechResponseFormat] = "mp3"
    r"""The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`. If a format is provided but not supported by the provider, the response will be in the default format. When the provided format is not supported by the provider, the response will be in the default format."""

    speed: Optional[float] = 1
    r"""The speed of the generated audio."""

    orq: Optional[CreateSpeechOrq] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["response_format", "speed", "orq"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
