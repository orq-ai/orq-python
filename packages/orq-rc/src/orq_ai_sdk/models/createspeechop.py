"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .publiccontact import PublicContact, PublicContactTypedDict
from .publicidentity import PublicIdentity, PublicIdentityTypedDict
from orq_ai_sdk.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Literal, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


CreateSpeechResponseFormat = Literal[
    "mp3",
    "opus",
    "aac",
    "flac",
    "wav",
    "pcm",
]
r"""The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`. If a format is provided but not supported by the provider, the response will be in the default format. When the provided format is not supported by the provider, the response will be in the default format."""


class CreateSpeechFallbacksTypedDict(TypedDict):
    model: str
    r"""Fallback model identifier"""


class CreateSpeechFallbacks(BaseModel):
    model: str
    r"""Fallback model identifier"""


class CreateSpeechRetryTypedDict(TypedDict):
    r"""Retry configuration for the request"""

    count: NotRequired[float]
    r"""Number of retry attempts (1-5)"""
    on_codes: NotRequired[List[float]]
    r"""HTTP status codes that trigger retry logic"""


class CreateSpeechRetry(BaseModel):
    r"""Retry configuration for the request"""

    count: Optional[float] = 3
    r"""Number of retry attempts (1-5)"""

    on_codes: Optional[List[float]] = None
    r"""HTTP status codes that trigger retry logic"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["count", "on_codes"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateSpeechLoadBalancerType = Literal["weight_based",]


class CreateSpeechLoadBalancerModelsTypedDict(TypedDict):
    model: str
    r"""Model identifier for load balancing"""
    weight: NotRequired[float]
    r"""Weight assigned to this model for load balancing"""


class CreateSpeechLoadBalancerModels(BaseModel):
    model: str
    r"""Model identifier for load balancing"""

    weight: Optional[float] = 0.5
    r"""Weight assigned to this model for load balancing"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["weight"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateSpeechLoadBalancer1TypedDict(TypedDict):
    type: CreateSpeechLoadBalancerType
    models: List[CreateSpeechLoadBalancerModelsTypedDict]


class CreateSpeechLoadBalancer1(BaseModel):
    type: CreateSpeechLoadBalancerType

    models: List[CreateSpeechLoadBalancerModels]


CreateSpeechLoadBalancerTypedDict = CreateSpeechLoadBalancer1TypedDict
r"""Load balancer configuration for the request."""


CreateSpeechLoadBalancer = CreateSpeechLoadBalancer1
r"""Load balancer configuration for the request."""


class CreateSpeechTimeoutTypedDict(TypedDict):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateSpeechTimeout(BaseModel):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateSpeechRouterAudioSpeechRetryTypedDict(TypedDict):
    r"""Retry configuration for the request"""

    count: NotRequired[float]
    r"""Number of retry attempts (1-5)"""
    on_codes: NotRequired[List[float]]
    r"""HTTP status codes that trigger retry logic"""


class CreateSpeechRouterAudioSpeechRetry(BaseModel):
    r"""Retry configuration for the request"""

    count: Optional[float] = 3
    r"""Number of retry attempts (1-5)"""

    on_codes: Optional[List[float]] = None
    r"""HTTP status codes that trigger retry logic"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["count", "on_codes"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateSpeechRouterAudioSpeechFallbacksTypedDict(TypedDict):
    model: str
    r"""Fallback model identifier"""


class CreateSpeechRouterAudioSpeechFallbacks(BaseModel):
    model: str
    r"""Fallback model identifier"""


class CreateSpeechThreadTypedDict(TypedDict):
    r"""Thread information to group related requests"""

    id: str
    r"""Unique thread identifier to group related invocations."""
    tags: NotRequired[List[str]]
    r"""Optional tags to differentiate or categorize threads"""


class CreateSpeechThread(BaseModel):
    r"""Thread information to group related requests"""

    id: str
    r"""Unique thread identifier to group related invocations."""

    tags: Optional[List[str]] = None
    r"""Optional tags to differentiate or categorize threads"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["tags"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateSpeechLoadBalancerRouterAudioSpeechType = Literal["weight_based",]


class CreateSpeechLoadBalancerRouterAudioSpeechModelsTypedDict(TypedDict):
    model: str
    r"""Model identifier for load balancing"""
    weight: NotRequired[float]
    r"""Weight assigned to this model for load balancing"""


class CreateSpeechLoadBalancerRouterAudioSpeechModels(BaseModel):
    model: str
    r"""Model identifier for load balancing"""

    weight: Optional[float] = 0.5
    r"""Weight assigned to this model for load balancing"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["weight"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateSpeechLoadBalancerRouterAudioSpeech1TypedDict(TypedDict):
    type: CreateSpeechLoadBalancerRouterAudioSpeechType
    models: List[CreateSpeechLoadBalancerRouterAudioSpeechModelsTypedDict]


class CreateSpeechLoadBalancerRouterAudioSpeech1(BaseModel):
    type: CreateSpeechLoadBalancerRouterAudioSpeechType

    models: List[CreateSpeechLoadBalancerRouterAudioSpeechModels]


CreateSpeechRouterAudioSpeechLoadBalancerTypedDict = (
    CreateSpeechLoadBalancerRouterAudioSpeech1TypedDict
)
r"""Array of models with weights for load balancing requests"""


CreateSpeechRouterAudioSpeechLoadBalancer = CreateSpeechLoadBalancerRouterAudioSpeech1
r"""Array of models with weights for load balancing requests"""


class CreateSpeechRouterAudioSpeechTimeoutTypedDict(TypedDict):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateSpeechRouterAudioSpeechTimeout(BaseModel):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateSpeechOrqTypedDict(TypedDict):
    retry: NotRequired[CreateSpeechRouterAudioSpeechRetryTypedDict]
    r"""Retry configuration for the request"""
    fallbacks: NotRequired[List[CreateSpeechRouterAudioSpeechFallbacksTypedDict]]
    r"""Array of fallback models to use if primary model fails"""
    name: NotRequired[str]
    r"""The name to display on the trace. If not specified, the default system name will be used."""
    identity: NotRequired[PublicIdentityTypedDict]
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""
    contact: NotRequired[PublicContactTypedDict]
    r"""@deprecated Use identity instead. Information about the contact making the request."""
    thread: NotRequired[CreateSpeechThreadTypedDict]
    r"""Thread information to group related requests"""
    load_balancer: NotRequired[CreateSpeechRouterAudioSpeechLoadBalancerTypedDict]
    r"""Array of models with weights for load balancing requests"""
    timeout: NotRequired[CreateSpeechRouterAudioSpeechTimeoutTypedDict]
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""


class CreateSpeechOrq(BaseModel):
    retry: Optional[CreateSpeechRouterAudioSpeechRetry] = None
    r"""Retry configuration for the request"""

    fallbacks: Optional[List[CreateSpeechRouterAudioSpeechFallbacks]] = None
    r"""Array of fallback models to use if primary model fails"""

    name: Optional[str] = None
    r"""The name to display on the trace. If not specified, the default system name will be used."""

    identity: Optional[PublicIdentity] = None
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""

    contact: Annotated[
        Optional[PublicContact],
        pydantic.Field(
            deprecated="warning: ** DEPRECATED ** - This will be removed in a future release, please migrate away from it as soon as possible."
        ),
    ] = None
    r"""@deprecated Use identity instead. Information about the contact making the request."""

    thread: Optional[CreateSpeechThread] = None
    r"""Thread information to group related requests"""

    load_balancer: Optional[CreateSpeechRouterAudioSpeechLoadBalancer] = None
    r"""Array of models with weights for load balancing requests"""

    timeout: Optional[CreateSpeechRouterAudioSpeechTimeout] = None
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "retry",
                "fallbacks",
                "name",
                "identity",
                "contact",
                "thread",
                "load_balancer",
                "timeout",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateSpeechRequestBodyTypedDict(TypedDict):
    r"""input"""

    input: str
    r"""The text to generate audio for. The maximum length is 4096 characters"""
    model: str
    r"""ID of the model to use"""
    voice: str
    r"""The voice to use.

    Available voices for OpenAI

    `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`

    Available voices for ElevenLabs

    `aria`, `roger`, `sarah`, `laura`, `charlie`, `george`, `callum`, `river`, `liam`, `charlotte`, `alice`, `matilda`, `will`, `jessica`, `eric`, `chris`, `brian`, `daniel`, `lily`, `bill`
    """
    response_format: NotRequired[CreateSpeechResponseFormat]
    r"""The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`. If a format is provided but not supported by the provider, the response will be in the default format. When the provided format is not supported by the provider, the response will be in the default format."""
    speed: NotRequired[float]
    r"""The speed of the generated audio."""
    name: NotRequired[str]
    r"""The name to display on the trace. If not specified, the default system name will be used."""
    fallbacks: NotRequired[List[CreateSpeechFallbacksTypedDict]]
    r"""Array of fallback models to use if primary model fails"""
    retry: NotRequired[CreateSpeechRetryTypedDict]
    r"""Retry configuration for the request"""
    load_balancer: NotRequired[CreateSpeechLoadBalancerTypedDict]
    r"""Load balancer configuration for the request."""
    timeout: NotRequired[CreateSpeechTimeoutTypedDict]
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""
    orq: NotRequired[CreateSpeechOrqTypedDict]


class CreateSpeechRequestBody(BaseModel):
    r"""input"""

    input: str
    r"""The text to generate audio for. The maximum length is 4096 characters"""

    model: str
    r"""ID of the model to use"""

    voice: str
    r"""The voice to use.

    Available voices for OpenAI

    `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`

    Available voices for ElevenLabs

    `aria`, `roger`, `sarah`, `laura`, `charlie`, `george`, `callum`, `river`, `liam`, `charlotte`, `alice`, `matilda`, `will`, `jessica`, `eric`, `chris`, `brian`, `daniel`, `lily`, `bill`
    """

    response_format: Optional[CreateSpeechResponseFormat] = "mp3"
    r"""The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`. If a format is provided but not supported by the provider, the response will be in the default format. When the provided format is not supported by the provider, the response will be in the default format."""

    speed: Optional[float] = 1
    r"""The speed of the generated audio."""

    name: Optional[str] = None
    r"""The name to display on the trace. If not specified, the default system name will be used."""

    fallbacks: Optional[List[CreateSpeechFallbacks]] = None
    r"""Array of fallback models to use if primary model fails"""

    retry: Optional[CreateSpeechRetry] = None
    r"""Retry configuration for the request"""

    load_balancer: Optional[CreateSpeechLoadBalancer] = None
    r"""Load balancer configuration for the request."""

    timeout: Optional[CreateSpeechTimeout] = None
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    orq: Optional[CreateSpeechOrq] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "response_format",
                "speed",
                "name",
                "fallbacks",
                "retry",
                "load_balancer",
                "timeout",
                "orq",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
