"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from orq_ai_sdk.utils import (
    FieldMetadata,
    PathParamMetadata,
    RequestMetadata,
    get_discriminator,
)
import pydantic
from pydantic import Discriminator, Tag, model_serializer
from typing import Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


CreateDatasourceChunkingConfigurationType = Literal["advanced",]


class ChunkingConfiguration2TypedDict(TypedDict):
    r"""Provides advanced settings for customizing chunking behavior, enabling fine-grained control to better meet specific data processing needs."""

    type: CreateDatasourceChunkingConfigurationType
    chunk_max_characters: NotRequired[float]
    r"""Defines the absolute maximum character length per chunk. Text elements exceeding this size will be automatically split into multiple chunks."""
    chunk_overlap: NotRequired[float]
    r"""Specifies the number of characters to overlap between consecutive chunks. This overlap helps maintain semantic continuity when splitting large text elements."""


class ChunkingConfiguration2(BaseModel):
    r"""Provides advanced settings for customizing chunking behavior, enabling fine-grained control to better meet specific data processing needs."""

    type: CreateDatasourceChunkingConfigurationType

    chunk_max_characters: Optional[float] = 500
    r"""Defines the absolute maximum character length per chunk. Text elements exceeding this size will be automatically split into multiple chunks."""

    chunk_overlap: Optional[float] = 0
    r"""Specifies the number of characters to overlap between consecutive chunks. This overlap helps maintain semantic continuity when splitting large text elements."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["chunk_max_characters", "chunk_overlap"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


ChunkingConfigurationType = Literal["default",]


class ChunkingConfiguration1TypedDict(TypedDict):
    r"""Optimized chunking strategy focusing on speed and avoiding duplication of content chunks."""

    type: ChunkingConfigurationType


class ChunkingConfiguration1(BaseModel):
    r"""Optimized chunking strategy focusing on speed and avoiding duplication of content chunks."""

    type: ChunkingConfigurationType


ChunkingConfigurationTypedDict = TypeAliasType(
    "ChunkingConfigurationTypedDict",
    Union[ChunkingConfiguration1TypedDict, ChunkingConfiguration2TypedDict],
)
r"""The chunking configuration settings for the datasource. Defaults to the system's standard chunking configuration if not specified."""


ChunkingConfiguration = Annotated[
    Union[
        Annotated[ChunkingConfiguration1, Tag("default")],
        Annotated[ChunkingConfiguration2, Tag("advanced")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]
r"""The chunking configuration settings for the datasource. Defaults to the system's standard chunking configuration if not specified."""


class ChunkingCleanupOptionsTypedDict(TypedDict):
    r"""The cleanup options applied to the datasource content. All options are enabled by default to ensure enhanced security and optimal chunk quality. Defaults to system-standard cleanup options if not specified."""

    delete_emails: NotRequired[bool]
    r"""Removes email addresses from the provided text."""
    delete_credit_cards: NotRequired[bool]
    r"""Removes credit card numbers from the provided text."""
    delete_phone_numbers: NotRequired[bool]
    r"""Removes phone numbers from the provided text."""
    clean_bullet_points: NotRequired[bool]
    r"""Removes bullet points formatting from the text."""
    clean_numbered_list: NotRequired[bool]
    r"""Removes numbered list formatting from the text."""
    clean_unicode: NotRequired[bool]
    r"""Normalizes or removes unnecessary unicode characters from the text."""
    clean_dashes: NotRequired[bool]
    r"""Normalizes or removes various dash characters to standardize the text."""
    clean_whitespaces: NotRequired[bool]
    r"""Trims and normalizes excessive whitespace throughout the text."""


class ChunkingCleanupOptions(BaseModel):
    r"""The cleanup options applied to the datasource content. All options are enabled by default to ensure enhanced security and optimal chunk quality. Defaults to system-standard cleanup options if not specified."""

    delete_emails: Optional[bool] = None
    r"""Removes email addresses from the provided text."""

    delete_credit_cards: Optional[bool] = None
    r"""Removes credit card numbers from the provided text."""

    delete_phone_numbers: Optional[bool] = None
    r"""Removes phone numbers from the provided text."""

    clean_bullet_points: Optional[bool] = None
    r"""Removes bullet points formatting from the text."""

    clean_numbered_list: Optional[bool] = None
    r"""Removes numbered list formatting from the text."""

    clean_unicode: Optional[bool] = None
    r"""Normalizes or removes unnecessary unicode characters from the text."""

    clean_dashes: Optional[bool] = None
    r"""Normalizes or removes various dash characters to standardize the text."""

    clean_whitespaces: Optional[bool] = None
    r"""Trims and normalizes excessive whitespace throughout the text."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "delete_emails",
                "delete_credit_cards",
                "delete_phone_numbers",
                "clean_bullet_points",
                "clean_numbered_list",
                "clean_unicode",
                "clean_dashes",
                "clean_whitespaces",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class ChunkingOptionsTypedDict(TypedDict):
    r"""Configuration options specifying how the datasource file is chunked. Required if `file_id` is specified. Defaults to standard chunking options if omitted."""

    chunking_configuration: NotRequired[ChunkingConfigurationTypedDict]
    r"""The chunking configuration settings for the datasource. Defaults to the system's standard chunking configuration if not specified."""
    chunking_cleanup_options: NotRequired[ChunkingCleanupOptionsTypedDict]
    r"""The cleanup options applied to the datasource content. All options are enabled by default to ensure enhanced security and optimal chunk quality. Defaults to system-standard cleanup options if not specified."""


class ChunkingOptions(BaseModel):
    r"""Configuration options specifying how the datasource file is chunked. Required if `file_id` is specified. Defaults to standard chunking options if omitted."""

    chunking_configuration: Optional[ChunkingConfiguration] = None
    r"""The chunking configuration settings for the datasource. Defaults to the system's standard chunking configuration if not specified."""

    chunking_cleanup_options: Optional[ChunkingCleanupOptions] = None
    r"""The cleanup options applied to the datasource content. All options are enabled by default to ensure enhanced security and optimal chunk quality. Defaults to system-standard cleanup options if not specified."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["chunking_configuration", "chunking_cleanup_options"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateDatasourceRequestBodyTypedDict(TypedDict):
    display_name: NotRequired[str]
    r"""The display name for the datasource visible in the UI. If omitted, the display name is derived from the uploaded file. When both `display_name` and `file_id` are provided, the provided `display_name` is prioritized."""
    file_id: NotRequired[str]
    r"""The unique identifier of the file used for datasource creation. If provided, the file is immediately queued for chunking."""
    chunking_options: NotRequired[ChunkingOptionsTypedDict]
    r"""Configuration options specifying how the datasource file is chunked. Required if `file_id` is specified. Defaults to standard chunking options if omitted."""


class CreateDatasourceRequestBody(BaseModel):
    display_name: Optional[str] = None
    r"""The display name for the datasource visible in the UI. If omitted, the display name is derived from the uploaded file. When both `display_name` and `file_id` are provided, the provided `display_name` is prioritized."""

    file_id: Optional[str] = None
    r"""The unique identifier of the file used for datasource creation. If provided, the file is immediately queued for chunking."""

    chunking_options: Optional[ChunkingOptions] = None
    r"""Configuration options specifying how the datasource file is chunked. Required if `file_id` is specified. Defaults to standard chunking options if omitted."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["display_name", "file_id", "chunking_options"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateDatasourceRequestTypedDict(TypedDict):
    knowledge_id: str
    r"""The unique identifier of the knowledge base"""
    request_body: CreateDatasourceRequestBodyTypedDict


class CreateDatasourceRequest(BaseModel):
    knowledge_id: Annotated[
        str, FieldMetadata(path=PathParamMetadata(style="simple", explode=False))
    ]
    r"""The unique identifier of the knowledge base"""

    request_body: Annotated[
        CreateDatasourceRequestBody,
        FieldMetadata(request=RequestMetadata(media_type="application/json")),
    ]


CreateDatasourceStatus = Literal[
    "pending",
    "processing",
    "completed",
    "failed",
    "queued",
]


class CreateDatasourceResponseBodyTypedDict(TypedDict):
    r"""Datasource successfully created"""

    display_name: str
    r"""The display name of the datasource. Normally the name of the uploaded file"""
    status: CreateDatasourceStatus
    created: str
    r"""The date and time the datasource was created"""
    updated: str
    r"""The date and time the datasource was updated"""
    knowledge_id: str
    r"""The unique identifier of the knowledge base"""
    chunks_count: float
    r"""The number of chunks in the datasource"""
    id: NotRequired[str]
    r"""The unique identifier of the data source"""
    description: NotRequired[str]
    r"""The description of the knowledge base"""
    file_id: NotRequired[Nullable[str]]
    r"""The unique identifier of the file used to create the datasource."""
    created_by_id: NotRequired[Nullable[str]]
    r"""The user ID of the creator of the knowledge base"""
    update_by_id: NotRequired[Nullable[str]]
    r"""The user ID of the last user who updated the knowledge base"""


class CreateDatasourceResponseBody(BaseModel):
    r"""Datasource successfully created"""

    display_name: str
    r"""The display name of the datasource. Normally the name of the uploaded file"""

    status: CreateDatasourceStatus

    created: str
    r"""The date and time the datasource was created"""

    updated: str
    r"""The date and time the datasource was updated"""

    knowledge_id: str
    r"""The unique identifier of the knowledge base"""

    chunks_count: float
    r"""The number of chunks in the datasource"""

    id: Annotated[Optional[str], pydantic.Field(alias="_id")] = (
        "01KGQ98MQ8E5V3ZD7H84RTRYRR"
    )
    r"""The unique identifier of the data source"""

    description: Optional[str] = None
    r"""The description of the knowledge base"""

    file_id: OptionalNullable[str] = UNSET
    r"""The unique identifier of the file used to create the datasource."""

    created_by_id: OptionalNullable[str] = UNSET
    r"""The user ID of the creator of the knowledge base"""

    update_by_id: OptionalNullable[str] = UNSET
    r"""The user ID of the last user who updated the knowledge base"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            ["_id", "description", "file_id", "created_by_id", "update_by_id"]
        )
        nullable_fields = set(["file_id", "created_by_id", "update_by_id"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m
