"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from orq_ai_sdk.utils import FieldMetadata
from pydantic import model_serializer
from typing import Any, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


ImageTypedDict = TypeAliasType("ImageTypedDict", Union[Any, List[Any]])
r"""The image(s) to edit. Must be a supported image file or an array of images.  Each image should be a png, webp, or jpg file less than 50MB. You can provide up to 16 images."""


Image = TypeAliasType("Image", Union[Any, List[Any]])
r"""The image(s) to edit. Must be a supported image file or an array of images.  Each image should be a png, webp, or jpg file less than 50MB. You can provide up to 16 images."""


PostV2ProxyImagesEditsResponseFormat = Literal["url", "b64_json"]
r"""The format in which the generated images are returned. Some of the models only return the image in base64 format."""


class PostV2ProxyImagesEditsRequestBodyTypedDict(TypedDict):
    model: str
    r"""The model to use for image generation. [Check models](https://docs.orq.ai/docs/proxy#/image-models)"""
    image: ImageTypedDict
    r"""The image(s) to edit. Must be a supported image file or an array of images.  Each image should be a png, webp, or jpg file less than 50MB. You can provide up to 16 images."""
    prompt: str
    r"""A text description of the desired image(s)."""
    n: NotRequired[Nullable[int]]
    r"""The number of images to generate. Must be between 1 and 10."""
    size: NotRequired[Nullable[str]]
    r"""The size of the generated images"""
    response_format: NotRequired[Nullable[PostV2ProxyImagesEditsResponseFormat]]
    r"""The format in which the generated images are returned. Some of the models only return the image in base64 format."""
    user: NotRequired[str]
    r"""A unique identifier representing your end-user, which can help to monitor and detect abuse."""


class PostV2ProxyImagesEditsRequestBody(BaseModel):
    model: Annotated[str, FieldMetadata(multipart=True)]
    r"""The model to use for image generation. [Check models](https://docs.orq.ai/docs/proxy#/image-models)"""

    image: Annotated[Image, FieldMetadata(multipart=True)]
    r"""The image(s) to edit. Must be a supported image file or an array of images.  Each image should be a png, webp, or jpg file less than 50MB. You can provide up to 16 images."""

    prompt: Annotated[str, FieldMetadata(multipart=True)]
    r"""A text description of the desired image(s)."""

    n: Annotated[OptionalNullable[int], FieldMetadata(multipart=True)] = 1
    r"""The number of images to generate. Must be between 1 and 10."""

    size: Annotated[OptionalNullable[str], FieldMetadata(multipart=True)] = UNSET
    r"""The size of the generated images"""

    response_format: Annotated[
        OptionalNullable[PostV2ProxyImagesEditsResponseFormat],
        FieldMetadata(multipart=True),
    ] = "url"
    r"""The format in which the generated images are returned. Some of the models only return the image in base64 format."""

    user: Annotated[Optional[str], FieldMetadata(multipart=True)] = None
    r"""A unique identifier representing your end-user, which can help to monitor and detect abuse."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["n", "size", "response_format", "user"]
        nullable_fields = ["n", "size", "response_format"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PostV2ProxyImagesEditsDataTypedDict(TypedDict):
    b64_json: NotRequired[str]
    r"""The base64-encoded JSON of the generated image, if response_format is b64_json"""
    url: NotRequired[str]
    r"""The URL of the generated image, if response_format is url (default)"""


class PostV2ProxyImagesEditsData(BaseModel):
    b64_json: Optional[str] = None
    r"""The base64-encoded JSON of the generated image, if response_format is b64_json"""

    url: Optional[str] = None
    r"""The URL of the generated image, if response_format is url (default)"""


class PostV2ProxyImagesEditsInputTokensDetailsTypedDict(TypedDict):
    r"""The input tokens detailed information for the image generation."""

    text_tokens: float
    r"""The number of text tokens in the input prompt."""
    image_tokens: float
    r"""The number of image tokens in the input prompt."""


class PostV2ProxyImagesEditsInputTokensDetails(BaseModel):
    r"""The input tokens detailed information for the image generation."""

    text_tokens: float
    r"""The number of text tokens in the input prompt."""

    image_tokens: float
    r"""The number of image tokens in the input prompt."""


class PostV2ProxyImagesEditsUsageTypedDict(TypedDict):
    r"""The token usage information for the image generation."""

    total_tokens: float
    r"""The total number of tokens (images and text) used for the image generation."""
    input_tokens: float
    r"""The number of tokens (images and text) in the input prompt."""
    output_tokens: float
    r"""The number of output tokens generated by the model."""
    input_tokens_details: PostV2ProxyImagesEditsInputTokensDetailsTypedDict
    r"""The input tokens detailed information for the image generation."""


class PostV2ProxyImagesEditsUsage(BaseModel):
    r"""The token usage information for the image generation."""

    total_tokens: float
    r"""The total number of tokens (images and text) used for the image generation."""

    input_tokens: float
    r"""The number of tokens (images and text) in the input prompt."""

    output_tokens: float
    r"""The number of output tokens generated by the model."""

    input_tokens_details: PostV2ProxyImagesEditsInputTokensDetails
    r"""The input tokens detailed information for the image generation."""


class PostV2ProxyImagesEditsResponseBodyTypedDict(TypedDict):
    r"""Represents an image edit response from the API."""

    created: float
    r"""The Unix timestamp (in seconds) of when the image was created."""
    data: List[PostV2ProxyImagesEditsDataTypedDict]
    r"""The list of generated images."""
    output_format: NotRequired[str]
    r"""The output format of the image generation"""
    size: NotRequired[str]
    r"""The size of the image generated"""
    quality: NotRequired[str]
    r"""The quality of the image generated"""
    usage: NotRequired[PostV2ProxyImagesEditsUsageTypedDict]
    r"""The token usage information for the image generation."""


class PostV2ProxyImagesEditsResponseBody(BaseModel):
    r"""Represents an image edit response from the API."""

    created: float
    r"""The Unix timestamp (in seconds) of when the image was created."""

    data: List[PostV2ProxyImagesEditsData]
    r"""The list of generated images."""

    output_format: Optional[str] = None
    r"""The output format of the image generation"""

    size: Optional[str] = None
    r"""The size of the image generated"""

    quality: Optional[str] = None
    r"""The quality of the image generated"""

    usage: Optional[PostV2ProxyImagesEditsUsage] = None
    r"""The token usage information for the image generation."""
