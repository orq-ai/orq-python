"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from .sdkconfiguration import SDKConfiguration
from orq_ai_sdk import models, utils
from orq_ai_sdk._hooks import HookContext
from orq_ai_sdk.metrics import Metrics
from orq_ai_sdk.models import (
    deploymentgetconfigop as models_deploymentgetconfigop,
    deploymentstreamop as models_deploymentstreamop,
    invokedeploymentrequest as models_invokedeploymentrequest,
)
from orq_ai_sdk.types import OptionalNullable, UNSET
from orq_ai_sdk.utils import eventstreaming, get_security_from_env
from orq_ai_sdk.utils.unmarshal_json_response import unmarshal_json_response
from typing import Any, Dict, List, Mapping, Optional, Union


class Deployments(BaseSDK):
    metrics: Metrics

    def __init__(
        self, sdk_config: SDKConfiguration, parent_ref: Optional[object] = None
    ) -> None:
        BaseSDK.__init__(self, sdk_config, parent_ref=parent_ref)
        self.sdk_configuration = sdk_config
        self._init_sdks()

    def _init_sdks(self):
        self.metrics = Metrics(self.sdk_configuration, parent_ref=self.parent_ref)

    def invoke(
        self,
        *,
        key: str,
        stream: Optional[bool] = False,
        inputs: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None,
        prefix_messages: Optional[
            Union[
                List[models_invokedeploymentrequest.PrefixMessages],
                List[models_invokedeploymentrequest.PrefixMessagesTypedDict],
            ]
        ] = None,
        messages: Optional[
            Union[
                List[models_invokedeploymentrequest.Messages],
                List[models_invokedeploymentrequest.MessagesTypedDict],
            ]
        ] = None,
        file_ids: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        extra_params: Optional[Dict[str, Any]] = None,
        documents: Optional[
            Union[
                List[models_invokedeploymentrequest.Documents],
                List[models_invokedeploymentrequest.DocumentsTypedDict],
            ]
        ] = None,
        invoke_options: Optional[
            Union[
                models_invokedeploymentrequest.InvokeOptions,
                models_invokedeploymentrequest.InvokeOptionsTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_invokedeploymentrequest.Thread,
                models_invokedeploymentrequest.ThreadTypedDict,
            ]
        ] = None,
        knowledge_filter: Optional[
            Union[
                models_invokedeploymentrequest.KnowledgeFilter,
                models_invokedeploymentrequest.KnowledgeFilterTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[models.DeploymentInvokeResponseBody]:
        r"""Invoke

        Invoke a deployment with a given payload

        :param key: The deployment key to invoke
        :param stream: If set, partial message content will be sent. Tokens will be sent as data-only `server-sent events` as they become available, with the stream terminated by a `data: [DONE]` message.
        :param inputs: Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used.
        :param context: Key-value pairs that match your data model and fields declared in your deployment routing configuration
        :param prefix_messages: A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment.
        :param messages: A list of messages to send to the deployment.
        :param file_ids: A list of file IDs that are associated with the deployment request.
        :param metadata: Key-value pairs that you want to attach to the log generated by this request.
        :param extra_params: Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration.
        :param documents: A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings.
        :param invoke_options:
        :param thread:
        :param knowledge_filter: A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.InvokeDeploymentRequest(
            key=key,
            stream=stream,
            inputs=inputs,
            context=context,
            prefix_messages=utils.get_pydantic_model(
                prefix_messages, Optional[List[models.PrefixMessages]]
            ),
            messages=utils.get_pydantic_model(
                messages, Optional[List[models.Messages]]
            ),
            file_ids=file_ids,
            metadata=metadata,
            extra_params=extra_params,
            documents=utils.get_pydantic_model(
                documents, Optional[List[models.Documents]]
            ),
            invoke_options=utils.get_pydantic_model(
                invoke_options, Optional[models.InvokeOptions]
            ),
            thread=utils.get_pydantic_model(thread, Optional[models.Thread]),
            knowledge_filter=utils.get_pydantic_model(
                knowledge_filter, Optional[models.KnowledgeFilter]
            ),
        )

        req = self._build_request(
            method="POST",
            path="/v2/deployments/invoke",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            _globals=models.DeploymentInvokeGlobals(
                environment=self.sdk_configuration.globals.environment,
                contact_id=self.sdk_configuration.globals.contact_id,
            ),
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.InvokeDeploymentRequest
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="DeploymentInvoke",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                Optional[models.DeploymentInvokeResponseBody], http_res
            )
        if utils.match_response(http_res, "204", "*"):
            return None
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)

    async def invoke_async(
        self,
        *,
        key: str,
        stream: Optional[bool] = False,
        inputs: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None,
        prefix_messages: Optional[
            Union[
                List[models_invokedeploymentrequest.PrefixMessages],
                List[models_invokedeploymentrequest.PrefixMessagesTypedDict],
            ]
        ] = None,
        messages: Optional[
            Union[
                List[models_invokedeploymentrequest.Messages],
                List[models_invokedeploymentrequest.MessagesTypedDict],
            ]
        ] = None,
        file_ids: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        extra_params: Optional[Dict[str, Any]] = None,
        documents: Optional[
            Union[
                List[models_invokedeploymentrequest.Documents],
                List[models_invokedeploymentrequest.DocumentsTypedDict],
            ]
        ] = None,
        invoke_options: Optional[
            Union[
                models_invokedeploymentrequest.InvokeOptions,
                models_invokedeploymentrequest.InvokeOptionsTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_invokedeploymentrequest.Thread,
                models_invokedeploymentrequest.ThreadTypedDict,
            ]
        ] = None,
        knowledge_filter: Optional[
            Union[
                models_invokedeploymentrequest.KnowledgeFilter,
                models_invokedeploymentrequest.KnowledgeFilterTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[models.DeploymentInvokeResponseBody]:
        r"""Invoke

        Invoke a deployment with a given payload

        :param key: The deployment key to invoke
        :param stream: If set, partial message content will be sent. Tokens will be sent as data-only `server-sent events` as they become available, with the stream terminated by a `data: [DONE]` message.
        :param inputs: Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used.
        :param context: Key-value pairs that match your data model and fields declared in your deployment routing configuration
        :param prefix_messages: A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment.
        :param messages: A list of messages to send to the deployment.
        :param file_ids: A list of file IDs that are associated with the deployment request.
        :param metadata: Key-value pairs that you want to attach to the log generated by this request.
        :param extra_params: Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration.
        :param documents: A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings.
        :param invoke_options:
        :param thread:
        :param knowledge_filter: A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.InvokeDeploymentRequest(
            key=key,
            stream=stream,
            inputs=inputs,
            context=context,
            prefix_messages=utils.get_pydantic_model(
                prefix_messages, Optional[List[models.PrefixMessages]]
            ),
            messages=utils.get_pydantic_model(
                messages, Optional[List[models.Messages]]
            ),
            file_ids=file_ids,
            metadata=metadata,
            extra_params=extra_params,
            documents=utils.get_pydantic_model(
                documents, Optional[List[models.Documents]]
            ),
            invoke_options=utils.get_pydantic_model(
                invoke_options, Optional[models.InvokeOptions]
            ),
            thread=utils.get_pydantic_model(thread, Optional[models.Thread]),
            knowledge_filter=utils.get_pydantic_model(
                knowledge_filter, Optional[models.KnowledgeFilter]
            ),
        )

        req = self._build_request_async(
            method="POST",
            path="/v2/deployments/invoke",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            _globals=models.DeploymentInvokeGlobals(
                environment=self.sdk_configuration.globals.environment,
                contact_id=self.sdk_configuration.globals.contact_id,
            ),
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.InvokeDeploymentRequest
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="DeploymentInvoke",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                Optional[models.DeploymentInvokeResponseBody], http_res
            )
        if utils.match_response(http_res, "204", "*"):
            return None
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)

    def list(
        self,
        *,
        limit: Optional[float] = 10,
        starting_after: Optional[str] = None,
        ending_before: Optional[str] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[models.DeploymentsResponseBody]:
        r"""List all deployments

        Returns a list of your deployments. The deployments are returned sorted by creation date, with the most recent deployments appearing first.

        :param limit: A limit on the number of objects to be returned. Limit can range between 1 and 50, and the default is 10
        :param starting_after: A cursor for use in pagination. `starting_after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 20 objects, ending with `01JJ1HDHN79XAS7A01WB3HYSDB`, your subsequent call can include `after=01JJ1HDHN79XAS7A01WB3HYSDB` in order to fetch the next page of the list.
        :param ending_before: A cursor for use in pagination. `ending_before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 20 objects, starting with `01JJ1HDHN79XAS7A01WB3HYSDB`, your subsequent call can include `before=01JJ1HDHN79XAS7A01WB3HYSDB` in order to fetch the previous page of the list.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.DeploymentsRequest(
            limit=limit,
            starting_after=starting_after,
            ending_before=ending_before,
        )

        req = self._build_request(
            method="GET",
            path="/v2/deployments",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=False,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="Deployments",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                Optional[models.DeploymentsResponseBody], http_res
            )
        if utils.match_response(http_res, "500", "application/json"):
            response_data = unmarshal_json_response(models.HonoAPIErrorData, http_res)
            raise models.HonoAPIError(response_data, http_res)
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)

    async def list_async(
        self,
        *,
        limit: Optional[float] = 10,
        starting_after: Optional[str] = None,
        ending_before: Optional[str] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[models.DeploymentsResponseBody]:
        r"""List all deployments

        Returns a list of your deployments. The deployments are returned sorted by creation date, with the most recent deployments appearing first.

        :param limit: A limit on the number of objects to be returned. Limit can range between 1 and 50, and the default is 10
        :param starting_after: A cursor for use in pagination. `starting_after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 20 objects, ending with `01JJ1HDHN79XAS7A01WB3HYSDB`, your subsequent call can include `after=01JJ1HDHN79XAS7A01WB3HYSDB` in order to fetch the next page of the list.
        :param ending_before: A cursor for use in pagination. `ending_before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 20 objects, starting with `01JJ1HDHN79XAS7A01WB3HYSDB`, your subsequent call can include `before=01JJ1HDHN79XAS7A01WB3HYSDB` in order to fetch the previous page of the list.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.DeploymentsRequest(
            limit=limit,
            starting_after=starting_after,
            ending_before=ending_before,
        )

        req = self._build_request_async(
            method="GET",
            path="/v2/deployments",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=False,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="Deployments",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                Optional[models.DeploymentsResponseBody], http_res
            )
        if utils.match_response(http_res, "500", "application/json"):
            response_data = unmarshal_json_response(models.HonoAPIErrorData, http_res)
            raise models.HonoAPIError(response_data, http_res)
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)

    def get_config(
        self,
        *,
        key: str,
        inputs: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None,
        prefix_messages: Optional[
            Union[
                List[models_deploymentgetconfigop.DeploymentGetConfigPrefixMessages],
                List[
                    models_deploymentgetconfigop.DeploymentGetConfigPrefixMessagesTypedDict
                ],
            ]
        ] = None,
        messages: Optional[
            Union[
                List[models_deploymentgetconfigop.DeploymentGetConfigMessages],
                List[models_deploymentgetconfigop.DeploymentGetConfigMessagesTypedDict],
            ]
        ] = None,
        file_ids: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        extra_params: Optional[Dict[str, Any]] = None,
        documents: Optional[
            Union[
                List[models_deploymentgetconfigop.DeploymentGetConfigDocuments],
                List[
                    models_deploymentgetconfigop.DeploymentGetConfigDocumentsTypedDict
                ],
            ]
        ] = None,
        invoke_options: Optional[
            Union[
                models_deploymentgetconfigop.DeploymentGetConfigInvokeOptions,
                models_deploymentgetconfigop.DeploymentGetConfigInvokeOptionsTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_deploymentgetconfigop.DeploymentGetConfigThread,
                models_deploymentgetconfigop.DeploymentGetConfigThreadTypedDict,
            ]
        ] = None,
        knowledge_filter: Optional[
            Union[
                models_deploymentgetconfigop.DeploymentGetConfigKnowledgeFilter,
                models_deploymentgetconfigop.DeploymentGetConfigKnowledgeFilterTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[models.DeploymentGetConfigResponseBody]:
        r"""Get config

        Retrieve the deployment configuration

        :param key: The deployment key to invoke
        :param inputs: Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used.
        :param context: Key-value pairs that match your data model and fields declared in your deployment routing configuration
        :param prefix_messages: A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment.
        :param messages: A list of messages to send to the deployment.
        :param file_ids: A list of file IDs that are associated with the deployment request.
        :param metadata: Key-value pairs that you want to attach to the log generated by this request.
        :param extra_params: Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration.
        :param documents: A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings.
        :param invoke_options:
        :param thread:
        :param knowledge_filter: A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.DeploymentGetConfigRequestBody(
            key=key,
            inputs=inputs,
            context=context,
            prefix_messages=utils.get_pydantic_model(
                prefix_messages,
                Optional[List[models.DeploymentGetConfigPrefixMessages]],
            ),
            messages=utils.get_pydantic_model(
                messages, Optional[List[models.DeploymentGetConfigMessages]]
            ),
            file_ids=file_ids,
            metadata=metadata,
            extra_params=extra_params,
            documents=utils.get_pydantic_model(
                documents, Optional[List[models.DeploymentGetConfigDocuments]]
            ),
            invoke_options=utils.get_pydantic_model(
                invoke_options, Optional[models.DeploymentGetConfigInvokeOptions]
            ),
            thread=utils.get_pydantic_model(
                thread, Optional[models.DeploymentGetConfigThread]
            ),
            knowledge_filter=utils.get_pydantic_model(
                knowledge_filter, Optional[models.DeploymentGetConfigKnowledgeFilter]
            ),
        )

        req = self._build_request(
            method="POST",
            path="/v2/deployments/get_config",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.DeploymentGetConfigRequestBody
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="DeploymentGetConfig",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["401", "4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                Optional[models.DeploymentGetConfigResponseBody], http_res
            )
        if utils.match_response(http_res, "204", "*"):
            return None
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)

    async def get_config_async(
        self,
        *,
        key: str,
        inputs: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None,
        prefix_messages: Optional[
            Union[
                List[models_deploymentgetconfigop.DeploymentGetConfigPrefixMessages],
                List[
                    models_deploymentgetconfigop.DeploymentGetConfigPrefixMessagesTypedDict
                ],
            ]
        ] = None,
        messages: Optional[
            Union[
                List[models_deploymentgetconfigop.DeploymentGetConfigMessages],
                List[models_deploymentgetconfigop.DeploymentGetConfigMessagesTypedDict],
            ]
        ] = None,
        file_ids: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        extra_params: Optional[Dict[str, Any]] = None,
        documents: Optional[
            Union[
                List[models_deploymentgetconfigop.DeploymentGetConfigDocuments],
                List[
                    models_deploymentgetconfigop.DeploymentGetConfigDocumentsTypedDict
                ],
            ]
        ] = None,
        invoke_options: Optional[
            Union[
                models_deploymentgetconfigop.DeploymentGetConfigInvokeOptions,
                models_deploymentgetconfigop.DeploymentGetConfigInvokeOptionsTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_deploymentgetconfigop.DeploymentGetConfigThread,
                models_deploymentgetconfigop.DeploymentGetConfigThreadTypedDict,
            ]
        ] = None,
        knowledge_filter: Optional[
            Union[
                models_deploymentgetconfigop.DeploymentGetConfigKnowledgeFilter,
                models_deploymentgetconfigop.DeploymentGetConfigKnowledgeFilterTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[models.DeploymentGetConfigResponseBody]:
        r"""Get config

        Retrieve the deployment configuration

        :param key: The deployment key to invoke
        :param inputs: Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used.
        :param context: Key-value pairs that match your data model and fields declared in your deployment routing configuration
        :param prefix_messages: A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment.
        :param messages: A list of messages to send to the deployment.
        :param file_ids: A list of file IDs that are associated with the deployment request.
        :param metadata: Key-value pairs that you want to attach to the log generated by this request.
        :param extra_params: Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration.
        :param documents: A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings.
        :param invoke_options:
        :param thread:
        :param knowledge_filter: A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.DeploymentGetConfigRequestBody(
            key=key,
            inputs=inputs,
            context=context,
            prefix_messages=utils.get_pydantic_model(
                prefix_messages,
                Optional[List[models.DeploymentGetConfigPrefixMessages]],
            ),
            messages=utils.get_pydantic_model(
                messages, Optional[List[models.DeploymentGetConfigMessages]]
            ),
            file_ids=file_ids,
            metadata=metadata,
            extra_params=extra_params,
            documents=utils.get_pydantic_model(
                documents, Optional[List[models.DeploymentGetConfigDocuments]]
            ),
            invoke_options=utils.get_pydantic_model(
                invoke_options, Optional[models.DeploymentGetConfigInvokeOptions]
            ),
            thread=utils.get_pydantic_model(
                thread, Optional[models.DeploymentGetConfigThread]
            ),
            knowledge_filter=utils.get_pydantic_model(
                knowledge_filter, Optional[models.DeploymentGetConfigKnowledgeFilter]
            ),
        )

        req = self._build_request_async(
            method="POST",
            path="/v2/deployments/get_config",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.DeploymentGetConfigRequestBody
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="DeploymentGetConfig",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["401", "4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(
                Optional[models.DeploymentGetConfigResponseBody], http_res
            )
        if utils.match_response(http_res, "204", "*"):
            return None
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        raise models.APIError("Unexpected response received", http_res)

    def stream(
        self,
        *,
        key: str,
        inputs: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None,
        prefix_messages: Optional[
            Union[
                List[models_deploymentstreamop.DeploymentStreamPrefixMessages],
                List[models_deploymentstreamop.DeploymentStreamPrefixMessagesTypedDict],
            ]
        ] = None,
        messages: Optional[
            Union[
                List[models_deploymentstreamop.DeploymentStreamMessages],
                List[models_deploymentstreamop.DeploymentStreamMessagesTypedDict],
            ]
        ] = None,
        file_ids: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        extra_params: Optional[Dict[str, Any]] = None,
        documents: Optional[
            Union[
                List[models_deploymentstreamop.DeploymentStreamDocuments],
                List[models_deploymentstreamop.DeploymentStreamDocumentsTypedDict],
            ]
        ] = None,
        invoke_options: Optional[
            Union[
                models_deploymentstreamop.DeploymentStreamInvokeOptions,
                models_deploymentstreamop.DeploymentStreamInvokeOptionsTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_deploymentstreamop.DeploymentStreamThread,
                models_deploymentstreamop.DeploymentStreamThreadTypedDict,
            ]
        ] = None,
        knowledge_filter: Optional[
            Union[
                models_deploymentstreamop.DeploymentStreamKnowledgeFilter,
                models_deploymentstreamop.DeploymentStreamKnowledgeFilterTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[eventstreaming.EventStream[models.DeploymentStreamResponseBody]]:
        r"""Stream

        Stream deployment generation. Only supported for completions and chat completions.

        :param key: The deployment key to invoke
        :param inputs: Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used.
        :param context: Key-value pairs that match your data model and fields declared in your deployment routing configuration
        :param prefix_messages: A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment.
        :param messages: A list of messages to send to the deployment.
        :param file_ids: A list of file IDs that are associated with the deployment request.
        :param metadata: Key-value pairs that you want to attach to the log generated by this request.
        :param extra_params: Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration.
        :param documents: A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings.
        :param invoke_options:
        :param thread:
        :param knowledge_filter: A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.DeploymentStreamRequestBody(
            key=key,
            inputs=inputs,
            context=context,
            prefix_messages=utils.get_pydantic_model(
                prefix_messages, Optional[List[models.DeploymentStreamPrefixMessages]]
            ),
            messages=utils.get_pydantic_model(
                messages, Optional[List[models.DeploymentStreamMessages]]
            ),
            file_ids=file_ids,
            metadata=metadata,
            extra_params=extra_params,
            documents=utils.get_pydantic_model(
                documents, Optional[List[models.DeploymentStreamDocuments]]
            ),
            invoke_options=utils.get_pydantic_model(
                invoke_options, Optional[models.DeploymentStreamInvokeOptions]
            ),
            thread=utils.get_pydantic_model(
                thread, Optional[models.DeploymentStreamThread]
            ),
            knowledge_filter=utils.get_pydantic_model(
                knowledge_filter, Optional[models.DeploymentStreamKnowledgeFilter]
            ),
        )

        req = self._build_request(
            method="POST",
            path="/v2/deployments/stream",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="text/event-stream",
            http_headers=http_headers,
            _globals=models.DeploymentStreamGlobals(
                environment=self.sdk_configuration.globals.environment,
                contact_id=self.sdk_configuration.globals.contact_id,
            ),
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.DeploymentStreamRequestBody
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="DeploymentStream",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "5XX"],
            stream=True,
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "text/event-stream"):
            return eventstreaming.EventStream(
                http_res,
                lambda raw: utils.unmarshal_json(
                    raw, models.DeploymentStreamResponseBody
                ),
                sentinel="[DONE]",
                client_ref=self,
            )
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        http_res_text = utils.stream_to_text(http_res)
        raise models.APIError("Unexpected response received", http_res, http_res_text)

    async def stream_async(
        self,
        *,
        key: str,
        inputs: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None,
        prefix_messages: Optional[
            Union[
                List[models_deploymentstreamop.DeploymentStreamPrefixMessages],
                List[models_deploymentstreamop.DeploymentStreamPrefixMessagesTypedDict],
            ]
        ] = None,
        messages: Optional[
            Union[
                List[models_deploymentstreamop.DeploymentStreamMessages],
                List[models_deploymentstreamop.DeploymentStreamMessagesTypedDict],
            ]
        ] = None,
        file_ids: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        extra_params: Optional[Dict[str, Any]] = None,
        documents: Optional[
            Union[
                List[models_deploymentstreamop.DeploymentStreamDocuments],
                List[models_deploymentstreamop.DeploymentStreamDocumentsTypedDict],
            ]
        ] = None,
        invoke_options: Optional[
            Union[
                models_deploymentstreamop.DeploymentStreamInvokeOptions,
                models_deploymentstreamop.DeploymentStreamInvokeOptionsTypedDict,
            ]
        ] = None,
        thread: Optional[
            Union[
                models_deploymentstreamop.DeploymentStreamThread,
                models_deploymentstreamop.DeploymentStreamThreadTypedDict,
            ]
        ] = None,
        knowledge_filter: Optional[
            Union[
                models_deploymentstreamop.DeploymentStreamKnowledgeFilter,
                models_deploymentstreamop.DeploymentStreamKnowledgeFilterTypedDict,
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> Optional[eventstreaming.EventStreamAsync[models.DeploymentStreamResponseBody]]:
        r"""Stream

        Stream deployment generation. Only supported for completions and chat completions.

        :param key: The deployment key to invoke
        :param inputs: Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used.
        :param context: Key-value pairs that match your data model and fields declared in your deployment routing configuration
        :param prefix_messages: A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment.
        :param messages: A list of messages to send to the deployment.
        :param file_ids: A list of file IDs that are associated with the deployment request.
        :param metadata: Key-value pairs that you want to attach to the log generated by this request.
        :param extra_params: Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration.
        :param documents: A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings.
        :param invoke_options:
        :param thread:
        :param knowledge_filter: A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if timeout_ms is None:
            timeout_ms = 600000

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.DeploymentStreamRequestBody(
            key=key,
            inputs=inputs,
            context=context,
            prefix_messages=utils.get_pydantic_model(
                prefix_messages, Optional[List[models.DeploymentStreamPrefixMessages]]
            ),
            messages=utils.get_pydantic_model(
                messages, Optional[List[models.DeploymentStreamMessages]]
            ),
            file_ids=file_ids,
            metadata=metadata,
            extra_params=extra_params,
            documents=utils.get_pydantic_model(
                documents, Optional[List[models.DeploymentStreamDocuments]]
            ),
            invoke_options=utils.get_pydantic_model(
                invoke_options, Optional[models.DeploymentStreamInvokeOptions]
            ),
            thread=utils.get_pydantic_model(
                thread, Optional[models.DeploymentStreamThread]
            ),
            knowledge_filter=utils.get_pydantic_model(
                knowledge_filter, Optional[models.DeploymentStreamKnowledgeFilter]
            ),
        )

        req = self._build_request_async(
            method="POST",
            path="/v2/deployments/stream",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="text/event-stream",
            http_headers=http_headers,
            _globals=models.DeploymentStreamGlobals(
                environment=self.sdk_configuration.globals.environment,
                contact_id=self.sdk_configuration.globals.contact_id,
            ),
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.DeploymentStreamRequestBody
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="DeploymentStream",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["4XX", "5XX"],
            stream=True,
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "text/event-stream"):
            return eventstreaming.EventStreamAsync(
                http_res,
                lambda raw: utils.unmarshal_json(
                    raw, models.DeploymentStreamResponseBody
                ),
                sentinel="[DONE]",
                client_ref=self,
            )
        if utils.match_response(http_res, "4XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError("API error occurred", http_res, http_res_text)

        http_res_text = await utils.stream_to_text_async(http_res)
        raise models.APIError("Unexpected response received", http_res, http_res_text)
