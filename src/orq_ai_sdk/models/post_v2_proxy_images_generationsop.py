"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .publiccontact import PublicContact, PublicContactTypedDict
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from pydantic import model_serializer
from typing import List, Literal, Optional
from typing_extensions import NotRequired, TypedDict


Background = Literal["transparent", "opaque", "auto"]
r"""Allows to set transparency for the background of the generated image(s). This parameter is only supported for `openai/gpt-image-1`."""

Moderation = Literal["low", "auto"]
r"""Control the content-moderation level for images generated by `openai/gpt-image-1`."""

OutputFormat = Literal["png", "jpeg", "webp"]
r"""The format in which the generated images are returned. This parameter is only supported for `openai/gpt-image-1`."""

Quality = Literal["auto", "high", "medium", "low", "hd", "standard"]
r"""The quality of the image that will be generated. Auto will automatically select the best quality for the given model."""

PostV2ProxyImagesGenerationsResponseFormat = Literal["url", "b64_json"]
r"""The format in which generated images with are returned. This parameter isn't supported for `openai/gpt-image-1` which will always return base64-encoded images."""


class PostV2ProxyImagesGenerationsRetryTypedDict(TypedDict):
    r"""Retry configuration for the request"""

    count: NotRequired[float]
    r"""Number of retry attempts (1-5)"""
    on_codes: NotRequired[List[float]]
    r"""HTTP status codes that trigger retry logic"""


class PostV2ProxyImagesGenerationsRetry(BaseModel):
    r"""Retry configuration for the request"""

    count: Optional[float] = 3
    r"""Number of retry attempts (1-5)"""

    on_codes: Optional[List[float]] = None
    r"""HTTP status codes that trigger retry logic"""


class PostV2ProxyImagesGenerationsFallbacksTypedDict(TypedDict):
    model: str
    r"""Fallback model identifier"""


class PostV2ProxyImagesGenerationsFallbacks(BaseModel):
    model: str
    r"""Fallback model identifier"""


class PostV2ProxyImagesGenerationsThreadTypedDict(TypedDict):
    r"""Thread information to group related requests"""

    id: str
    r"""Unique thread identifier to group related invocations."""
    tags: NotRequired[List[str]]
    r"""Optional tags to differentiate or categorize threads"""


class PostV2ProxyImagesGenerationsThread(BaseModel):
    r"""Thread information to group related requests"""

    id: str
    r"""Unique thread identifier to group related invocations."""

    tags: Optional[List[str]] = None
    r"""Optional tags to differentiate or categorize threads"""


PostV2ProxyImagesGenerationsType = Literal["exact_match"]


class PostV2ProxyImagesGenerationsCacheTypedDict(TypedDict):
    r"""Cache configuration for the request."""

    type: PostV2ProxyImagesGenerationsType
    ttl: NotRequired[float]
    r"""Time to live for cached responses in seconds. Maximum 259200 seconds (3 days)."""


class PostV2ProxyImagesGenerationsCache(BaseModel):
    r"""Cache configuration for the request."""

    type: PostV2ProxyImagesGenerationsType

    ttl: Optional[float] = 1800
    r"""Time to live for cached responses in seconds. Maximum 259200 seconds (3 days)."""


class PostV2ProxyImagesGenerationsOrqTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name to display on the trace. If not specified, the default system name will be used."""
    retry: NotRequired[PostV2ProxyImagesGenerationsRetryTypedDict]
    r"""Retry configuration for the request"""
    fallbacks: NotRequired[List[PostV2ProxyImagesGenerationsFallbacksTypedDict]]
    r"""Array of fallback models to use if primary model fails"""
    contact: NotRequired[PublicContactTypedDict]
    r"""Information about the contact making the request. If the contact does not exist, it will be created automatically."""
    thread: NotRequired[PostV2ProxyImagesGenerationsThreadTypedDict]
    r"""Thread information to group related requests"""
    cache: NotRequired[PostV2ProxyImagesGenerationsCacheTypedDict]
    r"""Cache configuration for the request."""


class PostV2ProxyImagesGenerationsOrq(BaseModel):
    name: Optional[str] = None
    r"""The name to display on the trace. If not specified, the default system name will be used."""

    retry: Optional[PostV2ProxyImagesGenerationsRetry] = None
    r"""Retry configuration for the request"""

    fallbacks: Optional[List[PostV2ProxyImagesGenerationsFallbacks]] = None
    r"""Array of fallback models to use if primary model fails"""

    contact: Optional[PublicContact] = None
    r"""Information about the contact making the request. If the contact does not exist, it will be created automatically."""

    thread: Optional[PostV2ProxyImagesGenerationsThread] = None
    r"""Thread information to group related requests"""

    cache: Optional[PostV2ProxyImagesGenerationsCache] = None
    r"""Cache configuration for the request."""


class PostV2ProxyImagesGenerationsRequestBodyTypedDict(TypedDict):
    r"""input"""

    prompt: str
    r"""A text description of the desired image(s)."""
    model: str
    r"""The model to use for image generation. Defaults to dall-e-2 unless a parameter specific to gpt-image-1 is used."""
    background: NotRequired[Nullable[Background]]
    r"""Allows to set transparency for the background of the generated image(s). This parameter is only supported for `openai/gpt-image-1`."""
    moderation: NotRequired[Nullable[Moderation]]
    r"""Control the content-moderation level for images generated by `openai/gpt-image-1`."""
    n: NotRequired[Nullable[int]]
    r"""The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported."""
    output_compression: NotRequired[Nullable[int]]
    r"""The compression level (0-100%) for the generated images. This parameter is only supported for gpt-image-1 with the webp or jpeg output formats."""
    output_format: NotRequired[Nullable[OutputFormat]]
    r"""The format in which the generated images are returned. This parameter is only supported for `openai/gpt-image-1`."""
    quality: NotRequired[Nullable[Quality]]
    r"""The quality of the image that will be generated. Auto will automatically select the best quality for the given model."""
    response_format: NotRequired[Nullable[PostV2ProxyImagesGenerationsResponseFormat]]
    r"""The format in which generated images with are returned. This parameter isn't supported for `openai/gpt-image-1` which will always return base64-encoded images."""
    size: NotRequired[Nullable[str]]
    r"""The size of the generated images. Must be one of the specified sizes for each model."""
    style: NotRequired[Nullable[str]]
    r"""The style of the generated images. This parameter is only supported for dall-e-3."""
    orq: NotRequired[PostV2ProxyImagesGenerationsOrqTypedDict]


class PostV2ProxyImagesGenerationsRequestBody(BaseModel):
    r"""input"""

    prompt: str
    r"""A text description of the desired image(s)."""

    model: str
    r"""The model to use for image generation. Defaults to dall-e-2 unless a parameter specific to gpt-image-1 is used."""

    background: OptionalNullable[Background] = "auto"
    r"""Allows to set transparency for the background of the generated image(s). This parameter is only supported for `openai/gpt-image-1`."""

    moderation: OptionalNullable[Moderation] = "auto"
    r"""Control the content-moderation level for images generated by `openai/gpt-image-1`."""

    n: OptionalNullable[int] = 1
    r"""The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported."""

    output_compression: OptionalNullable[int] = 100
    r"""The compression level (0-100%) for the generated images. This parameter is only supported for gpt-image-1 with the webp or jpeg output formats."""

    output_format: OptionalNullable[OutputFormat] = "png"
    r"""The format in which the generated images are returned. This parameter is only supported for `openai/gpt-image-1`."""

    quality: OptionalNullable[Quality] = "auto"
    r"""The quality of the image that will be generated. Auto will automatically select the best quality for the given model."""

    response_format: OptionalNullable[PostV2ProxyImagesGenerationsResponseFormat] = (
        "url"
    )
    r"""The format in which generated images with are returned. This parameter isn't supported for `openai/gpt-image-1` which will always return base64-encoded images."""

    size: OptionalNullable[str] = UNSET
    r"""The size of the generated images. Must be one of the specified sizes for each model."""

    style: OptionalNullable[str] = UNSET
    r"""The style of the generated images. This parameter is only supported for dall-e-3."""

    orq: Optional[PostV2ProxyImagesGenerationsOrq] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "background",
            "moderation",
            "n",
            "output_compression",
            "output_format",
            "quality",
            "response_format",
            "size",
            "style",
            "orq",
        ]
        nullable_fields = [
            "background",
            "moderation",
            "n",
            "output_compression",
            "output_format",
            "quality",
            "response_format",
            "size",
            "style",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PostV2ProxyImagesGenerationsDataTypedDict(TypedDict):
    revised_prompt: NotRequired[Nullable[str]]
    r"""The prompt that was used to generate the image, if there was any revision to the prompt."""
    b64_json: NotRequired[str]
    r"""The base64-encoded JSON of the generated image, if `response_format` is `b64_json`"""
    url: NotRequired[str]
    r"""The url of the generated image, if `response_format` is `url` (default)"""


class PostV2ProxyImagesGenerationsData(BaseModel):
    revised_prompt: OptionalNullable[str] = UNSET
    r"""The prompt that was used to generate the image, if there was any revision to the prompt."""

    b64_json: Optional[str] = None
    r"""The base64-encoded JSON of the generated image, if `response_format` is `b64_json`"""

    url: Optional[str] = None
    r"""The url of the generated image, if `response_format` is `url` (default)"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["revised_prompt", "b64_json", "url"]
        nullable_fields = ["revised_prompt"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class InputTokensDetailsTypedDict(TypedDict):
    image_tokens: NotRequired[float]
    text_tokens: NotRequired[float]


class InputTokensDetails(BaseModel):
    image_tokens: Optional[float] = None

    text_tokens: Optional[float] = None


class PostV2ProxyImagesGenerationsUsageTypedDict(TypedDict):
    input_tokens_details: InputTokensDetailsTypedDict
    input_tokens: NotRequired[float]
    output_tokens: NotRequired[float]
    total_tokens: NotRequired[float]


class PostV2ProxyImagesGenerationsUsage(BaseModel):
    input_tokens_details: InputTokensDetails

    input_tokens: Optional[float] = None

    output_tokens: Optional[float] = None

    total_tokens: Optional[float] = None


class PostV2ProxyImagesGenerationsResponseBodyTypedDict(TypedDict):
    r"""Represents an image generation response from the API."""

    data: List[PostV2ProxyImagesGenerationsDataTypedDict]
    r"""Represents the url or the content of an image generated."""
    created: NotRequired[float]
    usage: NotRequired[PostV2ProxyImagesGenerationsUsageTypedDict]


class PostV2ProxyImagesGenerationsResponseBody(BaseModel):
    r"""Represents an image generation response from the API."""

    data: List[PostV2ProxyImagesGenerationsData]
    r"""Represents the url or the content of an image generated."""

    created: Optional[float] = None

    usage: Optional[PostV2ProxyImagesGenerationsUsage] = None
