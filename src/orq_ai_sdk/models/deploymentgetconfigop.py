"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
import pydantic
from pydantic import model_serializer
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


DeploymentGetConfigInputsTypedDict = TypeAliasType(
    "DeploymentGetConfigInputsTypedDict", Union[str, float, bool]
)


DeploymentGetConfigInputs = TypeAliasType(
    "DeploymentGetConfigInputs", Union[str, float, bool]
)


DeploymentGetConfigPrefixMessagesDeploymentsRequestRole = Literal["tool"]
r"""The role of the messages author, in this case tool."""

DeploymentGetConfigPrefixMessagesContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesContentTypedDict", Union[str, List[str]]
)
r"""The contents of the tool message."""


DeploymentGetConfigPrefixMessagesContent = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesContent", Union[str, List[str]]
)
r"""The contents of the tool message."""


class PrefixMessagesToolMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case tool."""
    content: DeploymentGetConfigPrefixMessagesContentTypedDict
    r"""The contents of the tool message."""
    tool_call_id: str
    r"""Tool call that this message is responding to."""


class PrefixMessagesToolMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case tool."""

    content: DeploymentGetConfigPrefixMessagesContent
    r"""The contents of the tool message."""

    tool_call_id: str
    r"""Tool call that this message is responding to."""


DeploymentGetConfig2DeploymentsRequestType = Literal["refusal"]
r"""The type of the content part."""


class DeploymentGetConfig2RefusalContentPartTypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestType
    r"""The type of the content part."""
    refusal: str
    r"""The refusal message generated by the model."""


class DeploymentGetConfig2RefusalContentPart(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestType
    r"""The type of the content part."""

    refusal: str
    r"""The refusal message generated by the model."""


DeploymentGetConfig2DeploymentsType = Literal["text"]
r"""The type of the content part."""


class DeploymentGetConfig2TextContentPartTypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsType
    r"""The type of the content part."""
    text: str
    r"""The text content."""


class DeploymentGetConfig2TextContentPart(BaseModel):
    type: DeploymentGetConfig2DeploymentsType
    r"""The type of the content part."""

    text: str
    r"""The text content."""


DeploymentGetConfigContentDeploymentsRequestRequestBody2TypedDict = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsRequestRequestBody2TypedDict",
    Union[
        DeploymentGetConfig2TextContentPartTypedDict,
        DeploymentGetConfig2RefusalContentPartTypedDict,
    ],
)


DeploymentGetConfigContentDeploymentsRequestRequestBody2 = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsRequestRequestBody2",
    Union[DeploymentGetConfig2TextContentPart, DeploymentGetConfig2RefusalContentPart],
)


DeploymentGetConfigPrefixMessagesDeploymentsRequestContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequestRequestBody2TypedDict]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigPrefixMessagesDeploymentsRequestContent = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsRequestContent",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequestRequestBody2]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigPrefixMessagesDeploymentsRole = Literal["assistant"]
r"""The role of the messages author, in this case `assistant`."""


class PrefixMessagesAudioTypedDict(TypedDict):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


class PrefixMessagesAudio(BaseModel):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


PrefixMessagesType = Literal["function"]
r"""The type of the tool. Currently, only `function` is supported."""


class PrefixMessagesFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name of the function to call."""
    arguments: NotRequired[str]
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class PrefixMessagesFunction(BaseModel):
    name: Optional[str] = None
    r"""The name of the function to call."""

    arguments: Optional[str] = None
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class PrefixMessagesToolCallsTypedDict(TypedDict):
    id: str
    r"""The ID of the tool call."""
    type: PrefixMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: PrefixMessagesFunctionTypedDict


class PrefixMessagesToolCalls(BaseModel):
    id: str
    r"""The ID of the tool call."""

    type: PrefixMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: PrefixMessagesFunction


class PrefixMessagesAssistantMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRole
    r"""The role of the messages author, in this case `assistant`."""
    content: NotRequired[
        DeploymentGetConfigPrefixMessagesDeploymentsRequestContentTypedDict
    ]
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""
    refusal: NotRequired[Nullable[str]]
    r"""The refusal message by the assistant."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""
    audio: NotRequired[Nullable[PrefixMessagesAudioTypedDict]]
    r"""Data about a previous audio response from the model."""
    tool_calls: NotRequired[List[PrefixMessagesToolCallsTypedDict]]
    r"""The tool calls generated by the model, such as function calls."""


class PrefixMessagesAssistantMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRole
    r"""The role of the messages author, in this case `assistant`."""

    content: Optional[DeploymentGetConfigPrefixMessagesDeploymentsRequestContent] = None
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""

    refusal: OptionalNullable[str] = UNSET
    r"""The refusal message by the assistant."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    audio: OptionalNullable[PrefixMessagesAudio] = UNSET
    r"""Data about a previous audio response from the model."""

    tool_calls: Optional[List[PrefixMessagesToolCalls]] = None
    r"""The tool calls generated by the model, such as function calls."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["content", "refusal", "name", "audio", "tool_calls"]
        nullable_fields = ["refusal", "audio"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


DeploymentGetConfigPrefixMessagesRole = Literal["user"]
r"""The role of the messages author, in this case `user`."""

DeploymentGetConfig2Type = Literal["input_audio"]

DeploymentGetConfig2Format = Literal["mp3", "wav"]
r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentGetConfig2InputAudioTypedDict(TypedDict):
    data: str
    r"""Base64 encoded audio data."""
    format_: DeploymentGetConfig2Format
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentGetConfig2InputAudio(BaseModel):
    data: str
    r"""Base64 encoded audio data."""

    format_: Annotated[DeploymentGetConfig2Format, pydantic.Field(alias="format")]
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentGetConfig23TypedDict(TypedDict):
    type: DeploymentGetConfig2Type
    input_audio: DeploymentGetConfig2InputAudioTypedDict


class DeploymentGetConfig23(BaseModel):
    type: DeploymentGetConfig2Type

    input_audio: DeploymentGetConfig2InputAudio


DeploymentGetConfig2DeploymentsRequestRequestBodyPrefixMessages3Type = Literal[
    "image_url"
]

DeploymentGetConfig2Detail = Literal["low", "high", "auto"]
r"""Specifies the detail level of the image."""


class DeploymentGetConfig2ImageURLTypedDict(TypedDict):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""
    detail: NotRequired[DeploymentGetConfig2Detail]
    r"""Specifies the detail level of the image."""


class DeploymentGetConfig2ImageURL(BaseModel):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""

    detail: Optional[DeploymentGetConfig2Detail] = None
    r"""Specifies the detail level of the image."""


class DeploymentGetConfig2Deployments2TypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyPrefixMessages3Type
    image_url: DeploymentGetConfig2ImageURLTypedDict


class DeploymentGetConfig2Deployments2(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyPrefixMessages3Type

    image_url: DeploymentGetConfig2ImageURL


DeploymentGetConfig2DeploymentsRequestRequestBodyPrefixMessagesType = Literal["text"]


class DeploymentGetConfig21TypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyPrefixMessagesType
    text: str


class DeploymentGetConfig21(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyPrefixMessagesType

    text: str


DeploymentGetConfigContentDeploymentsRequest2TypedDict = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsRequest2TypedDict",
    Union[
        DeploymentGetConfig21TypedDict,
        DeploymentGetConfig2Deployments2TypedDict,
        DeploymentGetConfig23TypedDict,
    ],
)


DeploymentGetConfigContentDeploymentsRequest2 = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsRequest2",
    Union[
        DeploymentGetConfig21, DeploymentGetConfig2Deployments2, DeploymentGetConfig23
    ],
)


DeploymentGetConfigPrefixMessagesDeploymentsContentTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequest2TypedDict]],
)
r"""The contents of the user message."""


DeploymentGetConfigPrefixMessagesDeploymentsContent = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesDeploymentsContent",
    Union[str, List[DeploymentGetConfigContentDeploymentsRequest2]],
)
r"""The contents of the user message."""


class PrefixMessagesUserMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesRole
    r"""The role of the messages author, in this case `user`."""
    content: DeploymentGetConfigPrefixMessagesDeploymentsContentTypedDict
    r"""The contents of the user message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class PrefixMessagesUserMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesRole
    r"""The role of the messages author, in this case `user`."""

    content: DeploymentGetConfigPrefixMessagesDeploymentsContent
    r"""The contents of the user message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody2Role = Literal["system"]
r"""The role of the messages author, in this case `system`."""


class PrefixMessagesSystemMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody2Role
    r"""The role of the messages author, in this case `system`."""
    content: str
    r"""The contents of the system message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class PrefixMessagesSystemMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBody2Role
    r"""The role of the messages author, in this case `system`."""

    content: str
    r"""The contents of the system message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyRole = Literal[
    "developer"
]
r"""The role of the messages author, in this case  `developer`."""


class PrefixMessagesDeveloperMessageTypedDict(TypedDict):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case  `developer`."""
    content: str
    r"""The contents of the developer message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class PrefixMessagesDeveloperMessage(BaseModel):
    role: DeploymentGetConfigPrefixMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case  `developer`."""

    content: str
    r"""The contents of the developer message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentGetConfigPrefixMessagesTypedDict = TypeAliasType(
    "DeploymentGetConfigPrefixMessagesTypedDict",
    Union[
        PrefixMessagesDeveloperMessageTypedDict,
        PrefixMessagesSystemMessageTypedDict,
        PrefixMessagesUserMessageTypedDict,
        PrefixMessagesToolMessageTypedDict,
        PrefixMessagesAssistantMessageTypedDict,
    ],
)


DeploymentGetConfigPrefixMessages = TypeAliasType(
    "DeploymentGetConfigPrefixMessages",
    Union[
        PrefixMessagesDeveloperMessage,
        PrefixMessagesSystemMessage,
        PrefixMessagesUserMessage,
        PrefixMessagesToolMessage,
        PrefixMessagesAssistantMessage,
    ],
)


DeploymentGetConfigMessagesDeploymentsRequestRequestBodyRole = Literal["tool"]
r"""The role of the messages author, in this case tool."""

DeploymentGetConfigMessagesDeploymentsContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsContentTypedDict", Union[str, List[str]]
)
r"""The contents of the tool message."""


DeploymentGetConfigMessagesDeploymentsContent = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsContent", Union[str, List[str]]
)
r"""The contents of the tool message."""


class DeploymentGetConfigMessagesToolMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case tool."""
    content: DeploymentGetConfigMessagesDeploymentsContentTypedDict
    r"""The contents of the tool message."""
    tool_call_id: str
    r"""Tool call that this message is responding to."""


class DeploymentGetConfigMessagesToolMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case tool."""

    content: DeploymentGetConfigMessagesDeploymentsContent
    r"""The contents of the tool message."""

    tool_call_id: str
    r"""Tool call that this message is responding to."""


DeploymentGetConfig2DeploymentsRequestRequestBodyMessages4ContentType = Literal[
    "refusal"
]
r"""The type of the content part."""


class DeploymentGetConfig2DeploymentsRefusalContentPartTypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessages4ContentType
    r"""The type of the content part."""
    refusal: str
    r"""The refusal message generated by the model."""


class DeploymentGetConfig2DeploymentsRefusalContentPart(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessages4ContentType
    r"""The type of the content part."""

    refusal: str
    r"""The refusal message generated by the model."""


DeploymentGetConfig2DeploymentsRequestRequestBodyMessages4Type = Literal["text"]
r"""The type of the content part."""


class DeploymentGetConfig2DeploymentsTextContentPartTypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessages4Type
    r"""The type of the content part."""
    text: str
    r"""The text content."""


class DeploymentGetConfig2DeploymentsTextContentPart(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessages4Type
    r"""The type of the content part."""

    text: str
    r"""The text content."""


DeploymentGetConfigContentDeployments2TypedDict = TypeAliasType(
    "DeploymentGetConfigContentDeployments2TypedDict",
    Union[
        DeploymentGetConfig2DeploymentsTextContentPartTypedDict,
        DeploymentGetConfig2DeploymentsRefusalContentPartTypedDict,
    ],
)


DeploymentGetConfigContentDeployments2 = TypeAliasType(
    "DeploymentGetConfigContentDeployments2",
    Union[
        DeploymentGetConfig2DeploymentsTextContentPart,
        DeploymentGetConfig2DeploymentsRefusalContentPart,
    ],
)


DeploymentGetConfigMessagesContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeployments2TypedDict]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigMessagesContent = TypeAliasType(
    "DeploymentGetConfigMessagesContent",
    Union[str, List[DeploymentGetConfigContentDeployments2]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentGetConfigMessagesDeploymentsRequestRole = Literal["assistant"]
r"""The role of the messages author, in this case `assistant`."""


class DeploymentGetConfigMessagesAudioTypedDict(TypedDict):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


class DeploymentGetConfigMessagesAudio(BaseModel):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


DeploymentGetConfigMessagesType = Literal["function"]
r"""The type of the tool. Currently, only `function` is supported."""


class DeploymentGetConfigMessagesFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name of the function to call."""
    arguments: NotRequired[str]
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentGetConfigMessagesFunction(BaseModel):
    name: Optional[str] = None
    r"""The name of the function to call."""

    arguments: Optional[str] = None
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentGetConfigMessagesToolCallsTypedDict(TypedDict):
    id: str
    r"""The ID of the tool call."""
    type: DeploymentGetConfigMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: DeploymentGetConfigMessagesFunctionTypedDict


class DeploymentGetConfigMessagesToolCalls(BaseModel):
    id: str
    r"""The ID of the tool call."""

    type: DeploymentGetConfigMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: DeploymentGetConfigMessagesFunction


class DeploymentGetConfigMessagesAssistantMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `assistant`."""
    content: NotRequired[DeploymentGetConfigMessagesContentTypedDict]
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""
    refusal: NotRequired[Nullable[str]]
    r"""The refusal message by the assistant."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""
    audio: NotRequired[Nullable[DeploymentGetConfigMessagesAudioTypedDict]]
    r"""Data about a previous audio response from the model."""
    tool_calls: NotRequired[List[DeploymentGetConfigMessagesToolCallsTypedDict]]
    r"""The tool calls generated by the model, such as function calls."""


class DeploymentGetConfigMessagesAssistantMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `assistant`."""

    content: Optional[DeploymentGetConfigMessagesContent] = None
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""

    refusal: OptionalNullable[str] = UNSET
    r"""The refusal message by the assistant."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    audio: OptionalNullable[DeploymentGetConfigMessagesAudio] = UNSET
    r"""Data about a previous audio response from the model."""

    tool_calls: Optional[List[DeploymentGetConfigMessagesToolCalls]] = None
    r"""The tool calls generated by the model, such as function calls."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["content", "refusal", "name", "audio", "tool_calls"]
        nullable_fields = ["refusal", "audio"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


DeploymentGetConfigMessagesDeploymentsRole = Literal["user"]
r"""The role of the messages author, in this case `user`."""

DeploymentGetConfig2DeploymentsRequestRequestBodyMessages3Type = Literal["input_audio"]

DeploymentGetConfig2DeploymentsFormat = Literal["mp3", "wav"]
r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentGetConfig2DeploymentsInputAudioTypedDict(TypedDict):
    data: str
    r"""Base64 encoded audio data."""
    format_: DeploymentGetConfig2DeploymentsFormat
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentGetConfig2DeploymentsInputAudio(BaseModel):
    data: str
    r"""Base64 encoded audio data."""

    format_: Annotated[
        DeploymentGetConfig2DeploymentsFormat, pydantic.Field(alias="format")
    ]
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentGetConfig2Deployments3TypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessages3Type
    input_audio: DeploymentGetConfig2DeploymentsInputAudioTypedDict


class DeploymentGetConfig2Deployments3(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessages3Type

    input_audio: DeploymentGetConfig2DeploymentsInputAudio


DeploymentGetConfig2DeploymentsRequestRequestBodyMessagesType = Literal["image_url"]

DeploymentGetConfig2DeploymentsDetail = Literal["low", "high", "auto"]
r"""Specifies the detail level of the image."""


class DeploymentGetConfig2DeploymentsImageURLTypedDict(TypedDict):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""
    detail: NotRequired[DeploymentGetConfig2DeploymentsDetail]
    r"""Specifies the detail level of the image."""


class DeploymentGetConfig2DeploymentsImageURL(BaseModel):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""

    detail: Optional[DeploymentGetConfig2DeploymentsDetail] = None
    r"""Specifies the detail level of the image."""


class DeploymentGetConfig22TypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessagesType
    image_url: DeploymentGetConfig2DeploymentsImageURLTypedDict


class DeploymentGetConfig22(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyMessagesType

    image_url: DeploymentGetConfig2DeploymentsImageURL


DeploymentGetConfig2DeploymentsRequestRequestBodyType = Literal["text"]


class DeploymentGetConfig2Deployments1TypedDict(TypedDict):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyType
    text: str


class DeploymentGetConfig2Deployments1(BaseModel):
    type: DeploymentGetConfig2DeploymentsRequestRequestBodyType

    text: str


DeploymentGetConfigContent2TypedDict = TypeAliasType(
    "DeploymentGetConfigContent2TypedDict",
    Union[
        DeploymentGetConfig2Deployments1TypedDict,
        DeploymentGetConfig22TypedDict,
        DeploymentGetConfig2Deployments3TypedDict,
    ],
)


DeploymentGetConfigContent2 = TypeAliasType(
    "DeploymentGetConfigContent2",
    Union[
        DeploymentGetConfig2Deployments1,
        DeploymentGetConfig22,
        DeploymentGetConfig2Deployments3,
    ],
)


DeploymentGetConfigMessagesDeploymentsRequestContentTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestContentTypedDict",
    Union[str, List[DeploymentGetConfigContent2TypedDict]],
)
r"""The contents of the user message."""


DeploymentGetConfigMessagesDeploymentsRequestContent = TypeAliasType(
    "DeploymentGetConfigMessagesDeploymentsRequestContent",
    Union[str, List[DeploymentGetConfigContent2]],
)
r"""The contents of the user message."""


class DeploymentGetConfigMessagesUserMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRole
    r"""The role of the messages author, in this case `user`."""
    content: DeploymentGetConfigMessagesDeploymentsRequestContentTypedDict
    r"""The contents of the user message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentGetConfigMessagesUserMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRole
    r"""The role of the messages author, in this case `user`."""

    content: DeploymentGetConfigMessagesDeploymentsRequestContent
    r"""The contents of the user message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentGetConfigMessagesRole = Literal["system"]
r"""The role of the messages author, in this case `system`."""


class DeploymentGetConfigMessagesSystemMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesRole
    r"""The role of the messages author, in this case `system`."""
    content: str
    r"""The contents of the system message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentGetConfigMessagesSystemMessage(BaseModel):
    role: DeploymentGetConfigMessagesRole
    r"""The role of the messages author, in this case `system`."""

    content: str
    r"""The contents of the system message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentGetConfigMessagesDeploymentsRequestRequestBody1Role = Literal["developer"]
r"""The role of the messages author, in this case  `developer`."""


class DeploymentGetConfigMessagesDeveloperMessageTypedDict(TypedDict):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBody1Role
    r"""The role of the messages author, in this case  `developer`."""
    content: str
    r"""The contents of the developer message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentGetConfigMessagesDeveloperMessage(BaseModel):
    role: DeploymentGetConfigMessagesDeploymentsRequestRequestBody1Role
    r"""The role of the messages author, in this case  `developer`."""

    content: str
    r"""The contents of the developer message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentGetConfigMessagesTypedDict = TypeAliasType(
    "DeploymentGetConfigMessagesTypedDict",
    Union[
        DeploymentGetConfigMessagesDeveloperMessageTypedDict,
        DeploymentGetConfigMessagesSystemMessageTypedDict,
        DeploymentGetConfigMessagesUserMessageTypedDict,
        DeploymentGetConfigMessagesToolMessageTypedDict,
        DeploymentGetConfigMessagesAssistantMessageTypedDict,
    ],
)


DeploymentGetConfigMessages = TypeAliasType(
    "DeploymentGetConfigMessages",
    Union[
        DeploymentGetConfigMessagesDeveloperMessage,
        DeploymentGetConfigMessagesSystemMessage,
        DeploymentGetConfigMessagesUserMessage,
        DeploymentGetConfigMessagesToolMessage,
        DeploymentGetConfigMessagesAssistantMessage,
    ],
)


class DeploymentGetConfigMetadataTypedDict(TypedDict):
    r"""Metadata about the document"""

    file_name: NotRequired[str]
    r"""Name of the file the text is from."""
    file_type: NotRequired[str]
    r"""Content type of the file the text is from."""
    page_number: NotRequired[float]
    r"""The page number the text is from."""


class DeploymentGetConfigMetadata(BaseModel):
    r"""Metadata about the document"""

    file_name: Optional[str] = None
    r"""Name of the file the text is from."""

    file_type: Optional[str] = None
    r"""Content type of the file the text is from."""

    page_number: Optional[float] = None
    r"""The page number the text is from."""


class DeploymentGetConfigDocumentsTypedDict(TypedDict):
    text: str
    r"""The text content of the document"""
    metadata: NotRequired[DeploymentGetConfigMetadataTypedDict]
    r"""Metadata about the document"""


class DeploymentGetConfigDocuments(BaseModel):
    text: str
    r"""The text content of the document"""

    metadata: Optional[DeploymentGetConfigMetadata] = None
    r"""Metadata about the document"""


class DeploymentGetConfigInvokeOptionsTypedDict(TypedDict):
    include_retrievals: NotRequired[bool]
    r"""Whether to include the retrieved knowledge chunks in the response."""


class DeploymentGetConfigInvokeOptions(BaseModel):
    include_retrievals: Optional[bool] = False
    r"""Whether to include the retrieved knowledge chunks in the response."""


class DeploymentGetConfigRequestBodyTypedDict(TypedDict):
    key: str
    r"""The deployment key to invoke"""
    inputs: NotRequired[Dict[str, DeploymentGetConfigInputsTypedDict]]
    r"""Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used."""
    context: NotRequired[Dict[str, Any]]
    r"""Key-value pairs that match your data model and fields declared in your configuration matrix. If you send multiple prompt keys, the context will be applied to the evaluation of each key."""
    prefix_messages: NotRequired[List[DeploymentGetConfigPrefixMessagesTypedDict]]
    r"""A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment."""
    messages: NotRequired[List[DeploymentGetConfigMessagesTypedDict]]
    r"""A list of messages to send to the deployment."""
    file_ids: NotRequired[List[str]]
    r"""A list of file IDs that are associated with the deployment request."""
    metadata: NotRequired[Dict[str, Any]]
    r"""Key-value pairs that you want to attach to the log generated by this request."""
    extra_params: NotRequired[Dict[str, Any]]
    r"""Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration."""
    documents: NotRequired[List[DeploymentGetConfigDocumentsTypedDict]]
    r"""A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings."""
    invoke_options: NotRequired[DeploymentGetConfigInvokeOptionsTypedDict]


class DeploymentGetConfigRequestBody(BaseModel):
    key: str
    r"""The deployment key to invoke"""

    inputs: Optional[Dict[str, DeploymentGetConfigInputs]] = None
    r"""Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used."""

    context: Optional[Dict[str, Any]] = None
    r"""Key-value pairs that match your data model and fields declared in your configuration matrix. If you send multiple prompt keys, the context will be applied to the evaluation of each key."""

    prefix_messages: Optional[List[DeploymentGetConfigPrefixMessages]] = None
    r"""A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment."""

    messages: Optional[List[DeploymentGetConfigMessages]] = None
    r"""A list of messages to send to the deployment."""

    file_ids: Optional[List[str]] = None
    r"""A list of file IDs that are associated with the deployment request."""

    metadata: Optional[Dict[str, Any]] = None
    r"""Key-value pairs that you want to attach to the log generated by this request."""

    extra_params: Optional[Dict[str, Any]] = None
    r"""Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration."""

    documents: Optional[List[DeploymentGetConfigDocuments]] = None
    r"""A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings."""

    invoke_options: Optional[DeploymentGetConfigInvokeOptions] = None


DeploymentGetConfigType = Literal[
    "chat",
    "completion",
    "embedding",
    "vision",
    "image",
    "tts",
    "stt",
    "rerank",
    "moderations",
]
r"""The type of the model. Current `chat`,`completion` and `image` are supported"""

DeploymentGetConfigRole = Literal[
    "system",
    "assistant",
    "user",
    "exception",
    "tool",
    "prompt",
    "correction",
    "expected_output",
]
r"""The role of the prompt message"""

DeploymentGetConfig2DeploymentsResponse200Type = Literal["image_url"]


class DeploymentGetConfig2DeploymentsResponseImageURLTypedDict(TypedDict):
    url: str
    r"""Either a URL of the image or the base64 encoded data URI."""
    id: NotRequired[str]
    r"""The orq.ai id of the image"""
    detail: NotRequired[str]
    r"""Specifies the detail level of the image. Currently only supported with OpenAI models"""


class DeploymentGetConfig2DeploymentsResponseImageURL(BaseModel):
    url: str
    r"""Either a URL of the image or the base64 encoded data URI."""

    id: Optional[str] = None
    r"""The orq.ai id of the image"""

    detail: Optional[str] = None
    r"""Specifies the detail level of the image. Currently only supported with OpenAI models"""


class DeploymentGetConfig2DeploymentsResponse2TypedDict(TypedDict):
    r"""The image part of the prompt message. Only supported with vision models."""

    type: DeploymentGetConfig2DeploymentsResponse200Type
    image_url: DeploymentGetConfig2DeploymentsResponseImageURLTypedDict


class DeploymentGetConfig2DeploymentsResponse2(BaseModel):
    r"""The image part of the prompt message. Only supported with vision models."""

    type: DeploymentGetConfig2DeploymentsResponse200Type

    image_url: DeploymentGetConfig2DeploymentsResponseImageURL


DeploymentGetConfig2DeploymentsResponseType = Literal["text"]


class DeploymentGetConfig2DeploymentsResponse1TypedDict(TypedDict):
    r"""Text content part of a prompt message"""

    type: DeploymentGetConfig2DeploymentsResponseType
    text: str


class DeploymentGetConfig2DeploymentsResponse1(BaseModel):
    r"""Text content part of a prompt message"""

    type: DeploymentGetConfig2DeploymentsResponseType

    text: str


DeploymentGetConfigContentDeploymentsResponse2TypedDict = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsResponse2TypedDict",
    Union[
        DeploymentGetConfig2DeploymentsResponse1TypedDict,
        DeploymentGetConfig2DeploymentsResponse2TypedDict,
    ],
)


DeploymentGetConfigContentDeploymentsResponse2 = TypeAliasType(
    "DeploymentGetConfigContentDeploymentsResponse2",
    Union[
        DeploymentGetConfig2DeploymentsResponse1,
        DeploymentGetConfig2DeploymentsResponse2,
    ],
)


DeploymentGetConfigContentTypedDict = TypeAliasType(
    "DeploymentGetConfigContentTypedDict",
    Union[str, List[DeploymentGetConfigContentDeploymentsResponse2TypedDict]],
)
r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts."""


DeploymentGetConfigContent = TypeAliasType(
    "DeploymentGetConfigContent",
    Union[str, List[DeploymentGetConfigContentDeploymentsResponse2]],
)
r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts."""


DeploymentGetConfigDeploymentsResponseType = Literal["function"]


class DeploymentGetConfigDeploymentsFunctionTypedDict(TypedDict):
    name: str
    arguments: str
    r"""JSON string arguments for the functions"""


class DeploymentGetConfigDeploymentsFunction(BaseModel):
    name: str

    arguments: str
    r"""JSON string arguments for the functions"""


class DeploymentGetConfigToolCallsTypedDict(TypedDict):
    type: DeploymentGetConfigDeploymentsResponseType
    function: DeploymentGetConfigDeploymentsFunctionTypedDict
    id: NotRequired[str]
    index: NotRequired[float]


class DeploymentGetConfigToolCalls(BaseModel):
    type: DeploymentGetConfigDeploymentsResponseType

    function: DeploymentGetConfigDeploymentsFunction

    id: Optional[str] = None

    index: Optional[float] = None


class DeploymentGetConfigDeploymentsMessagesTypedDict(TypedDict):
    role: DeploymentGetConfigRole
    r"""The role of the prompt message"""
    content: DeploymentGetConfigContentTypedDict
    r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts."""
    tool_calls: NotRequired[List[DeploymentGetConfigToolCallsTypedDict]]


class DeploymentGetConfigDeploymentsMessages(BaseModel):
    role: DeploymentGetConfigRole
    r"""The role of the prompt message"""

    content: DeploymentGetConfigContent
    r"""The contents of the user message. Either the text content of the message or an array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts."""

    tool_calls: Optional[List[DeploymentGetConfigToolCalls]] = None


DeploymentGetConfigFormat = Literal["url", "b64_json", "text", "json_object"]
r"""Only supported on `image` models."""

DeploymentGetConfigQuality = Literal["standard", "hd"]
r"""Only supported on `image` models."""

DeploymentGetConfigResponseFormatType = Literal["json_object"]


class DeploymentGetConfigResponseFormat2TypedDict(TypedDict):
    type: DeploymentGetConfigResponseFormatType


class DeploymentGetConfigResponseFormat2(BaseModel):
    type: DeploymentGetConfigResponseFormatType


DeploymentGetConfigResponseFormatDeploymentsType = Literal["json_schema"]


class DeploymentGetConfigResponseFormatJSONSchemaTypedDict(TypedDict):
    name: str
    strict: bool
    schema_: Dict[str, Any]


class DeploymentGetConfigResponseFormatJSONSchema(BaseModel):
    name: str

    strict: bool

    schema_: Annotated[Dict[str, Any], pydantic.Field(alias="schema")]


class DeploymentGetConfigResponseFormat1TypedDict(TypedDict):
    type: DeploymentGetConfigResponseFormatDeploymentsType
    json_schema: DeploymentGetConfigResponseFormatJSONSchemaTypedDict


class DeploymentGetConfigResponseFormat1(BaseModel):
    type: DeploymentGetConfigResponseFormatDeploymentsType

    json_schema: DeploymentGetConfigResponseFormatJSONSchema


DeploymentGetConfigResponseFormatTypedDict = TypeAliasType(
    "DeploymentGetConfigResponseFormatTypedDict",
    Union[
        DeploymentGetConfigResponseFormat2TypedDict,
        DeploymentGetConfigResponseFormat1TypedDict,
    ],
)
r"""An object specifying the format that the model must output.

Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
"""


DeploymentGetConfigResponseFormat = TypeAliasType(
    "DeploymentGetConfigResponseFormat",
    Union[DeploymentGetConfigResponseFormat2, DeploymentGetConfigResponseFormat1],
)
r"""An object specifying the format that the model must output.

Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
"""


DeploymentGetConfigPhotoRealVersion = Literal["v1", "v2"]
r"""The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider"""

DeploymentGetConfigEncodingFormat = Literal["float", "base64"]
r"""The format to return the embeddings"""

DeploymentGetConfigReasoningEffort = Literal["low", "medium", "high"]
r"""Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."""


class ParametersTypedDict(TypedDict):
    r"""Model Parameters: Not all parameters apply to every model"""

    temperature: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    max_tokens: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    top_k: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    top_p: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    frequency_penalty: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    presence_penalty: NotRequired[float]
    r"""Only supported on `chat` and `completion` models."""
    num_images: NotRequired[float]
    r"""Only supported on `image` models."""
    seed: NotRequired[float]
    r"""Best effort deterministic seed for the model. Currently only OpenAI models support these"""
    format_: NotRequired[DeploymentGetConfigFormat]
    r"""Only supported on `image` models."""
    dimensions: NotRequired[str]
    r"""Only supported on `image` models."""
    quality: NotRequired[DeploymentGetConfigQuality]
    r"""Only supported on `image` models."""
    style: NotRequired[str]
    r"""Only supported on `image` models."""
    response_format: NotRequired[Nullable[DeploymentGetConfigResponseFormatTypedDict]]
    r"""An object specifying the format that the model must output.

    Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

    Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

    Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
    """
    photo_real_version: NotRequired[DeploymentGetConfigPhotoRealVersion]
    r"""The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider"""
    encoding_format: NotRequired[DeploymentGetConfigEncodingFormat]
    r"""The format to return the embeddings"""
    reasoning_effort: NotRequired[DeploymentGetConfigReasoningEffort]
    r"""Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."""
    budget_tokens: NotRequired[float]
    r"""Gives the model enhanced reasoning capabilities for complex tasks. A value of 0 disables thinking. The minimum budget tokens for thinking are 1024. The Budget Tokens should never exceed the Max Tokens parameter. Only supported by `Anthropic`"""


class Parameters(BaseModel):
    r"""Model Parameters: Not all parameters apply to every model"""

    temperature: Optional[float] = None
    r"""Only supported on `chat` and `completion` models."""

    max_tokens: Annotated[Optional[float], pydantic.Field(alias="maxTokens")] = None
    r"""Only supported on `chat` and `completion` models."""

    top_k: Annotated[Optional[float], pydantic.Field(alias="topK")] = None
    r"""Only supported on `chat` and `completion` models."""

    top_p: Annotated[Optional[float], pydantic.Field(alias="topP")] = None
    r"""Only supported on `chat` and `completion` models."""

    frequency_penalty: Annotated[
        Optional[float], pydantic.Field(alias="frequencyPenalty")
    ] = None
    r"""Only supported on `chat` and `completion` models."""

    presence_penalty: Annotated[
        Optional[float], pydantic.Field(alias="presencePenalty")
    ] = None
    r"""Only supported on `chat` and `completion` models."""

    num_images: Annotated[Optional[float], pydantic.Field(alias="numImages")] = None
    r"""Only supported on `image` models."""

    seed: Optional[float] = None
    r"""Best effort deterministic seed for the model. Currently only OpenAI models support these"""

    format_: Annotated[
        Optional[DeploymentGetConfigFormat], pydantic.Field(alias="format")
    ] = None
    r"""Only supported on `image` models."""

    dimensions: Optional[str] = None
    r"""Only supported on `image` models."""

    quality: Optional[DeploymentGetConfigQuality] = None
    r"""Only supported on `image` models."""

    style: Optional[str] = None
    r"""Only supported on `image` models."""

    response_format: Annotated[
        OptionalNullable[DeploymentGetConfigResponseFormat],
        pydantic.Field(alias="responseFormat"),
    ] = UNSET
    r"""An object specifying the format that the model must output.

    Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema

    Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.

    Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
    """

    photo_real_version: Annotated[
        Optional[DeploymentGetConfigPhotoRealVersion],
        pydantic.Field(alias="photoRealVersion"),
    ] = None
    r"""The version of photoReal to use. Must be v1 or v2. Only available for `leonardoai` provider"""

    encoding_format: Optional[DeploymentGetConfigEncodingFormat] = None
    r"""The format to return the embeddings"""

    reasoning_effort: Annotated[
        Optional[DeploymentGetConfigReasoningEffort],
        pydantic.Field(alias="reasoningEffort"),
    ] = None
    r"""Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."""

    budget_tokens: Annotated[Optional[float], pydantic.Field(alias="budgetTokens")] = (
        None
    )
    r"""Gives the model enhanced reasoning capabilities for complex tasks. A value of 0 disables thinking. The minimum budget tokens for thinking are 1024. The Budget Tokens should never exceed the Max Tokens parameter. Only supported by `Anthropic`"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "temperature",
            "maxTokens",
            "topK",
            "topP",
            "frequencyPenalty",
            "presencePenalty",
            "numImages",
            "seed",
            "format",
            "dimensions",
            "quality",
            "style",
            "responseFormat",
            "photoRealVersion",
            "encoding_format",
            "reasoningEffort",
            "budgetTokens",
        ]
        nullable_fields = ["responseFormat"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


DeploymentGetConfigDeploymentsType = Literal["function"]
r"""The type of the tool. Currently, only `function` is supported."""


class DeploymentGetConfigFunctionTypedDict(TypedDict):
    name: str
    r"""The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."""
    description: NotRequired[str]
    r"""A description of what the function does, used by the model to choose when and how to call the function."""
    parameters: NotRequired[Dict[str, Any]]
    r"""The parameters the functions accepts, described as a JSON Schema object.

    Omitting `parameters` defines a function with an empty parameter list.
    """


class DeploymentGetConfigFunction(BaseModel):
    name: str
    r"""The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."""

    description: Optional[str] = None
    r"""A description of what the function does, used by the model to choose when and how to call the function."""

    parameters: Optional[Dict[str, Any]] = None
    r"""The parameters the functions accepts, described as a JSON Schema object.

    Omitting `parameters` defines a function with an empty parameter list.
    """


class ToolsTypedDict(TypedDict):
    type: DeploymentGetConfigDeploymentsType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: DeploymentGetConfigFunctionTypedDict


class Tools(BaseModel):
    type: DeploymentGetConfigDeploymentsType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: DeploymentGetConfigFunction


class DeploymentGetConfigResponseBodyTypedDict(TypedDict):
    r"""The deployment configuration"""

    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""
    provider: str
    r"""The provider of the model"""
    model: str
    r"""The model of the configuration"""
    version: str
    r"""The current version of the deployment"""
    messages: List[DeploymentGetConfigDeploymentsMessagesTypedDict]
    parameters: ParametersTypedDict
    r"""Model Parameters: Not all parameters apply to every model"""
    type: NotRequired[DeploymentGetConfigType]
    r"""The type of the model. Current `chat`,`completion` and `image` are supported"""
    tools: NotRequired[List[ToolsTypedDict]]
    r"""A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for."""


class DeploymentGetConfigResponseBody(BaseModel):
    r"""The deployment configuration"""

    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""

    provider: str
    r"""The provider of the model"""

    model: str
    r"""The model of the configuration"""

    version: str
    r"""The current version of the deployment"""

    messages: List[DeploymentGetConfigDeploymentsMessages]

    parameters: Parameters
    r"""Model Parameters: Not all parameters apply to every model"""

    type: Optional[DeploymentGetConfigType] = None
    r"""The type of the model. Current `chat`,`completion` and `image` are supported"""

    tools: Optional[List[Tools]] = None
    r"""A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for."""
