"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .publiccontact import PublicContact, PublicContactTypedDict
from dataclasses import dataclass, field
import httpx
import io
from orq_ai_sdk.models import OrqError
from orq_ai_sdk.types import BaseModel, Nullable, UNSET_SENTINEL
from orq_ai_sdk.utils import FieldMetadata, MultipartFormMetadata
import pydantic
from pydantic import model_serializer
from typing import Any, Dict, IO, List, Literal, Optional, Union
from typing_extensions import (
    Annotated,
    NotRequired,
    TypeAliasType,
    TypedDict,
    deprecated,
)


CreateTranslationResponseFormat = Literal[
    "json",
    "text",
    "srt",
    "verbose_json",
    "vtt",
]
r"""The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt."""


CreateTranslationTimestampsGranularity = Literal[
    "none",
    "word",
    "character",
]
r"""The granularity of the timestamps in the transcription. Word provides word-level timestamps and character provides character-level timestamps per word."""


class CreateTranslationFallbacksTypedDict(TypedDict):
    model: str
    r"""Fallback model identifier"""


class CreateTranslationFallbacks(BaseModel):
    model: str
    r"""Fallback model identifier"""


class CreateTranslationRetryTypedDict(TypedDict):
    r"""Retry configuration for the request"""

    count: NotRequired[float]
    r"""Number of retry attempts (1-5)"""
    on_codes: NotRequired[List[float]]
    r"""HTTP status codes that trigger retry logic"""


class CreateTranslationRetry(BaseModel):
    r"""Retry configuration for the request"""

    count: Optional[float] = 3
    r"""Number of retry attempts (1-5)"""

    on_codes: Optional[List[float]] = None
    r"""HTTP status codes that trigger retry logic"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["count", "on_codes"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


@deprecated(
    "warning: ** DEPRECATED ** - This will be removed in a future release, please migrate away from it as soon as possible."
)
class CreateTranslationContactTypedDict(TypedDict):
    r"""@deprecated Use identity instead. Information about the contact making the request."""

    id: str
    r"""Unique identifier for the contact"""
    display_name: NotRequired[str]
    r"""Display name of the contact"""
    email: NotRequired[str]
    r"""Email address of the contact"""
    metadata: NotRequired[List[Dict[str, Any]]]
    r"""A hash of key/value pairs containing any other data about the contact"""
    logo_url: NotRequired[str]
    r"""URL to the contact's avatar or logo"""
    tags: NotRequired[List[str]]
    r"""A list of tags associated with the contact"""


@deprecated(
    "warning: ** DEPRECATED ** - This will be removed in a future release, please migrate away from it as soon as possible."
)
class CreateTranslationContact(BaseModel):
    r"""@deprecated Use identity instead. Information about the contact making the request."""

    id: str
    r"""Unique identifier for the contact"""

    display_name: Optional[str] = None
    r"""Display name of the contact"""

    email: Optional[str] = None
    r"""Email address of the contact"""

    metadata: Optional[List[Dict[str, Any]]] = None
    r"""A hash of key/value pairs containing any other data about the contact"""

    logo_url: Optional[str] = None
    r"""URL to the contact's avatar or logo"""

    tags: Optional[List[str]] = None
    r"""A list of tags associated with the contact"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["display_name", "email", "metadata", "logo_url", "tags"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


CreateTranslationLoadBalancerType = Literal["weight_based",]


class CreateTranslationLoadBalancerModelsTypedDict(TypedDict):
    model: str
    r"""Model identifier for load balancing"""
    weight: NotRequired[float]
    r"""Weight assigned to this model for load balancing"""


class CreateTranslationLoadBalancerModels(BaseModel):
    model: str
    r"""Model identifier for load balancing"""

    weight: Optional[float] = 0.5
    r"""Weight assigned to this model for load balancing"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["weight"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateTranslationLoadBalancer1TypedDict(TypedDict):
    type: CreateTranslationLoadBalancerType
    models: List[CreateTranslationLoadBalancerModelsTypedDict]


class CreateTranslationLoadBalancer1(BaseModel):
    type: CreateTranslationLoadBalancerType

    models: List[CreateTranslationLoadBalancerModels]


CreateTranslationLoadBalancerTypedDict = CreateTranslationLoadBalancer1TypedDict
r"""Array of models with weights for load balancing requests"""


CreateTranslationLoadBalancer = CreateTranslationLoadBalancer1
r"""Array of models with weights for load balancing requests"""


class CreateTranslationTimeoutTypedDict(TypedDict):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateTranslationTimeout(BaseModel):
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    call_timeout: float
    r"""Timeout value in milliseconds"""


class CreateTranslationOrqTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name to display on the trace. If not specified, the default system name will be used."""
    fallbacks: NotRequired[List[CreateTranslationFallbacksTypedDict]]
    r"""Array of fallback models to use if primary model fails"""
    retry: NotRequired[CreateTranslationRetryTypedDict]
    r"""Retry configuration for the request"""
    identity: NotRequired[PublicContactTypedDict]
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""
    contact: NotRequired[CreateTranslationContactTypedDict]
    load_balancer: NotRequired[CreateTranslationLoadBalancerTypedDict]
    r"""Array of models with weights for load balancing requests"""
    timeout: NotRequired[CreateTranslationTimeoutTypedDict]
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""


class CreateTranslationOrq(BaseModel):
    name: Optional[str] = None
    r"""The name to display on the trace. If not specified, the default system name will be used."""

    fallbacks: Optional[List[CreateTranslationFallbacks]] = None
    r"""Array of fallback models to use if primary model fails"""

    retry: Optional[CreateTranslationRetry] = None
    r"""Retry configuration for the request"""

    identity: Optional[PublicContact] = None
    r"""Information about the identity making the request. If the identity does not exist, it will be created automatically."""

    contact: Optional[CreateTranslationContact] = None

    load_balancer: Optional[CreateTranslationLoadBalancer] = None
    r"""Array of models with weights for load balancing requests"""

    timeout: Optional[CreateTranslationTimeout] = None
    r"""Timeout configuration to apply to the request. If the request exceeds the timeout, it will be retried or fallback to the next model if configured."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "name",
                "fallbacks",
                "retry",
                "identity",
                "contact",
                "load_balancer",
                "timeout",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateTranslationFileTypedDict(TypedDict):
    file_name: str
    content: Union[bytes, IO[bytes], io.BufferedReader]
    content_type: NotRequired[str]


class CreateTranslationFile(BaseModel):
    file_name: Annotated[
        str, pydantic.Field(alias="fileName"), FieldMetadata(multipart=True)
    ]

    content: Annotated[
        Union[bytes, IO[bytes], io.BufferedReader],
        pydantic.Field(alias=""),
        FieldMetadata(multipart=MultipartFormMetadata(content=True)),
    ]

    content_type: Annotated[
        Optional[str],
        pydantic.Field(alias="Content-Type"),
        FieldMetadata(multipart=True),
    ] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["contentType"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateTranslationRequestBodyTypedDict(TypedDict):
    r"""Translates audio into English."""

    model: str
    r"""ID of the model to use"""
    prompt: NotRequired[str]
    r"""An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language."""
    enable_logging: NotRequired[bool]
    r"""When enable_logging is set to false, zero retention mode is used. This disables history features like request stitching and is only available to enterprise customers."""
    diarize: NotRequired[bool]
    r"""Whether to annotate which speaker is currently talking in the uploaded file."""
    response_format: NotRequired[CreateTranslationResponseFormat]
    r"""The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt."""
    tag_audio_events: NotRequired[bool]
    r"""Whether to tag audio events like (laughter), (footsteps), etc. in the transcription."""
    num_speakers: NotRequired[float]
    r"""The maximum amount of speakers talking in the uploaded file. Helps with predicting who speaks when, the maximum is 32."""
    timestamps_granularity: NotRequired[CreateTranslationTimestampsGranularity]
    r"""The granularity of the timestamps in the transcription. Word provides word-level timestamps and character provides character-level timestamps per word."""
    temperature: NotRequired[float]
    r"""The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit."""
    orq: NotRequired[CreateTranslationOrqTypedDict]
    file: NotRequired[CreateTranslationFileTypedDict]
    r"""The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm."""


class CreateTranslationRequestBody(BaseModel):
    r"""Translates audio into English."""

    model: Annotated[str, FieldMetadata(multipart=True)]
    r"""ID of the model to use"""

    prompt: Annotated[Optional[str], FieldMetadata(multipart=True)] = None
    r"""An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language."""

    enable_logging: Annotated[Optional[bool], FieldMetadata(multipart=True)] = True
    r"""When enable_logging is set to false, zero retention mode is used. This disables history features like request stitching and is only available to enterprise customers."""

    diarize: Annotated[Optional[bool], FieldMetadata(multipart=True)] = False
    r"""Whether to annotate which speaker is currently talking in the uploaded file."""

    response_format: Annotated[
        Optional[CreateTranslationResponseFormat], FieldMetadata(multipart=True)
    ] = None
    r"""The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt."""

    tag_audio_events: Annotated[Optional[bool], FieldMetadata(multipart=True)] = True
    r"""Whether to tag audio events like (laughter), (footsteps), etc. in the transcription."""

    num_speakers: Annotated[Optional[float], FieldMetadata(multipart=True)] = None
    r"""The maximum amount of speakers talking in the uploaded file. Helps with predicting who speaks when, the maximum is 32."""

    timestamps_granularity: Annotated[
        Optional[CreateTranslationTimestampsGranularity], FieldMetadata(multipart=True)
    ] = "word"
    r"""The granularity of the timestamps in the transcription. Word provides word-level timestamps and character provides character-level timestamps per word."""

    temperature: Annotated[Optional[float], FieldMetadata(multipart=True)] = None
    r"""The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit."""

    orq: Annotated[
        Optional[CreateTranslationOrq],
        FieldMetadata(multipart=MultipartFormMetadata(json=True)),
    ] = None

    file: Annotated[
        Optional[CreateTranslationFile],
        FieldMetadata(multipart=MultipartFormMetadata(file=True)),
    ] = None
    r"""The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "prompt",
                "enable_logging",
                "diarize",
                "response_format",
                "tag_audio_events",
                "num_speakers",
                "timestamps_granularity",
                "temperature",
                "orq",
                "file",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateTranslationErrorTypedDict(TypedDict):
    message: str
    type: str
    param: Nullable[str]
    code: str


class CreateTranslationError(BaseModel):
    message: str

    type: str

    param: Nullable[str]

    code: str

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                m[k] = val

        return m


class CreateTranslationRouterAudioTranslationsResponseBodyData(BaseModel):
    error: CreateTranslationError


@dataclass(unsafe_hash=True)
class CreateTranslationRouterAudioTranslationsResponseBody(OrqError):
    r"""Returns validation error"""

    data: CreateTranslationRouterAudioTranslationsResponseBodyData = field(hash=False)

    def __init__(
        self,
        data: CreateTranslationRouterAudioTranslationsResponseBodyData,
        raw_response: httpx.Response,
        body: Optional[str] = None,
    ):
        fallback = body or raw_response.text
        message = str(data.error.message) or fallback
        super().__init__(message, raw_response, body)
        object.__setattr__(self, "data", data)


class ResponseBodyWordsTypedDict(TypedDict):
    word: NotRequired[str]
    start: NotRequired[float]
    end: NotRequired[float]


class ResponseBodyWords(BaseModel):
    word: Optional[str] = None

    start: Optional[float] = None

    end: Optional[float] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["word", "start", "end"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class ResponseBodySegmentsTypedDict(TypedDict):
    id: float
    seek: float
    start: float
    end: float
    text: str
    tokens: List[float]
    temperature: float
    avg_logprob: float
    compression_ratio: float
    no_speech_prob: float


class ResponseBodySegments(BaseModel):
    id: float

    seek: float

    start: float

    end: float

    text: str

    tokens: List[float]

    temperature: float

    avg_logprob: float

    compression_ratio: float

    no_speech_prob: float


class CreateTranslationResponseBody2TypedDict(TypedDict):
    text: str
    task: NotRequired[str]
    language: NotRequired[str]
    duration: NotRequired[float]
    words: NotRequired[List[ResponseBodyWordsTypedDict]]
    segments: NotRequired[List[ResponseBodySegmentsTypedDict]]


class CreateTranslationResponseBody2(BaseModel):
    text: str

    task: Optional[str] = None

    language: Optional[str] = None

    duration: Optional[float] = None

    words: Optional[List[ResponseBodyWords]] = None

    segments: Optional[List[ResponseBodySegments]] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["task", "language", "duration", "words", "segments"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class CreateTranslationResponseBody1TypedDict(TypedDict):
    text: str


class CreateTranslationResponseBody1(BaseModel):
    text: str


CreateTranslationResponseBodyTypedDict = TypeAliasType(
    "CreateTranslationResponseBodyTypedDict",
    Union[
        CreateTranslationResponseBody1TypedDict,
        CreateTranslationResponseBody2TypedDict,
        str,
    ],
)
r"""Returns the translated text"""


CreateTranslationResponseBody = TypeAliasType(
    "CreateTranslationResponseBody",
    Union[CreateTranslationResponseBody1, CreateTranslationResponseBody2, str],
)
r"""Returns the translated text"""
