"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from orq_ai_sdk.types import BaseModel, Nullable, UNSET_SENTINEL
from orq_ai_sdk.utils import FieldMetadata, QueryParamMetadata
from pydantic import model_serializer
from typing import Any, Dict, List, Literal, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class ListBatchesRequestTypedDict(TypedDict):
    after: str
    limit: NotRequired[float]


class ListBatchesRequest(BaseModel):
    after: Annotated[
        str, FieldMetadata(query=QueryParamMetadata(style="form", explode=True))
    ]

    limit: Annotated[
        Optional[float],
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = 10


ListBatchesObject = Literal["list"]

ListBatchesBatchesObject = Literal["batch"]
r"""The object type, which is always batch."""


class ListBatchesErrorsTypedDict(TypedDict):
    r"""Errors associated with the batch."""


class ListBatchesErrors(BaseModel):
    r"""Errors associated with the batch."""


class ListBatchesRequestCountsTypedDict(TypedDict):
    r"""The request counts for different statuses within the batch."""

    total: int
    r"""Total number of requests in the batch."""
    completed: int
    r"""Number of requests that have been completed successfully."""
    failed: int
    r"""Number of requests that have failed."""


class ListBatchesRequestCounts(BaseModel):
    r"""The request counts for different statuses within the batch."""

    total: int
    r"""Total number of requests in the batch."""

    completed: int
    r"""Number of requests that have been completed successfully."""

    failed: int
    r"""Number of requests that have failed."""


class ListBatchesDataTypedDict(TypedDict):
    id: str
    r"""The ID of the batch job."""
    object: ListBatchesBatchesObject
    r"""The object type, which is always batch."""
    endpoint: str
    r"""The OpenAI API endpoint used by the batch."""
    errors: ListBatchesErrorsTypedDict
    r"""Errors associated with the batch."""
    input_file_id: str
    r"""The ID of the input file for the batch."""
    completion_window: str
    r"""The time frame within which the batch should be processed."""
    status: str
    r"""The current status of the batch."""
    output_file_id: Nullable[str]
    r"""The ID of the file containing the outputs of successfully executed requests."""
    error_file_id: Nullable[str]
    r"""The ID of the file containing the outputs of requests with errors."""
    created_at: int
    r"""The Unix timestamp (in seconds) for when the batch was created."""
    in_progress_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch started processing."""
    expires_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch will expire."""
    finalizing_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch started finalizing."""
    completed_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch was completed."""
    failed_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch failed."""
    expired_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch expired."""
    cancelling_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch started cancelling."""
    cancelled_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch was cancelled."""
    request_counts: ListBatchesRequestCountsTypedDict
    r"""The request counts for different statuses within the batch."""
    metadata: NotRequired[Dict[str, Any]]
    r"""Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

    Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.
    """


class ListBatchesData(BaseModel):
    id: str
    r"""The ID of the batch job."""

    object: ListBatchesBatchesObject
    r"""The object type, which is always batch."""

    endpoint: str
    r"""The OpenAI API endpoint used by the batch."""

    errors: ListBatchesErrors
    r"""Errors associated with the batch."""

    input_file_id: str
    r"""The ID of the input file for the batch."""

    completion_window: str
    r"""The time frame within which the batch should be processed."""

    status: str
    r"""The current status of the batch."""

    output_file_id: Nullable[str]
    r"""The ID of the file containing the outputs of successfully executed requests."""

    error_file_id: Nullable[str]
    r"""The ID of the file containing the outputs of requests with errors."""

    created_at: int
    r"""The Unix timestamp (in seconds) for when the batch was created."""

    in_progress_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch started processing."""

    expires_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch will expire."""

    finalizing_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch started finalizing."""

    completed_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch was completed."""

    failed_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch failed."""

    expired_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch expired."""

    cancelling_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch started cancelling."""

    cancelled_at: Nullable[int]
    r"""The Unix timestamp (in seconds) for when the batch was cancelled."""

    request_counts: ListBatchesRequestCounts
    r"""The request counts for different statuses within the batch."""

    metadata: Optional[Dict[str, Any]] = None
    r"""Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

    Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.
    """

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["metadata"]
        nullable_fields = [
            "output_file_id",
            "error_file_id",
            "in_progress_at",
            "expires_at",
            "finalizing_at",
            "completed_at",
            "failed_at",
            "expired_at",
            "cancelling_at",
            "cancelled_at",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class ListBatchesResponseBodyTypedDict(TypedDict):
    r"""A list of paginated Batch objects."""

    object: ListBatchesObject
    data: List[ListBatchesDataTypedDict]
    has_more: bool


class ListBatchesResponseBody(BaseModel):
    r"""A list of paginated Batch objects."""

    object: ListBatchesObject

    data: List[ListBatchesData]

    has_more: bool
