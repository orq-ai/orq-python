"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from datetime import datetime
from orq_ai_sdk.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from orq_ai_sdk.utils import FieldMetadata, HeaderMetadata
import pydantic
from pydantic import model_serializer
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class DeploymentStreamGlobalsTypedDict(TypedDict):
    environment: NotRequired[str]
    contact_id: NotRequired[str]


class DeploymentStreamGlobals(BaseModel):
    environment: Annotated[
        Optional[str],
        FieldMetadata(header=HeaderMetadata(style="simple", explode=False)),
    ] = None

    contact_id: Annotated[
        Optional[str],
        pydantic.Field(alias="contactId"),
        FieldMetadata(header=HeaderMetadata(style="simple", explode=False)),
    ] = None


DeploymentStreamPrefixMessagesDeploymentsRequestRequestBody5Role = Literal["tool",]
r"""The role of the messages author, in this case tool."""


DeploymentStreamPrefixMessagesDeploymentsRequestContentTypedDict = TypeAliasType(
    "DeploymentStreamPrefixMessagesDeploymentsRequestContentTypedDict",
    Union[str, List[str]],
)
r"""The contents of the tool message."""


DeploymentStreamPrefixMessagesDeploymentsRequestContent = TypeAliasType(
    "DeploymentStreamPrefixMessagesDeploymentsRequestContent", Union[str, List[str]]
)
r"""The contents of the tool message."""


class DeploymentStreamPrefixMessagesToolMessageTypedDict(TypedDict):
    role: DeploymentStreamPrefixMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""
    content: DeploymentStreamPrefixMessagesDeploymentsRequestContentTypedDict
    r"""The contents of the tool message."""
    tool_call_id: str
    r"""Tool call that this message is responding to."""


class DeploymentStreamPrefixMessagesToolMessage(BaseModel):
    role: DeploymentStreamPrefixMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""

    content: DeploymentStreamPrefixMessagesDeploymentsRequestContent
    r"""The contents of the tool message."""

    tool_call_id: str
    r"""Tool call that this message is responding to."""


DeploymentStream2DeploymentsRequestRequestBodyPrefixMessages4Type = Literal["refusal",]
r"""The type of the content part."""


class DeploymentStream2RefusalContentPartTypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyPrefixMessages4Type
    r"""The type of the content part."""
    refusal: str
    r"""The refusal message generated by the model."""


class DeploymentStream2RefusalContentPart(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyPrefixMessages4Type
    r"""The type of the content part."""

    refusal: str
    r"""The refusal message generated by the model."""


DeploymentStream2DeploymentsRequestRequestBodyPrefixMessagesType = Literal["text",]
r"""The type of the content part."""


DeploymentStreamAnnotationsDeploymentsType = Literal["file_path",]


class DeploymentStreamAnnotationsFilePathTypedDict(TypedDict):
    file_id: str


class DeploymentStreamAnnotationsFilePath(BaseModel):
    file_id: str


class DeploymentStreamAnnotations2TypedDict(TypedDict):
    type: DeploymentStreamAnnotationsDeploymentsType
    text: str
    file_path: DeploymentStreamAnnotationsFilePathTypedDict
    start_index: int
    end_index: int


class DeploymentStreamAnnotations2(BaseModel):
    type: DeploymentStreamAnnotationsDeploymentsType

    text: str

    file_path: DeploymentStreamAnnotationsFilePath

    start_index: int

    end_index: int


DeploymentStreamAnnotationsType = Literal["file_citation",]


class DeploymentStreamAnnotationsFileCitationTypedDict(TypedDict):
    file_id: str
    quote: NotRequired[str]


class DeploymentStreamAnnotationsFileCitation(BaseModel):
    file_id: str

    quote: Optional[str] = None


class DeploymentStreamAnnotations1TypedDict(TypedDict):
    type: DeploymentStreamAnnotationsType
    text: str
    file_citation: DeploymentStreamAnnotationsFileCitationTypedDict
    start_index: int
    end_index: int


class DeploymentStreamAnnotations1(BaseModel):
    type: DeploymentStreamAnnotationsType

    text: str

    file_citation: DeploymentStreamAnnotationsFileCitation

    start_index: int

    end_index: int


DeploymentStream2AnnotationsTypedDict = TypeAliasType(
    "DeploymentStream2AnnotationsTypedDict",
    Union[DeploymentStreamAnnotations1TypedDict, DeploymentStreamAnnotations2TypedDict],
)


DeploymentStream2Annotations = TypeAliasType(
    "DeploymentStream2Annotations",
    Union[DeploymentStreamAnnotations1, DeploymentStreamAnnotations2],
)


class DeploymentStream2TextContentPartTypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyPrefixMessagesType
    r"""The type of the content part."""
    text: str
    r"""The text content."""
    annotations: NotRequired[List[DeploymentStream2AnnotationsTypedDict]]
    r"""Annotations for the text content."""


class DeploymentStream2TextContentPart(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyPrefixMessagesType
    r"""The type of the content part."""

    text: str
    r"""The text content."""

    annotations: Optional[List[DeploymentStream2Annotations]] = None
    r"""Annotations for the text content."""


DeploymentStreamContentDeployments2TypedDict = TypeAliasType(
    "DeploymentStreamContentDeployments2TypedDict",
    Union[
        DeploymentStream2RefusalContentPartTypedDict,
        DeploymentStream2TextContentPartTypedDict,
    ],
)


DeploymentStreamContentDeployments2 = TypeAliasType(
    "DeploymentStreamContentDeployments2",
    Union[DeploymentStream2RefusalContentPart, DeploymentStream2TextContentPart],
)


DeploymentStreamPrefixMessagesDeploymentsContentTypedDict = TypeAliasType(
    "DeploymentStreamPrefixMessagesDeploymentsContentTypedDict",
    Union[str, List[DeploymentStreamContentDeployments2TypedDict]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentStreamPrefixMessagesDeploymentsContent = TypeAliasType(
    "DeploymentStreamPrefixMessagesDeploymentsContent",
    Union[str, List[DeploymentStreamContentDeployments2]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentStreamPrefixMessagesDeploymentsRequestRequestBodyRole = Literal["assistant",]
r"""The role of the messages author, in this case `assistant`."""


class DeploymentStreamPrefixMessagesAudioTypedDict(TypedDict):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


class DeploymentStreamPrefixMessagesAudio(BaseModel):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


DeploymentStreamPrefixMessagesType = Literal["function",]
r"""The type of the tool. Currently, only `function` is supported."""


class DeploymentStreamPrefixMessagesFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name of the function to call."""
    arguments: NotRequired[str]
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentStreamPrefixMessagesFunction(BaseModel):
    name: Optional[str] = None
    r"""The name of the function to call."""

    arguments: Optional[str] = None
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentStreamPrefixMessagesToolCallsTypedDict(TypedDict):
    id: str
    r"""The ID of the tool call."""
    type: DeploymentStreamPrefixMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: DeploymentStreamPrefixMessagesFunctionTypedDict


class DeploymentStreamPrefixMessagesToolCalls(BaseModel):
    id: str
    r"""The ID of the tool call."""

    type: DeploymentStreamPrefixMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: DeploymentStreamPrefixMessagesFunction


class DeploymentStreamPrefixMessagesAssistantMessageTypedDict(TypedDict):
    role: DeploymentStreamPrefixMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""
    content: NotRequired[
        Nullable[DeploymentStreamPrefixMessagesDeploymentsContentTypedDict]
    ]
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""
    refusal: NotRequired[Nullable[str]]
    r"""The refusal message by the assistant."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""
    audio: NotRequired[Nullable[DeploymentStreamPrefixMessagesAudioTypedDict]]
    r"""Data about a previous audio response from the model."""
    tool_calls: NotRequired[List[DeploymentStreamPrefixMessagesToolCallsTypedDict]]
    r"""The tool calls generated by the model, such as function calls."""
    reasoning: NotRequired[str]
    r"""Internal thought process of the model"""
    reasoning_signature: NotRequired[str]
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""
    redacted_reasoning: NotRequired[str]
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""


class DeploymentStreamPrefixMessagesAssistantMessage(BaseModel):
    role: DeploymentStreamPrefixMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""

    content: OptionalNullable[DeploymentStreamPrefixMessagesDeploymentsContent] = UNSET
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""

    refusal: OptionalNullable[str] = UNSET
    r"""The refusal message by the assistant."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    audio: OptionalNullable[DeploymentStreamPrefixMessagesAudio] = UNSET
    r"""Data about a previous audio response from the model."""

    tool_calls: Optional[List[DeploymentStreamPrefixMessagesToolCalls]] = None
    r"""The tool calls generated by the model, such as function calls."""

    reasoning: Optional[str] = None
    r"""Internal thought process of the model"""

    reasoning_signature: Optional[str] = None
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""

    redacted_reasoning: Optional[str] = None
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "content",
            "refusal",
            "name",
            "audio",
            "tool_calls",
            "reasoning",
            "reasoning_signature",
            "redacted_reasoning",
        ]
        nullable_fields = ["content", "refusal", "audio"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


DeploymentStreamPrefixMessagesDeploymentsRequestRole = Literal["user",]
r"""The role of the messages author, in this case `user`."""


DeploymentStream2DeploymentsRequestRequestBodyType = Literal["file",]
r"""The type of the content part. Always `file`."""


class DeploymentStream2FileTypedDict(TypedDict):
    r"""File data for the content part. Must contain either file_data or uri, but not both."""

    file_data: NotRequired[str]
    r"""The file data as a data URI string in the format 'data:<mime-type>;base64,<base64-encoded-data>'. Example: 'data:image/png;base64,iVBORw0KGgoAAAANS...'"""
    uri: NotRequired[str]
    r"""URL to the file. Only supported by Anthropic Claude models for PDF files."""
    mime_type: NotRequired[str]
    r"""MIME type of the file (e.g., application/pdf, image/png)"""
    filename: NotRequired[str]
    r"""The name of the file, used when passing the file to the model as a string."""


class DeploymentStream2File(BaseModel):
    r"""File data for the content part. Must contain either file_data or uri, but not both."""

    file_data: Optional[str] = None
    r"""The file data as a data URI string in the format 'data:<mime-type>;base64,<base64-encoded-data>'. Example: 'data:image/png;base64,iVBORw0KGgoAAAANS...'"""

    uri: Optional[str] = None
    r"""URL to the file. Only supported by Anthropic Claude models for PDF files."""

    mime_type: Annotated[Optional[str], pydantic.Field(alias="mimeType")] = None
    r"""MIME type of the file (e.g., application/pdf, image/png)"""

    filename: Optional[str] = None
    r"""The name of the file, used when passing the file to the model as a string."""


class DeploymentStream24TypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyType
    r"""The type of the content part. Always `file`."""
    file: DeploymentStream2FileTypedDict
    r"""File data for the content part. Must contain either file_data or uri, but not both."""


class DeploymentStream24(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyType
    r"""The type of the content part. Always `file`."""

    file: DeploymentStream2File
    r"""File data for the content part. Must contain either file_data or uri, but not both."""


DeploymentStream2DeploymentsRequestType = Literal["input_audio",]


DeploymentStream2Format = Literal[
    "mp3",
    "wav",
]
r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentStream2InputAudioTypedDict(TypedDict):
    data: str
    r"""Base64 encoded audio data."""
    format_: DeploymentStream2Format
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentStream2InputAudio(BaseModel):
    data: str
    r"""Base64 encoded audio data."""

    format_: Annotated[DeploymentStream2Format, pydantic.Field(alias="format")]
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentStream23TypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestType
    input_audio: DeploymentStream2InputAudioTypedDict


class DeploymentStream23(BaseModel):
    type: DeploymentStream2DeploymentsRequestType

    input_audio: DeploymentStream2InputAudio


DeploymentStream2DeploymentsType = Literal["image_url",]


DeploymentStream2Detail = Literal[
    "low",
    "high",
    "auto",
]
r"""Specifies the detail level of the image."""


class DeploymentStream2ImageURLTypedDict(TypedDict):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""
    detail: NotRequired[DeploymentStream2Detail]
    r"""Specifies the detail level of the image."""


class DeploymentStream2ImageURL(BaseModel):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""

    detail: Optional[DeploymentStream2Detail] = None
    r"""Specifies the detail level of the image."""


class DeploymentStream22TypedDict(TypedDict):
    type: DeploymentStream2DeploymentsType
    image_url: DeploymentStream2ImageURLTypedDict


class DeploymentStream22(BaseModel):
    type: DeploymentStream2DeploymentsType

    image_url: DeploymentStream2ImageURL


DeploymentStream2Type = Literal["text",]


class DeploymentStream21TypedDict(TypedDict):
    type: DeploymentStream2Type
    text: str


class DeploymentStream21(BaseModel):
    type: DeploymentStream2Type

    text: str


DeploymentStreamContent2TypedDict = TypeAliasType(
    "DeploymentStreamContent2TypedDict",
    Union[
        DeploymentStream21TypedDict,
        DeploymentStream22TypedDict,
        DeploymentStream23TypedDict,
        DeploymentStream24TypedDict,
    ],
)


DeploymentStreamContent2 = TypeAliasType(
    "DeploymentStreamContent2",
    Union[
        DeploymentStream21, DeploymentStream22, DeploymentStream23, DeploymentStream24
    ],
)


DeploymentStreamPrefixMessagesContentTypedDict = TypeAliasType(
    "DeploymentStreamPrefixMessagesContentTypedDict",
    Union[str, List[DeploymentStreamContent2TypedDict]],
)
r"""The contents of the user message."""


DeploymentStreamPrefixMessagesContent = TypeAliasType(
    "DeploymentStreamPrefixMessagesContent", Union[str, List[DeploymentStreamContent2]]
)
r"""The contents of the user message."""


class DeploymentStreamPrefixMessagesUserMessageTypedDict(TypedDict):
    role: DeploymentStreamPrefixMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""
    content: DeploymentStreamPrefixMessagesContentTypedDict
    r"""The contents of the user message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentStreamPrefixMessagesUserMessage(BaseModel):
    role: DeploymentStreamPrefixMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""

    content: DeploymentStreamPrefixMessagesContent
    r"""The contents of the user message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentStreamPrefixMessagesDeploymentsRole = Literal["system",]
r"""The role of the messages author, in this case `system`."""


class DeploymentStreamPrefixMessagesSystemMessageTypedDict(TypedDict):
    role: DeploymentStreamPrefixMessagesDeploymentsRole
    r"""The role of the messages author, in this case `system`."""
    content: str
    r"""The contents of the system message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentStreamPrefixMessagesSystemMessage(BaseModel):
    role: DeploymentStreamPrefixMessagesDeploymentsRole
    r"""The role of the messages author, in this case `system`."""

    content: str
    r"""The contents of the system message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentStreamPrefixMessagesRole = Literal["developer",]
r"""The role of the messages author, in this case  `developer`."""


class DeploymentStreamPrefixMessagesDeveloperMessageTypedDict(TypedDict):
    role: DeploymentStreamPrefixMessagesRole
    r"""The role of the messages author, in this case  `developer`."""
    content: str
    r"""The contents of the developer message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentStreamPrefixMessagesDeveloperMessage(BaseModel):
    role: DeploymentStreamPrefixMessagesRole
    r"""The role of the messages author, in this case  `developer`."""

    content: str
    r"""The contents of the developer message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentStreamPrefixMessagesTypedDict = TypeAliasType(
    "DeploymentStreamPrefixMessagesTypedDict",
    Union[
        DeploymentStreamPrefixMessagesDeveloperMessageTypedDict,
        DeploymentStreamPrefixMessagesSystemMessageTypedDict,
        DeploymentStreamPrefixMessagesUserMessageTypedDict,
        DeploymentStreamPrefixMessagesToolMessageTypedDict,
        DeploymentStreamPrefixMessagesAssistantMessageTypedDict,
    ],
)


DeploymentStreamPrefixMessages = TypeAliasType(
    "DeploymentStreamPrefixMessages",
    Union[
        DeploymentStreamPrefixMessagesDeveloperMessage,
        DeploymentStreamPrefixMessagesSystemMessage,
        DeploymentStreamPrefixMessagesUserMessage,
        DeploymentStreamPrefixMessagesToolMessage,
        DeploymentStreamPrefixMessagesAssistantMessage,
    ],
)


DeploymentStreamMessagesDeploymentsRequestRequestBody5Role = Literal["tool",]
r"""The role of the messages author, in this case tool."""


DeploymentStreamMessagesDeploymentsRequestContentTypedDict = TypeAliasType(
    "DeploymentStreamMessagesDeploymentsRequestContentTypedDict", Union[str, List[str]]
)
r"""The contents of the tool message."""


DeploymentStreamMessagesDeploymentsRequestContent = TypeAliasType(
    "DeploymentStreamMessagesDeploymentsRequestContent", Union[str, List[str]]
)
r"""The contents of the tool message."""


class DeploymentStreamMessagesToolMessageTypedDict(TypedDict):
    role: DeploymentStreamMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""
    content: DeploymentStreamMessagesDeploymentsRequestContentTypedDict
    r"""The contents of the tool message."""
    tool_call_id: str
    r"""Tool call that this message is responding to."""


class DeploymentStreamMessagesToolMessage(BaseModel):
    role: DeploymentStreamMessagesDeploymentsRequestRequestBody5Role
    r"""The role of the messages author, in this case tool."""

    content: DeploymentStreamMessagesDeploymentsRequestContent
    r"""The contents of the tool message."""

    tool_call_id: str
    r"""Tool call that this message is responding to."""


DeploymentStream2DeploymentsRequestRequestBodyMessages4ContentType = Literal["refusal",]
r"""The type of the content part."""


class DeploymentStream2DeploymentsRefusalContentPartTypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages4ContentType
    r"""The type of the content part."""
    refusal: str
    r"""The refusal message generated by the model."""


class DeploymentStream2DeploymentsRefusalContentPart(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages4ContentType
    r"""The type of the content part."""

    refusal: str
    r"""The refusal message generated by the model."""


DeploymentStream2DeploymentsRequestRequestBodyMessages4Type = Literal["text",]
r"""The type of the content part."""


DeploymentStreamAnnotationsDeploymentsRequestRequestBodyType = Literal["file_path",]


class DeploymentStreamAnnotationsDeploymentsFilePathTypedDict(TypedDict):
    file_id: str


class DeploymentStreamAnnotationsDeploymentsFilePath(BaseModel):
    file_id: str


class DeploymentStreamAnnotationsDeployments2TypedDict(TypedDict):
    type: DeploymentStreamAnnotationsDeploymentsRequestRequestBodyType
    text: str
    file_path: DeploymentStreamAnnotationsDeploymentsFilePathTypedDict
    start_index: int
    end_index: int


class DeploymentStreamAnnotationsDeployments2(BaseModel):
    type: DeploymentStreamAnnotationsDeploymentsRequestRequestBodyType

    text: str

    file_path: DeploymentStreamAnnotationsDeploymentsFilePath

    start_index: int

    end_index: int


DeploymentStreamAnnotationsDeploymentsRequestType = Literal["file_citation",]


class DeploymentStreamAnnotationsDeploymentsFileCitationTypedDict(TypedDict):
    file_id: str
    quote: NotRequired[str]


class DeploymentStreamAnnotationsDeploymentsFileCitation(BaseModel):
    file_id: str

    quote: Optional[str] = None


class DeploymentStreamAnnotationsDeployments1TypedDict(TypedDict):
    type: DeploymentStreamAnnotationsDeploymentsRequestType
    text: str
    file_citation: DeploymentStreamAnnotationsDeploymentsFileCitationTypedDict
    start_index: int
    end_index: int


class DeploymentStreamAnnotationsDeployments1(BaseModel):
    type: DeploymentStreamAnnotationsDeploymentsRequestType

    text: str

    file_citation: DeploymentStreamAnnotationsDeploymentsFileCitation

    start_index: int

    end_index: int


DeploymentStream2DeploymentsAnnotationsTypedDict = TypeAliasType(
    "DeploymentStream2DeploymentsAnnotationsTypedDict",
    Union[
        DeploymentStreamAnnotationsDeployments1TypedDict,
        DeploymentStreamAnnotationsDeployments2TypedDict,
    ],
)


DeploymentStream2DeploymentsAnnotations = TypeAliasType(
    "DeploymentStream2DeploymentsAnnotations",
    Union[
        DeploymentStreamAnnotationsDeployments1, DeploymentStreamAnnotationsDeployments2
    ],
)


class DeploymentStream2DeploymentsTextContentPartTypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages4Type
    r"""The type of the content part."""
    text: str
    r"""The text content."""
    annotations: NotRequired[List[DeploymentStream2DeploymentsAnnotationsTypedDict]]
    r"""Annotations for the text content."""


class DeploymentStream2DeploymentsTextContentPart(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages4Type
    r"""The type of the content part."""

    text: str
    r"""The text content."""

    annotations: Optional[List[DeploymentStream2DeploymentsAnnotations]] = None
    r"""Annotations for the text content."""


DeploymentStreamContentDeploymentsRequestRequestBody2TypedDict = TypeAliasType(
    "DeploymentStreamContentDeploymentsRequestRequestBody2TypedDict",
    Union[
        DeploymentStream2DeploymentsRefusalContentPartTypedDict,
        DeploymentStream2DeploymentsTextContentPartTypedDict,
    ],
)


DeploymentStreamContentDeploymentsRequestRequestBody2 = TypeAliasType(
    "DeploymentStreamContentDeploymentsRequestRequestBody2",
    Union[
        DeploymentStream2DeploymentsRefusalContentPart,
        DeploymentStream2DeploymentsTextContentPart,
    ],
)


DeploymentStreamMessagesDeploymentsContentTypedDict = TypeAliasType(
    "DeploymentStreamMessagesDeploymentsContentTypedDict",
    Union[str, List[DeploymentStreamContentDeploymentsRequestRequestBody2TypedDict]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentStreamMessagesDeploymentsContent = TypeAliasType(
    "DeploymentStreamMessagesDeploymentsContent",
    Union[str, List[DeploymentStreamContentDeploymentsRequestRequestBody2]],
)
r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""


DeploymentStreamMessagesDeploymentsRequestRequestBodyRole = Literal["assistant",]
r"""The role of the messages author, in this case `assistant`."""


class DeploymentStreamMessagesAudioTypedDict(TypedDict):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


class DeploymentStreamMessagesAudio(BaseModel):
    r"""Data about a previous audio response from the model."""

    id: str
    r"""Unique identifier for a previous audio response from the model."""


DeploymentStreamMessagesType = Literal["function",]
r"""The type of the tool. Currently, only `function` is supported."""


class DeploymentStreamMessagesFunctionTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The name of the function to call."""
    arguments: NotRequired[str]
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentStreamMessagesFunction(BaseModel):
    name: Optional[str] = None
    r"""The name of the function to call."""

    arguments: Optional[str] = None
    r"""The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."""


class DeploymentStreamMessagesToolCallsTypedDict(TypedDict):
    id: str
    r"""The ID of the tool call."""
    type: DeploymentStreamMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""
    function: DeploymentStreamMessagesFunctionTypedDict


class DeploymentStreamMessagesToolCalls(BaseModel):
    id: str
    r"""The ID of the tool call."""

    type: DeploymentStreamMessagesType
    r"""The type of the tool. Currently, only `function` is supported."""

    function: DeploymentStreamMessagesFunction


class DeploymentStreamMessagesAssistantMessageTypedDict(TypedDict):
    role: DeploymentStreamMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""
    content: NotRequired[Nullable[DeploymentStreamMessagesDeploymentsContentTypedDict]]
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""
    refusal: NotRequired[Nullable[str]]
    r"""The refusal message by the assistant."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""
    audio: NotRequired[Nullable[DeploymentStreamMessagesAudioTypedDict]]
    r"""Data about a previous audio response from the model."""
    tool_calls: NotRequired[List[DeploymentStreamMessagesToolCallsTypedDict]]
    r"""The tool calls generated by the model, such as function calls."""
    reasoning: NotRequired[str]
    r"""Internal thought process of the model"""
    reasoning_signature: NotRequired[str]
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""
    redacted_reasoning: NotRequired[str]
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""


class DeploymentStreamMessagesAssistantMessage(BaseModel):
    role: DeploymentStreamMessagesDeploymentsRequestRequestBodyRole
    r"""The role of the messages author, in this case `assistant`."""

    content: OptionalNullable[DeploymentStreamMessagesDeploymentsContent] = UNSET
    r"""The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified."""

    refusal: OptionalNullable[str] = UNSET
    r"""The refusal message by the assistant."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""

    audio: OptionalNullable[DeploymentStreamMessagesAudio] = UNSET
    r"""Data about a previous audio response from the model."""

    tool_calls: Optional[List[DeploymentStreamMessagesToolCalls]] = None
    r"""The tool calls generated by the model, such as function calls."""

    reasoning: Optional[str] = None
    r"""Internal thought process of the model"""

    reasoning_signature: Optional[str] = None
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""

    redacted_reasoning: Optional[str] = None
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "content",
            "refusal",
            "name",
            "audio",
            "tool_calls",
            "reasoning",
            "reasoning_signature",
            "redacted_reasoning",
        ]
        nullable_fields = ["content", "refusal", "audio"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


DeploymentStreamMessagesDeploymentsRequestRole = Literal["user",]
r"""The role of the messages author, in this case `user`."""


DeploymentStream2DeploymentsRequestRequestBodyMessages3Content4Type = Literal["file",]
r"""The type of the content part. Always `file`."""


class DeploymentStream2DeploymentsFileTypedDict(TypedDict):
    r"""File data for the content part. Must contain either file_data or uri, but not both."""

    file_data: NotRequired[str]
    r"""The file data as a data URI string in the format 'data:<mime-type>;base64,<base64-encoded-data>'. Example: 'data:image/png;base64,iVBORw0KGgoAAAANS...'"""
    uri: NotRequired[str]
    r"""URL to the file. Only supported by Anthropic Claude models for PDF files."""
    mime_type: NotRequired[str]
    r"""MIME type of the file (e.g., application/pdf, image/png)"""
    filename: NotRequired[str]
    r"""The name of the file, used when passing the file to the model as a string."""


class DeploymentStream2DeploymentsFile(BaseModel):
    r"""File data for the content part. Must contain either file_data or uri, but not both."""

    file_data: Optional[str] = None
    r"""The file data as a data URI string in the format 'data:<mime-type>;base64,<base64-encoded-data>'. Example: 'data:image/png;base64,iVBORw0KGgoAAAANS...'"""

    uri: Optional[str] = None
    r"""URL to the file. Only supported by Anthropic Claude models for PDF files."""

    mime_type: Annotated[Optional[str], pydantic.Field(alias="mimeType")] = None
    r"""MIME type of the file (e.g., application/pdf, image/png)"""

    filename: Optional[str] = None
    r"""The name of the file, used when passing the file to the model as a string."""


class DeploymentStream2Deployments4TypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages3Content4Type
    r"""The type of the content part. Always `file`."""
    file: DeploymentStream2DeploymentsFileTypedDict
    r"""File data for the content part. Must contain either file_data or uri, but not both."""


class DeploymentStream2Deployments4(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages3Content4Type
    r"""The type of the content part. Always `file`."""

    file: DeploymentStream2DeploymentsFile
    r"""File data for the content part. Must contain either file_data or uri, but not both."""


DeploymentStream2DeploymentsRequestRequestBodyMessages3ContentType = Literal[
    "input_audio",
]


DeploymentStream2DeploymentsFormat = Literal[
    "mp3",
    "wav",
]
r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentStream2DeploymentsInputAudioTypedDict(TypedDict):
    data: str
    r"""Base64 encoded audio data."""
    format_: DeploymentStream2DeploymentsFormat
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentStream2DeploymentsInputAudio(BaseModel):
    data: str
    r"""Base64 encoded audio data."""

    format_: Annotated[
        DeploymentStream2DeploymentsFormat, pydantic.Field(alias="format")
    ]
    r"""The format of the encoded audio data. Currently supports `wav` and `mp3`."""


class DeploymentStream2Deployments3TypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages3ContentType
    input_audio: DeploymentStream2DeploymentsInputAudioTypedDict


class DeploymentStream2Deployments3(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages3ContentType

    input_audio: DeploymentStream2DeploymentsInputAudio


DeploymentStream2DeploymentsRequestRequestBodyMessages3Type = Literal["image_url",]


DeploymentStream2DeploymentsDetail = Literal[
    "low",
    "high",
    "auto",
]
r"""Specifies the detail level of the image."""


class DeploymentStream2DeploymentsImageURLTypedDict(TypedDict):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""
    detail: NotRequired[DeploymentStream2DeploymentsDetail]
    r"""Specifies the detail level of the image."""


class DeploymentStream2DeploymentsImageURL(BaseModel):
    url: str
    r"""Either a URL of the image or the base64 encoded image data."""

    detail: Optional[DeploymentStream2DeploymentsDetail] = None
    r"""Specifies the detail level of the image."""


class DeploymentStream2Deployments2TypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages3Type
    image_url: DeploymentStream2DeploymentsImageURLTypedDict


class DeploymentStream2Deployments2(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessages3Type

    image_url: DeploymentStream2DeploymentsImageURL


DeploymentStream2DeploymentsRequestRequestBodyMessagesType = Literal["text",]


class DeploymentStream2Deployments1TypedDict(TypedDict):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessagesType
    text: str


class DeploymentStream2Deployments1(BaseModel):
    type: DeploymentStream2DeploymentsRequestRequestBodyMessagesType

    text: str


DeploymentStreamContentDeploymentsRequest2TypedDict = TypeAliasType(
    "DeploymentStreamContentDeploymentsRequest2TypedDict",
    Union[
        DeploymentStream2Deployments1TypedDict,
        DeploymentStream2Deployments2TypedDict,
        DeploymentStream2Deployments3TypedDict,
        DeploymentStream2Deployments4TypedDict,
    ],
)


DeploymentStreamContentDeploymentsRequest2 = TypeAliasType(
    "DeploymentStreamContentDeploymentsRequest2",
    Union[
        DeploymentStream2Deployments1,
        DeploymentStream2Deployments2,
        DeploymentStream2Deployments3,
        DeploymentStream2Deployments4,
    ],
)


DeploymentStreamMessagesContentTypedDict = TypeAliasType(
    "DeploymentStreamMessagesContentTypedDict",
    Union[str, List[DeploymentStreamContentDeploymentsRequest2TypedDict]],
)
r"""The contents of the user message."""


DeploymentStreamMessagesContent = TypeAliasType(
    "DeploymentStreamMessagesContent",
    Union[str, List[DeploymentStreamContentDeploymentsRequest2]],
)
r"""The contents of the user message."""


class DeploymentStreamMessagesUserMessageTypedDict(TypedDict):
    role: DeploymentStreamMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""
    content: DeploymentStreamMessagesContentTypedDict
    r"""The contents of the user message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentStreamMessagesUserMessage(BaseModel):
    role: DeploymentStreamMessagesDeploymentsRequestRole
    r"""The role of the messages author, in this case `user`."""

    content: DeploymentStreamMessagesContent
    r"""The contents of the user message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentStreamMessagesDeploymentsRole = Literal["system",]
r"""The role of the messages author, in this case `system`."""


class DeploymentStreamMessagesSystemMessageTypedDict(TypedDict):
    role: DeploymentStreamMessagesDeploymentsRole
    r"""The role of the messages author, in this case `system`."""
    content: str
    r"""The contents of the system message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentStreamMessagesSystemMessage(BaseModel):
    role: DeploymentStreamMessagesDeploymentsRole
    r"""The role of the messages author, in this case `system`."""

    content: str
    r"""The contents of the system message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentStreamMessagesRole = Literal["developer",]
r"""The role of the messages author, in this case  `developer`."""


class DeploymentStreamMessagesDeveloperMessageTypedDict(TypedDict):
    role: DeploymentStreamMessagesRole
    r"""The role of the messages author, in this case  `developer`."""
    content: str
    r"""The contents of the developer message."""
    name: NotRequired[str]
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


class DeploymentStreamMessagesDeveloperMessage(BaseModel):
    role: DeploymentStreamMessagesRole
    r"""The role of the messages author, in this case  `developer`."""

    content: str
    r"""The contents of the developer message."""

    name: Optional[str] = None
    r"""An optional name for the participant. Provides the model information to differentiate between participants of the same role."""


DeploymentStreamMessagesTypedDict = TypeAliasType(
    "DeploymentStreamMessagesTypedDict",
    Union[
        DeploymentStreamMessagesDeveloperMessageTypedDict,
        DeploymentStreamMessagesSystemMessageTypedDict,
        DeploymentStreamMessagesUserMessageTypedDict,
        DeploymentStreamMessagesToolMessageTypedDict,
        DeploymentStreamMessagesAssistantMessageTypedDict,
    ],
)


DeploymentStreamMessages = TypeAliasType(
    "DeploymentStreamMessages",
    Union[
        DeploymentStreamMessagesDeveloperMessage,
        DeploymentStreamMessagesSystemMessage,
        DeploymentStreamMessagesUserMessage,
        DeploymentStreamMessagesToolMessage,
        DeploymentStreamMessagesAssistantMessage,
    ],
)


class DeploymentStreamMetadataTypedDict(TypedDict):
    r"""Metadata about the document"""

    file_name: NotRequired[str]
    r"""Name of the file the text is from."""
    file_type: NotRequired[str]
    r"""Content type of the file the text is from."""
    page_number: NotRequired[float]
    r"""The page number the text is from."""


class DeploymentStreamMetadata(BaseModel):
    r"""Metadata about the document"""

    file_name: Optional[str] = None
    r"""Name of the file the text is from."""

    file_type: Optional[str] = None
    r"""Content type of the file the text is from."""

    page_number: Optional[float] = None
    r"""The page number the text is from."""


class DeploymentStreamDocumentsTypedDict(TypedDict):
    text: str
    r"""The text content of the document"""
    metadata: NotRequired[DeploymentStreamMetadataTypedDict]
    r"""Metadata about the document"""


class DeploymentStreamDocuments(BaseModel):
    text: str
    r"""The text content of the document"""

    metadata: Optional[DeploymentStreamMetadata] = None
    r"""Metadata about the document"""


class DeploymentStreamInvokeOptionsTypedDict(TypedDict):
    include_retrievals: NotRequired[bool]
    r"""Whether to include the retrieved knowledge chunks in the response."""
    mock_response: NotRequired[str]
    r"""A mock response to use instead of calling the LLM API. This is useful for testing purposes. When provided, the system will return a response object with this content as the completion, without making an actual API call to the LLM provider. This works for both streaming and non-streaming requests. Mock responses will not generate logs, traces or be counted for your plan usage."""


class DeploymentStreamInvokeOptions(BaseModel):
    include_retrievals: Optional[bool] = False
    r"""Whether to include the retrieved knowledge chunks in the response."""

    mock_response: Optional[str] = None
    r"""A mock response to use instead of calling the LLM API. This is useful for testing purposes. When provided, the system will return a response object with this content as the completion, without making an actual API call to the LLM provider. This works for both streaming and non-streaming requests. Mock responses will not generate logs, traces or be counted for your plan usage."""


class DeploymentStreamThreadTypedDict(TypedDict):
    id: str
    r"""Unique thread identifier to group related invocations."""
    tags: NotRequired[List[str]]
    r"""Optional tags to differentiate or categorize threads"""


class DeploymentStreamThread(BaseModel):
    id: str
    r"""Unique thread identifier to group related invocations."""

    tags: Optional[List[str]] = None
    r"""Optional tags to differentiate or categorize threads"""


class DeploymentStreamOrExistsTypedDict(TypedDict):
    r"""Exists"""

    exists: bool


class DeploymentStreamOrExists(BaseModel):
    r"""Exists"""

    exists: bool


DeploymentStreamOrDeploymentsNinTypedDict = TypeAliasType(
    "DeploymentStreamOrDeploymentsNinTypedDict", Union[str, float, bool]
)


DeploymentStreamOrDeploymentsNin = TypeAliasType(
    "DeploymentStreamOrDeploymentsNin", Union[str, float, bool]
)


class DeploymentStreamOrNinTypedDict(TypedDict):
    r"""Not in"""

    nin: List[DeploymentStreamOrDeploymentsNinTypedDict]


class DeploymentStreamOrNin(BaseModel):
    r"""Not in"""

    nin: List[DeploymentStreamOrDeploymentsNin]


DeploymentStreamOrDeploymentsInTypedDict = TypeAliasType(
    "DeploymentStreamOrDeploymentsInTypedDict", Union[str, float, bool]
)


DeploymentStreamOrDeploymentsIn = TypeAliasType(
    "DeploymentStreamOrDeploymentsIn", Union[str, float, bool]
)


class DeploymentStreamOrInTypedDict(TypedDict):
    r"""In"""

    in_: List[DeploymentStreamOrDeploymentsInTypedDict]


class DeploymentStreamOrIn(BaseModel):
    r"""In"""

    in_: Annotated[List[DeploymentStreamOrDeploymentsIn], pydantic.Field(alias="in")]


class DeploymentStreamOrLteTypedDict(TypedDict):
    r"""Less than or equal to"""

    lte: float


class DeploymentStreamOrLte(BaseModel):
    r"""Less than or equal to"""

    lte: float


class DeploymentStreamOrLtTypedDict(TypedDict):
    r"""Less than"""

    lt: float


class DeploymentStreamOrLt(BaseModel):
    r"""Less than"""

    lt: float


class DeploymentStreamOrGteTypedDict(TypedDict):
    r"""Greater than or equal to"""

    gte: float


class DeploymentStreamOrGte(BaseModel):
    r"""Greater than or equal to"""

    gte: float


class DeploymentStreamOrGtTypedDict(TypedDict):
    r"""Greater than"""

    gt: float


class DeploymentStreamOrGt(BaseModel):
    r"""Greater than"""

    gt: float


DeploymentStreamOrDeploymentsNeTypedDict = TypeAliasType(
    "DeploymentStreamOrDeploymentsNeTypedDict", Union[str, float, bool]
)


DeploymentStreamOrDeploymentsNe = TypeAliasType(
    "DeploymentStreamOrDeploymentsNe", Union[str, float, bool]
)


class DeploymentStreamOrNeTypedDict(TypedDict):
    r"""Not equal to"""

    ne: DeploymentStreamOrDeploymentsNeTypedDict


class DeploymentStreamOrNe(BaseModel):
    r"""Not equal to"""

    ne: DeploymentStreamOrDeploymentsNe


DeploymentStreamOrDeploymentsEqTypedDict = TypeAliasType(
    "DeploymentStreamOrDeploymentsEqTypedDict", Union[str, float, bool]
)


DeploymentStreamOrDeploymentsEq = TypeAliasType(
    "DeploymentStreamOrDeploymentsEq", Union[str, float, bool]
)


class DeploymentStreamOrEqTypedDict(TypedDict):
    r"""Equal to"""

    eq: DeploymentStreamOrDeploymentsEqTypedDict


class DeploymentStreamOrEq(BaseModel):
    r"""Equal to"""

    eq: DeploymentStreamOrDeploymentsEq


DeploymentStreamKnowledgeFilterDeploymentsOrTypedDict = TypeAliasType(
    "DeploymentStreamKnowledgeFilterDeploymentsOrTypedDict",
    Union[
        DeploymentStreamOrEqTypedDict,
        DeploymentStreamOrNeTypedDict,
        DeploymentStreamOrGtTypedDict,
        DeploymentStreamOrGteTypedDict,
        DeploymentStreamOrLtTypedDict,
        DeploymentStreamOrLteTypedDict,
        DeploymentStreamOrInTypedDict,
        DeploymentStreamOrNinTypedDict,
        DeploymentStreamOrExistsTypedDict,
    ],
)


DeploymentStreamKnowledgeFilterDeploymentsOr = TypeAliasType(
    "DeploymentStreamKnowledgeFilterDeploymentsOr",
    Union[
        DeploymentStreamOrEq,
        DeploymentStreamOrNe,
        DeploymentStreamOrGt,
        DeploymentStreamOrGte,
        DeploymentStreamOrLt,
        DeploymentStreamOrLte,
        DeploymentStreamOrIn,
        DeploymentStreamOrNin,
        DeploymentStreamOrExists,
    ],
)


class DeploymentStreamKnowledgeFilterOrTypedDict(TypedDict):
    r"""Or"""

    or_: List[Dict[str, DeploymentStreamKnowledgeFilterDeploymentsOrTypedDict]]


class DeploymentStreamKnowledgeFilterOr(BaseModel):
    r"""Or"""

    or_: Annotated[
        List[Dict[str, DeploymentStreamKnowledgeFilterDeploymentsOr]],
        pydantic.Field(alias="or"),
    ]


class DeploymentStreamAndExistsTypedDict(TypedDict):
    r"""Exists"""

    exists: bool


class DeploymentStreamAndExists(BaseModel):
    r"""Exists"""

    exists: bool


DeploymentStreamAndDeploymentsNinTypedDict = TypeAliasType(
    "DeploymentStreamAndDeploymentsNinTypedDict", Union[str, float, bool]
)


DeploymentStreamAndDeploymentsNin = TypeAliasType(
    "DeploymentStreamAndDeploymentsNin", Union[str, float, bool]
)


class DeploymentStreamAndNinTypedDict(TypedDict):
    r"""Not in"""

    nin: List[DeploymentStreamAndDeploymentsNinTypedDict]


class DeploymentStreamAndNin(BaseModel):
    r"""Not in"""

    nin: List[DeploymentStreamAndDeploymentsNin]


DeploymentStreamAndDeploymentsInTypedDict = TypeAliasType(
    "DeploymentStreamAndDeploymentsInTypedDict", Union[str, float, bool]
)


DeploymentStreamAndDeploymentsIn = TypeAliasType(
    "DeploymentStreamAndDeploymentsIn", Union[str, float, bool]
)


class DeploymentStreamAndInTypedDict(TypedDict):
    r"""In"""

    in_: List[DeploymentStreamAndDeploymentsInTypedDict]


class DeploymentStreamAndIn(BaseModel):
    r"""In"""

    in_: Annotated[List[DeploymentStreamAndDeploymentsIn], pydantic.Field(alias="in")]


class DeploymentStreamAndLteTypedDict(TypedDict):
    r"""Less than or equal to"""

    lte: float


class DeploymentStreamAndLte(BaseModel):
    r"""Less than or equal to"""

    lte: float


class DeploymentStreamAndLtTypedDict(TypedDict):
    r"""Less than"""

    lt: float


class DeploymentStreamAndLt(BaseModel):
    r"""Less than"""

    lt: float


class DeploymentStreamAndGteTypedDict(TypedDict):
    r"""Greater than or equal to"""

    gte: float


class DeploymentStreamAndGte(BaseModel):
    r"""Greater than or equal to"""

    gte: float


class DeploymentStreamAndGtTypedDict(TypedDict):
    r"""Greater than"""

    gt: float


class DeploymentStreamAndGt(BaseModel):
    r"""Greater than"""

    gt: float


DeploymentStreamAndDeploymentsNeTypedDict = TypeAliasType(
    "DeploymentStreamAndDeploymentsNeTypedDict", Union[str, float, bool]
)


DeploymentStreamAndDeploymentsNe = TypeAliasType(
    "DeploymentStreamAndDeploymentsNe", Union[str, float, bool]
)


class DeploymentStreamAndNeTypedDict(TypedDict):
    r"""Not equal to"""

    ne: DeploymentStreamAndDeploymentsNeTypedDict


class DeploymentStreamAndNe(BaseModel):
    r"""Not equal to"""

    ne: DeploymentStreamAndDeploymentsNe


DeploymentStreamAndDeploymentsEqTypedDict = TypeAliasType(
    "DeploymentStreamAndDeploymentsEqTypedDict", Union[str, float, bool]
)


DeploymentStreamAndDeploymentsEq = TypeAliasType(
    "DeploymentStreamAndDeploymentsEq", Union[str, float, bool]
)


class DeploymentStreamAndEqTypedDict(TypedDict):
    r"""Equal to"""

    eq: DeploymentStreamAndDeploymentsEqTypedDict


class DeploymentStreamAndEq(BaseModel):
    r"""Equal to"""

    eq: DeploymentStreamAndDeploymentsEq


DeploymentStreamKnowledgeFilterDeploymentsAndTypedDict = TypeAliasType(
    "DeploymentStreamKnowledgeFilterDeploymentsAndTypedDict",
    Union[
        DeploymentStreamAndEqTypedDict,
        DeploymentStreamAndNeTypedDict,
        DeploymentStreamAndGtTypedDict,
        DeploymentStreamAndGteTypedDict,
        DeploymentStreamAndLtTypedDict,
        DeploymentStreamAndLteTypedDict,
        DeploymentStreamAndInTypedDict,
        DeploymentStreamAndNinTypedDict,
        DeploymentStreamAndExistsTypedDict,
    ],
)


DeploymentStreamKnowledgeFilterDeploymentsAnd = TypeAliasType(
    "DeploymentStreamKnowledgeFilterDeploymentsAnd",
    Union[
        DeploymentStreamAndEq,
        DeploymentStreamAndNe,
        DeploymentStreamAndGt,
        DeploymentStreamAndGte,
        DeploymentStreamAndLt,
        DeploymentStreamAndLte,
        DeploymentStreamAndIn,
        DeploymentStreamAndNin,
        DeploymentStreamAndExists,
    ],
)


class DeploymentStreamKnowledgeFilterAndTypedDict(TypedDict):
    r"""And"""

    and_: List[Dict[str, DeploymentStreamKnowledgeFilterDeploymentsAndTypedDict]]


class DeploymentStreamKnowledgeFilterAnd(BaseModel):
    r"""And"""

    and_: Annotated[
        List[Dict[str, DeploymentStreamKnowledgeFilterDeploymentsAnd]],
        pydantic.Field(alias="and"),
    ]


class DeploymentStream1ExistsTypedDict(TypedDict):
    r"""Exists"""

    exists: bool


class DeploymentStream1Exists(BaseModel):
    r"""Exists"""

    exists: bool


DeploymentStream1DeploymentsNinTypedDict = TypeAliasType(
    "DeploymentStream1DeploymentsNinTypedDict", Union[str, float, bool]
)


DeploymentStream1DeploymentsNin = TypeAliasType(
    "DeploymentStream1DeploymentsNin", Union[str, float, bool]
)


class DeploymentStream1NinTypedDict(TypedDict):
    r"""Not in"""

    nin: List[DeploymentStream1DeploymentsNinTypedDict]


class DeploymentStream1Nin(BaseModel):
    r"""Not in"""

    nin: List[DeploymentStream1DeploymentsNin]


DeploymentStream1DeploymentsInTypedDict = TypeAliasType(
    "DeploymentStream1DeploymentsInTypedDict", Union[str, float, bool]
)


DeploymentStream1DeploymentsIn = TypeAliasType(
    "DeploymentStream1DeploymentsIn", Union[str, float, bool]
)


class DeploymentStream1InTypedDict(TypedDict):
    r"""In"""

    in_: List[DeploymentStream1DeploymentsInTypedDict]


class DeploymentStream1In(BaseModel):
    r"""In"""

    in_: Annotated[List[DeploymentStream1DeploymentsIn], pydantic.Field(alias="in")]


class DeploymentStream1LteTypedDict(TypedDict):
    r"""Less than or equal to"""

    lte: float


class DeploymentStream1Lte(BaseModel):
    r"""Less than or equal to"""

    lte: float


class DeploymentStream1LtTypedDict(TypedDict):
    r"""Less than"""

    lt: float


class DeploymentStream1Lt(BaseModel):
    r"""Less than"""

    lt: float


class DeploymentStream1GteTypedDict(TypedDict):
    r"""Greater than or equal to"""

    gte: float


class DeploymentStream1Gte(BaseModel):
    r"""Greater than or equal to"""

    gte: float


class DeploymentStream1GtTypedDict(TypedDict):
    r"""Greater than"""

    gt: float


class DeploymentStream1Gt(BaseModel):
    r"""Greater than"""

    gt: float


DeploymentStream1DeploymentsNeTypedDict = TypeAliasType(
    "DeploymentStream1DeploymentsNeTypedDict", Union[str, float, bool]
)


DeploymentStream1DeploymentsNe = TypeAliasType(
    "DeploymentStream1DeploymentsNe", Union[str, float, bool]
)


class DeploymentStream1NeTypedDict(TypedDict):
    r"""Not equal to"""

    ne: DeploymentStream1DeploymentsNeTypedDict


class DeploymentStream1Ne(BaseModel):
    r"""Not equal to"""

    ne: DeploymentStream1DeploymentsNe


DeploymentStream1DeploymentsEqTypedDict = TypeAliasType(
    "DeploymentStream1DeploymentsEqTypedDict", Union[str, float, bool]
)


DeploymentStream1DeploymentsEq = TypeAliasType(
    "DeploymentStream1DeploymentsEq", Union[str, float, bool]
)


class DeploymentStream1EqTypedDict(TypedDict):
    r"""Equal to"""

    eq: DeploymentStream1DeploymentsEqTypedDict


class DeploymentStream1Eq(BaseModel):
    r"""Equal to"""

    eq: DeploymentStream1DeploymentsEq


DeploymentStreamKnowledgeFilter1TypedDict = TypeAliasType(
    "DeploymentStreamKnowledgeFilter1TypedDict",
    Union[
        DeploymentStream1EqTypedDict,
        DeploymentStream1NeTypedDict,
        DeploymentStream1GtTypedDict,
        DeploymentStream1GteTypedDict,
        DeploymentStream1LtTypedDict,
        DeploymentStream1LteTypedDict,
        DeploymentStream1InTypedDict,
        DeploymentStream1NinTypedDict,
        DeploymentStream1ExistsTypedDict,
    ],
)


DeploymentStreamKnowledgeFilter1 = TypeAliasType(
    "DeploymentStreamKnowledgeFilter1",
    Union[
        DeploymentStream1Eq,
        DeploymentStream1Ne,
        DeploymentStream1Gt,
        DeploymentStream1Gte,
        DeploymentStream1Lt,
        DeploymentStream1Lte,
        DeploymentStream1In,
        DeploymentStream1Nin,
        DeploymentStream1Exists,
    ],
)


DeploymentStreamKnowledgeFilterTypedDict = TypeAliasType(
    "DeploymentStreamKnowledgeFilterTypedDict",
    Union[
        DeploymentStreamKnowledgeFilterAndTypedDict,
        DeploymentStreamKnowledgeFilterOrTypedDict,
        Dict[str, DeploymentStreamKnowledgeFilter1TypedDict],
    ],
)
r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""


DeploymentStreamKnowledgeFilter = TypeAliasType(
    "DeploymentStreamKnowledgeFilter",
    Union[
        DeploymentStreamKnowledgeFilterAnd,
        DeploymentStreamKnowledgeFilterOr,
        Dict[str, DeploymentStreamKnowledgeFilter1],
    ],
)
r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""


class DeploymentStreamRequestBodyTypedDict(TypedDict):
    key: str
    r"""The deployment key to invoke"""
    inputs: NotRequired[Dict[str, Any]]
    r"""Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used."""
    context: NotRequired[Dict[str, Any]]
    r"""Key-value pairs that match your data model and fields declared in your deployment routing configuration"""
    prefix_messages: NotRequired[List[DeploymentStreamPrefixMessagesTypedDict]]
    r"""A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment."""
    messages: NotRequired[List[DeploymentStreamMessagesTypedDict]]
    r"""A list of messages to send to the deployment."""
    file_ids: NotRequired[List[str]]
    r"""A list of file IDs that are associated with the deployment request."""
    metadata: NotRequired[Dict[str, Any]]
    r"""Key-value pairs that you want to attach to the log generated by this request."""
    extra_params: NotRequired[Dict[str, Any]]
    r"""Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration."""
    documents: NotRequired[List[DeploymentStreamDocumentsTypedDict]]
    r"""A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings."""
    invoke_options: NotRequired[DeploymentStreamInvokeOptionsTypedDict]
    thread: NotRequired[DeploymentStreamThreadTypedDict]
    knowledge_filter: NotRequired[DeploymentStreamKnowledgeFilterTypedDict]
    r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""


class DeploymentStreamRequestBody(BaseModel):
    key: str
    r"""The deployment key to invoke"""

    inputs: Optional[Dict[str, Any]] = None
    r"""Key-value pairs variables to replace in your prompts. If a variable is not provided that is defined in the prompt, the default variables are used."""

    context: Optional[Dict[str, Any]] = None
    r"""Key-value pairs that match your data model and fields declared in your deployment routing configuration"""

    prefix_messages: Optional[List[DeploymentStreamPrefixMessages]] = None
    r"""A list of messages to include after the `System` message, but before the  `User` and `Assistant` pairs configured in your deployment."""

    messages: Optional[List[DeploymentStreamMessages]] = None
    r"""A list of messages to send to the deployment."""

    file_ids: Optional[List[str]] = None
    r"""A list of file IDs that are associated with the deployment request."""

    metadata: Optional[Dict[str, Any]] = None
    r"""Key-value pairs that you want to attach to the log generated by this request."""

    extra_params: Optional[Dict[str, Any]] = None
    r"""Utilized for passing additional parameters to the model provider. Exercise caution when using this feature, as the included parameters will overwrite any parameters specified in the deployment prompt configuration."""

    documents: Optional[List[DeploymentStreamDocuments]] = None
    r"""A list of relevant documents that evaluators and guardrails can cite to evaluate the user input or the model response based on your deployment settings."""

    invoke_options: Optional[DeploymentStreamInvokeOptions] = None

    thread: Optional[DeploymentStreamThread] = None

    knowledge_filter: Optional[DeploymentStreamKnowledgeFilter] = None
    r"""A filter to apply to the knowledge base chunk metadata when using  knowledge bases in the deployment."""


DeploymentStreamObject = Literal[
    "chat",
    "completion",
    "image",
]
r"""Indicates the type of model used to generate the response"""


DeploymentStreamProvider = Literal[
    "cohere",
    "openai",
    "anthropic",
    "huggingface",
    "replicate",
    "google",
    "google-ai",
    "azure",
    "aws",
    "anyscale",
    "perplexity",
    "groq",
    "fal",
    "leonardoai",
    "nvidia",
    "jina",
    "togetherai",
    "elevenlabs",
    "litellm",
    "openailike",
    "cerebras",
    "bytedance",
    "mistral",
]
r"""The provider used to generate the response"""


class DeploymentStreamDeploymentsMetadataTypedDict(TypedDict):
    r"""Metadata of the retrieved chunk from the knowledge base"""

    file_name: str
    r"""Name of the file"""
    page_number: Nullable[float]
    r"""Page number of the chunk"""
    file_type: str
    r"""Type of the file"""
    search_score: float
    r"""Search scores are normalized to be in the range [0, 1]. Search score is calculated based on `[Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)` algorithm. Scores close to 1 indicate the document is closer to the query, and scores closer to 0 indicate the document is farther from the query."""
    rerank_score: NotRequired[float]
    r"""Rerank scores are normalized to be in the range [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to 0 indicate low relevance. It is not accurate to assume a score of 0.9 means the document is 2x more relevant than a document with a score of 0.45"""


class DeploymentStreamDeploymentsMetadata(BaseModel):
    r"""Metadata of the retrieved chunk from the knowledge base"""

    file_name: str
    r"""Name of the file"""

    page_number: Nullable[float]
    r"""Page number of the chunk"""

    file_type: str
    r"""Type of the file"""

    search_score: float
    r"""Search scores are normalized to be in the range [0, 1]. Search score is calculated based on `[Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)` algorithm. Scores close to 1 indicate the document is closer to the query, and scores closer to 0 indicate the document is farther from the query."""

    rerank_score: Optional[float] = None
    r"""Rerank scores are normalized to be in the range [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to 0 indicate low relevance. It is not accurate to assume a score of 0.9 means the document is 2x more relevant than a document with a score of 0.45"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["rerank_score"]
        nullable_fields = ["page_number"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class DeploymentStreamRetrievalsTypedDict(TypedDict):
    document: str
    r"""Content of the retrieved chunk from the knowledge base"""
    metadata: DeploymentStreamDeploymentsMetadataTypedDict
    r"""Metadata of the retrieved chunk from the knowledge base"""


class DeploymentStreamRetrievals(BaseModel):
    document: str
    r"""Content of the retrieved chunk from the knowledge base"""

    metadata: DeploymentStreamDeploymentsMetadata
    r"""Metadata of the retrieved chunk from the knowledge base"""


DeploymentStreamMessageDeploymentsResponseType = Literal["image",]


DeploymentStreamMessageDeploymentsResponseRole = Literal[
    "system",
    "assistant",
    "user",
    "exception",
    "tool",
    "prompt",
    "correction",
    "expected_output",
]
r"""The role of the prompt message"""


class DeploymentStreamMessage3TypedDict(TypedDict):
    type: DeploymentStreamMessageDeploymentsResponseType
    role: DeploymentStreamMessageDeploymentsResponseRole
    r"""The role of the prompt message"""
    url: str


class DeploymentStreamMessage3(BaseModel):
    type: DeploymentStreamMessageDeploymentsResponseType

    role: DeploymentStreamMessageDeploymentsResponseRole
    r"""The role of the prompt message"""

    url: str


DeploymentStreamMessageDeploymentsType = Literal["content",]


DeploymentStreamMessageDeploymentsRole = Literal[
    "system",
    "assistant",
    "user",
    "exception",
    "tool",
    "prompt",
    "correction",
    "expected_output",
]
r"""The role of the prompt message"""


class DeploymentStreamMessage2TypedDict(TypedDict):
    type: DeploymentStreamMessageDeploymentsType
    role: DeploymentStreamMessageDeploymentsRole
    r"""The role of the prompt message"""
    content: Nullable[str]
    reasoning: NotRequired[str]
    r"""Internal thought process of the model"""
    reasoning_signature: NotRequired[str]
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""
    redacted_reasoning: NotRequired[str]
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""


class DeploymentStreamMessage2(BaseModel):
    type: DeploymentStreamMessageDeploymentsType

    role: DeploymentStreamMessageDeploymentsRole
    r"""The role of the prompt message"""

    content: Nullable[str]

    reasoning: Optional[str] = None
    r"""Internal thought process of the model"""

    reasoning_signature: Optional[str] = None
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""

    redacted_reasoning: Optional[str] = None
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["reasoning", "reasoning_signature", "redacted_reasoning"]
        nullable_fields = ["content"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


DeploymentStreamMessageType = Literal["tool_calls",]


DeploymentStreamMessageRole = Literal[
    "system",
    "assistant",
    "user",
    "exception",
    "tool",
    "prompt",
    "correction",
    "expected_output",
]
r"""The role of the prompt message"""


DeploymentStreamMessageDeploymentsResponse200Type = Literal["function",]


class DeploymentStreamMessageFunctionTypedDict(TypedDict):
    name: str
    arguments: str
    r"""JSON string arguments for the functions"""


class DeploymentStreamMessageFunction(BaseModel):
    name: str

    arguments: str
    r"""JSON string arguments for the functions"""


class DeploymentStreamMessageToolCallsTypedDict(TypedDict):
    type: DeploymentStreamMessageDeploymentsResponse200Type
    function: DeploymentStreamMessageFunctionTypedDict
    id: NotRequired[str]
    index: NotRequired[float]


class DeploymentStreamMessageToolCalls(BaseModel):
    type: DeploymentStreamMessageDeploymentsResponse200Type

    function: DeploymentStreamMessageFunction

    id: Optional[str] = None

    index: Optional[float] = None


class DeploymentStreamMessage1TypedDict(TypedDict):
    type: DeploymentStreamMessageType
    role: DeploymentStreamMessageRole
    r"""The role of the prompt message"""
    tool_calls: List[DeploymentStreamMessageToolCallsTypedDict]
    content: NotRequired[Nullable[str]]
    reasoning: NotRequired[str]
    r"""Internal thought process of the model"""
    reasoning_signature: NotRequired[str]
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""
    redacted_reasoning: NotRequired[str]
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""


class DeploymentStreamMessage1(BaseModel):
    type: DeploymentStreamMessageType

    role: DeploymentStreamMessageRole
    r"""The role of the prompt message"""

    tool_calls: List[DeploymentStreamMessageToolCalls]

    content: OptionalNullable[str] = UNSET

    reasoning: Optional[str] = None
    r"""Internal thought process of the model"""

    reasoning_signature: Optional[str] = None
    r"""The signature holds a cryptographic token which verifies that the thinking block was generated by the model, and is verified when thinking is part of a multiturn conversation. This value should not be modified and should always be sent to the API when the reasoning is redacted. Currently only supported by `Anthropic`."""

    redacted_reasoning: Optional[str] = None
    r"""Occasionally the model's internal reasoning will be flagged by the safety systems of the provider. When this occurs, the provider will encrypt the reasoning. These redacted reasoning is decrypted when passed back to the API, allowing the model to continue its response without losing context."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "content",
            "reasoning",
            "reasoning_signature",
            "redacted_reasoning",
        ]
        nullable_fields = ["content"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


DeploymentStreamMessageTypedDict = TypeAliasType(
    "DeploymentStreamMessageTypedDict",
    Union[
        DeploymentStreamMessage3TypedDict,
        DeploymentStreamMessage2TypedDict,
        DeploymentStreamMessage1TypedDict,
    ],
)


DeploymentStreamMessage = TypeAliasType(
    "DeploymentStreamMessage",
    Union[DeploymentStreamMessage3, DeploymentStreamMessage2, DeploymentStreamMessage1],
)


class DeploymentStreamChoicesTypedDict(TypedDict):
    index: float
    message: DeploymentStreamMessageTypedDict
    finish_reason: NotRequired[Nullable[str]]


class DeploymentStreamChoices(BaseModel):
    index: float

    message: DeploymentStreamMessage

    finish_reason: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["finish_reason"]
        nullable_fields = ["finish_reason"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class DeploymentStreamDataTypedDict(TypedDict):
    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""
    created: datetime
    r"""A timestamp indicating when the object was created. Usually in a standardized format like ISO 8601"""
    object: DeploymentStreamObject
    r"""Indicates the type of model used to generate the response"""
    model: str
    r"""The model used to generate the response"""
    provider: DeploymentStreamProvider
    r"""The provider used to generate the response"""
    is_final: bool
    r"""Indicates if the response is the final response"""
    choices: List[DeploymentStreamChoicesTypedDict]
    r"""A list of choices generated by the model"""
    integration_id: NotRequired[str]
    r"""Indicates integration id used to generate the response"""
    finalized: NotRequired[datetime]
    r"""A timestamp indicating when the object was finalized. Usually in a standardized format like ISO 8601"""
    system_fingerprint: NotRequired[Nullable[str]]
    r"""Provider backed system fingerprint."""
    retrievals: NotRequired[List[DeploymentStreamRetrievalsTypedDict]]
    r"""List of documents retrieved from the knowledge base. This property is only available when the `include_retrievals` flag is set to `true` in the invoke settings. When stream is set to true, the `retrievals` property will be returned in the last streamed chunk where the property `is_final` is set to `true`."""
    provider_response: NotRequired[Any]
    r"""Response returned by the model provider. This functionality is only supported when streaming is not used. If streaming is used, the `provider_response` property will be set to `null`."""


class DeploymentStreamData(BaseModel):
    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""

    created: datetime
    r"""A timestamp indicating when the object was created. Usually in a standardized format like ISO 8601"""

    object: DeploymentStreamObject
    r"""Indicates the type of model used to generate the response"""

    model: str
    r"""The model used to generate the response"""

    provider: DeploymentStreamProvider
    r"""The provider used to generate the response"""

    is_final: bool
    r"""Indicates if the response is the final response"""

    choices: List[DeploymentStreamChoices]
    r"""A list of choices generated by the model"""

    integration_id: Optional[str] = None
    r"""Indicates integration id used to generate the response"""

    finalized: Optional[datetime] = None
    r"""A timestamp indicating when the object was finalized. Usually in a standardized format like ISO 8601"""

    system_fingerprint: OptionalNullable[str] = UNSET
    r"""Provider backed system fingerprint."""

    retrievals: Optional[List[DeploymentStreamRetrievals]] = None
    r"""List of documents retrieved from the knowledge base. This property is only available when the `include_retrievals` flag is set to `true` in the invoke settings. When stream is set to true, the `retrievals` property will be returned in the last streamed chunk where the property `is_final` is set to `true`."""

    provider_response: Optional[Any] = None
    r"""Response returned by the model provider. This functionality is only supported when streaming is not used. If streaming is used, the `provider_response` property will be set to `null`."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "integration_id",
            "finalized",
            "system_fingerprint",
            "retrievals",
            "provider_response",
        ]
        nullable_fields = ["system_fingerprint"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class DeploymentStreamResponseBodyTypedDict(TypedDict):
    r"""Successful operation"""

    data: NotRequired[DeploymentStreamDataTypedDict]


class DeploymentStreamResponseBody(BaseModel):
    r"""Successful operation"""

    data: Optional[DeploymentStreamData] = None
